{"cells":[{"cell_type":"markdown","metadata":{"id":"cOxzuH_kOfSF"},"source":["# **Start**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58189,"status":"ok","timestamp":1746264192063,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"d5vKr6J_3p22","outputId":"56840faf-ced7-4e54-8692-73b1c713f5b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211757,"status":"ok","timestamp":1746264403819,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"t1jgcsTHOkrm","outputId":"4434c680-9fd7-434d-bf2c-2ff0a17c83d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: scikit-learn 1.6.1\n","Uninstalling scikit-learn-1.6.1:\n","  Successfully uninstalled scikit-learn-1.6.1\n","Collecting scikit-learn==1.5.2\n","  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n","Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn\n","Successfully installed scikit-learn-1.5.2\n","Collecting bayesian-optimization\n","  Downloading bayesian_optimization-2.0.3-py3-none-any.whl.metadata (9.0 kB)\n","Collecting colorama<0.5.0,>=0.4.6 (from bayesian-optimization)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (2.0.2)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (1.5.2)\n","Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.6.0)\n","Downloading bayesian_optimization-2.0.3-py3-none-any.whl (31 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Installing collected packages: colorama, bayesian-optimization\n","Successfully installed bayesian-optimization-2.0.3 colorama-0.4.6\n","Collecting optuna\n","  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n","Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n","Collecting gpboost\n","  Downloading gpboost-1.5.6-py3-none-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from gpboost) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gpboost) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gpboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gpboost) (1.15.2)\n","Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.11/dist-packages (from gpboost) (1.5.2)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from gpboost) (4.3.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->gpboost) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->gpboost) (3.6.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (1.15.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (6.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (6.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2025.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->gpboost) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->gpboost) (4.13.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->gpboost) (1.17.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->gpboost) (3.2.1)\n","Downloading gpboost-1.5.6-py3-none-manylinux1_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gpboost\n","Successfully installed gpboost-1.5.6\n","Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.5.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.13.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n","Collecting ngboost\n","  Downloading ngboost-0.5.5-py3-none-any.whl.metadata (4.0 kB)\n","Collecting lifelines>=0.25 (from ngboost)\n","  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from ngboost) (2.0.2)\n","Collecting scikit-learn<2.0,>=1.6 (from ngboost)\n","  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: scipy>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from ngboost) (1.15.2)\n","Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.11/dist-packages (from ngboost) (4.67.1)\n","Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (2.2.2)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (3.10.0)\n","Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (1.7.0)\n","Collecting autograd-gamma>=0.3 (from lifelines>=0.25->ngboost)\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting formulaic>=0.2.2 (from lifelines>=0.25->ngboost)\n","  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.6->ngboost) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.6->ngboost) (3.6.0)\n","Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines>=0.25->ngboost)\n","  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.13.2)\n","Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.17.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.17.0)\n","Downloading ngboost-0.5.5-py3-none-any.whl (33 kB)\n","Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: autograd-gamma\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=687f5b337981f300823cfea5f4b0c8f02af3353cff29f0d364c054a636c43981\n","  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n","Successfully built autograd-gamma\n","Installing collected packages: interface-meta, scikit-learn, autograd-gamma, formulaic, lifelines, ngboost\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.5.2\n","    Uninstalling scikit-learn-1.5.2:\n","      Successfully uninstalled scikit-learn-1.5.2\n","Successfully installed autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0 ngboost-0.5.5 scikit-learn-1.6.1\n","Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.11/dist-packages (2024.12.1)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (8.1.8)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (3.1.1)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (2025.3.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (24.2)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (6.0.2)\n","Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (0.12.1)\n","Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (8.7.0)\n","Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (2.2.2)\n","Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (1.1.21)\n","Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (18.1.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask[dataframe]) (3.21.0)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2025.2)\n","Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.17.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.2)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\n","Collecting lime\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.15.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.2.1)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.3.30)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n","Building wheels for collected packages: lime\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=f756e408acc91bf14cf452e6098ffa68626500d2243708d3ebb83eb80f8d0315\n","  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n","Successfully built lime\n","Installing collected packages: lime\n","Successfully installed lime-0.2.0.1\n","Collecting interpret\n","  Downloading interpret-0.6.10-py3-none-any.whl.metadata (1.2 kB)\n","Collecting interpret-core==0.6.10 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading interpret_core-0.6.10-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.0.2)\n","Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.2.2)\n","Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.6.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.4.2)\n","Requirement already satisfied: psutil>=5.6.2 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.9.5)\n","Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (6.17.1)\n","Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (7.34.0)\n","Requirement already satisfied: plotly>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.24.1)\n","Collecting SALib>=1.3.3 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading salib-1.5.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: shap>=0.28.5 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.47.2)\n","Collecting dill>=0.2.5 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n","Collecting aplr>=10.6.1 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading aplr-10.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n","Collecting dash<3.0.0,>=1.0.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n","Collecting dash-core-components>=1.0.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting dash-html-components>=1.0.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting dash-table>=4.1.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting dash-cytoscape>=0.1.1 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading dash_cytoscape-1.0.2.tar.gz (4.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gevent>=1.3.6 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading gevent-25.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.32.3)\n","Collecting Flask<3.1,>=1.0.4 (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n","Collecting Werkzeug<3.1 (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (8.7.0)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.13.2)\n","Collecting retrying (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (75.2.0)\n","Requirement already satisfied: greenlet>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.2.1)\n","Collecting zope.event (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n","Collecting zope.interface (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.8.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.1.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (24.2)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (24.0.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (6.4.2)\n","Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.7.1)\n","Collecting jedi>=0.16 (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.19.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.9.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2025.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=3.8.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (9.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2025.4.26)\n","Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.10.0)\n","Collecting multiprocess (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret)\n","  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.15.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18.1->interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.67.1)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.0.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.1.1)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.1.6)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (8.1.8)\n","Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.8.4)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (5.7.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.2.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.43.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19.2->interpret-core==0.6.10->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.0.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash<3.0.0,>=1.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (3.21.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret) (4.3.7)\n","Downloading interpret-0.6.10-py3-none-any.whl (1.4 kB)\n","Downloading interpret_core-0.6.10-py3-none-any.whl (16.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aplr-10.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n","Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n","Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n","Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gevent-25.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading salib-1.5.1-py3-none-any.whl (778 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.9/778.9 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flask-3.0.3-py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.18-py311-none-any.whl (144 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n","Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: dash-cytoscape\n","  Building wheel for dash-cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dash-cytoscape: filename=dash_cytoscape-1.0.2-py3-none-any.whl size=4010717 sha256=10a5ad34703603e0532d7022de149902a87f8c61790c73fe05ce04189315c89d\n","  Stored in directory: /root/.cache/pip/wheels/99/b1/ab/6c999ab288b4849d372e23c0a8f6ece7edb7ffeb8c97959ab0\n","Successfully built dash-cytoscape\n","Installing collected packages: dash-table, dash-html-components, dash-core-components, zope.interface, zope.event, Werkzeug, retrying, jedi, dill, aplr, multiprocess, gevent, Flask, SALib, interpret-core, dash, dash-cytoscape, interpret\n","  Attempting uninstall: Werkzeug\n","    Found existing installation: Werkzeug 3.1.3\n","    Uninstalling Werkzeug-3.1.3:\n","      Successfully uninstalled Werkzeug-3.1.3\n","  Attempting uninstall: Flask\n","    Found existing installation: Flask 3.1.0\n","    Uninstalling Flask-3.1.0:\n","      Successfully uninstalled Flask-3.1.0\n","Successfully installed Flask-3.0.3 SALib-1.5.1 Werkzeug-3.0.6 aplr-10.9.0 dash-2.18.2 dash-core-components-2.0.0 dash-cytoscape-1.0.2 dash-html-components-2.0.0 dash-table-5.0.0 dill-0.4.0 gevent-25.4.2 interpret-0.6.10 interpret-core-0.6.10 jedi-0.19.2 multiprocess-0.70.18 retrying-1.3.4 zope.event-5.0 zope.interface-7.2\n","Collecting optunahub\n","  Downloading optunahub-0.2.0-py3-none-any.whl.metadata (6.3 kB)\n","Collecting ga4mp (from optunahub)\n","  Downloading ga4mp-2.0.4-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optunahub) (4.3.0)\n","Collecting PyGithub>=1.59 (from optunahub)\n","  Downloading PyGithub-2.6.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting pynacl>=1.4.0 (from PyGithub>=1.59->optunahub)\n","  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n","Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (2.32.3)\n","Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub>=1.59->optunahub) (2.10.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (4.13.2)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (2.4.0)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (1.2.18)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (1.15.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optunahub) (1.1.3)\n","Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub>=1.59->optunahub) (43.0.3)\n","Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub>=1.59->optunahub) (1.17.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (2025.4.26)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optunahub) (3.2.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->PyGithub>=1.59->optunahub) (1.17.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub>=1.59->optunahub) (2.22)\n","Downloading optunahub-0.2.0-py3-none-any.whl (11 kB)\n","Downloading PyGithub-2.6.1-py3-none-any.whl (410 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ga4mp-2.0.4-py3-none-any.whl (15 kB)\n","Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ga4mp, pynacl, PyGithub, optunahub\n","Successfully installed PyGithub-2.6.1 ga4mp-2.0.4 optunahub-0.2.0 pynacl-1.5.0\n","Collecting cmaes\n","  Downloading cmaes-0.11.1-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cmaes) (2.0.2)\n","Downloading cmaes-0.11.1-py3-none-any.whl (35 kB)\n","Installing collected packages: cmaes\n","Successfully installed cmaes-0.11.1\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n","Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kaleido\n","Successfully installed kaleido-0.2.1\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n","Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (0.2.1)\n","Collecting properscoring\n","  Downloading properscoring-0.1-py2.py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from properscoring) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from properscoring) (1.15.2)\n","Downloading properscoring-0.1-py2.py3-none-any.whl (23 kB)\n","Installing collected packages: properscoring\n","Successfully installed properscoring-0.1\n","Collecting XlsxWriter\n","  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n","Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: XlsxWriter\n","Successfully installed XlsxWriter-3.2.3\n","Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n","Collecting pgbm\n","  Downloading pgbm-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n","Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pgbm) (1.6.1)\n","Collecting ninja>=1.10.2.2 (from pgbm)\n","  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.11/dist-packages (from pgbm) (0.60.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.56->pgbm) (0.43.0)\n","Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba>=0.56->pgbm) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (3.6.0)\n","Downloading pgbm-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ninja, pgbm\n","Successfully installed ninja-1.11.1.4 pgbm-2.3.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting cp\n","  Downloading cp-2020.12.3.tar.gz (1.4 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: cp\n","  Building wheel for cp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cp: filename=cp-2020.12.3-py3-none-any.whl size=1420 sha256=7acc767447dba758da37fad850414b01bcb5cf00266859c200fe28be1f62fe36\n","  Stored in directory: /root/.cache/pip/wheels/58/67/10/9ba963c5b021c764015a1463b9bb89a408fc37bbcde7436aa7\n","Successfully built cp\n","Installing collected packages: cp\n","Successfully installed cp-2020.12.3\n","Collecting mapie\n","  Downloading MAPIE-0.9.2-py3-none-any.whl.metadata (12 kB)\n","Collecting scikit-learn<1.6.0 (from mapie)\n","  Using cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mapie) (1.15.2)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from mapie) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mapie) (24.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0->mapie) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0->mapie) (3.6.0)\n","Downloading MAPIE-0.9.2-py3-none-any.whl (178 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.1/178.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","Installing collected packages: scikit-learn, mapie\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.6.1\n","    Uninstalling scikit-learn-1.6.1:\n","      Successfully uninstalled scikit-learn-1.6.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ngboost 0.5.5 requires scikit-learn<2.0,>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed mapie-0.9.2 scikit-learn-1.5.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting skorch\n","  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\n","Collecting puncc\n","  Downloading puncc-0.8.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from skorch) (2.0.2)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.5.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.15.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch) (0.9.0)\n","Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (4.67.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from puncc) (1.4.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from puncc) (3.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from puncc) (2.2.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->puncc) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->puncc) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->puncc) (1.17.0)\n","Downloading skorch-1.1.0-py3-none-any.whl (228 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading puncc-0.8.0-py3-none-any.whl (70 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: skorch, puncc\n","Successfully installed puncc-0.8.0 skorch-1.1.0\n","Found existing installation: scikit-learn 1.5.2\n","Uninstalling scikit-learn-1.5.2:\n","  Successfully uninstalled scikit-learn-1.5.2\n","Collecting scikit-learn==1.6.1\n","  Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (3.6.0)\n","Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","Installing collected packages: scikit-learn\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","mapie 0.9.2 requires scikit-learn<1.6.0, but you have scikit-learn 1.6.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed scikit-learn-1.6.1\n","Collecting numpy==1.26.4\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","mapie 0.9.2 requires scikit-learn<1.6.0, but you have scikit-learn 1.6.1 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n","Collecting catboost\n","  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n","Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n","Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: catboost\n","Successfully installed catboost-1.2.8\n"]}],"source":["# Uninstall existing scikit-learn to avoid conflicts\n","!pip uninstall -y scikit-learn\n","# Install specific versions of libraries to avoid conflicts\n","!pip install scikit-learn==1.5.2\n","!pip install bayesian-optimization\n","!pip install optuna\n","!pip install gpboost\n","!pip install shap\n","!pip install ngboost\n","!pip install dask[dataframe]\n","!pip install torch seaborn\n","!pip install lightgbm\n","!pip install xgboost\n","!pip install lime\n","!pip install interpret\n","!pip install optunahub\n","!pip install cmaes\n","!pip install plotly kaleido\n","!pip install openpyxl\n","!pip install -U kaleido\n","!pip install properscoring\n","!pip install XlsxWriter\n","!pip install cython\n","!pip install pgbm\n","!pip install torch\n","!pip install cp\n","!pip install mapie\n","!pip install torch skorch puncc\n","# Reinstall scikit-learn to the version required by ngboost\n","!pip uninstall -y scikit-learn\n","!pip install scikit-learn==1.6.1\n","# Reinstall numpy first\n","!pip install numpy==1.26.4  # Use the version compatible with catboost\n","# Reinstall catboost\n","!pip install catboost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5QL-bkHqPwKM"},"outputs":[],"source":["# Restart the runtime to apply changes\n","import os\n","os._exit(00)"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":106307,"status":"ok","timestamp":1746264566593,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"0kBPL1V9O2sA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9074654b-9b1e-4e2c-8abe-1aa0e0532eef"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n","Creating extension directory /root/.cache/torch_extensions/py311_cu124/split_decision...\n","Detected CUDA files, patching ldflags\n","Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/split_decision/build.ninja...\n","/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n","If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n","  warnings.warn(\n","Building extension module split_decision...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","Loading extension module split_decision...\n","Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n","No modifications detected for re-loaded extension module split_decision, skipping build step...\n","Loading extension module split_decision...\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import ngboost\n","from scipy.stats import randint\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.svm import SVR\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from gpboost import GPBoostRegressor\n","from ngboost import NGBRegressor\n","import optuna\n","import optunahub\n","from sklearn.experimental import enable_halving_search_cv\n","from sklearn.model_selection import HalvingGridSearchCV\n","from interpret import show\n","from interpret.blackbox import LimeTabular, ShapKernel\n","from optuna.samplers import RandomSampler\n","import random\n","import time\n","from ngboost.distns import Normal\n","from ngboost.scores import LogScore\n","from scipy.stats import norm\n","from interpret import set_visualize_provider\n","from interpret.provider import InlineProvider\n","from interpret.glassbox import ExplainableBoostingRegressor\n","from interpret import show\n","import plotly.express as px\n","from io import BytesIO\n","from openpyxl import Workbook, load_workbook\n","import os\n","from openpyxl.drawing.image import Image as openpyxlImage\n","import warnings\n","import xlsxwriter\n","from openpyxl.drawing.image import Image\n","from pgbm.sklearn import HistGradientBoostingRegressor\n","import torch\n","from pgbm.torch import PGBM\n","import plotly.graph_objects as go\n","warnings.filterwarnings('ignore')\n","import pickle\n","import json"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4599,"status":"ok","timestamp":1746264571198,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"D_rzxWyr3pKj","outputId":"84b870eb-0f1f-4dc5-a6ef-56f7fae46646"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data loaded successfully.\n","Test data loaded successfully.\n"]}],"source":["train_data_path = \"./drive/MyDrive/SCOUR/Scour_uncertainity/train.csv\"\n","test_data_path = \"./drive/MyDrive/SCOUR/Scour_uncertainity/test.csv\"\n","train_data = pd.read_csv(train_data_path)\n","test_data = pd.read_csv(test_data_path)\n","print(\"Training data loaded successfully.\")\n","print(\"Test data loaded successfully.\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1746264571232,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"sjMvmRLkPB0x","outputId":"45f55bd0-3c19-4291-a4b0-8deff543dde5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Shape of training data: (154, 8)\n","First 5 rows of training data:\n","     Ps   Pw   Skew     Velocity     Depth     D50     Gradation     Scour  \n","0  0.7  1.5        0          2.9       6.6   70.00           1.2       0.6\n","1  0.7  1.5        0          3.0       5.3   70.00           1.2       0.6\n","2  1.3  3.3        0          0.8       4.8    0.48           1.8       0.4\n","3  1.0  4.3        0          2.9       9.7    0.30           1.4       3.7\n","4  0.7  0.5       20          1.4       1.8    1.10           3.5       0.3\n","\n","Shape of test data: (78, 8)\n","First 5 rows of test data:\n","     Ps   Pw   Skew     Velocity     Depth     D50     Gradation     Scour  \n","0  1.3  0.3       16          1.0       0.3    0.94           3.0       0.4\n","1  1.0  0.8        0          0.2       1.5    0.25           8.0       0.2\n","2  1.0  0.6       10          1.6       6.6    0.90           4.2       1.1\n","3  1.3  1.2        0          0.8       3.1    0.38           2.3       1.6\n","4  1.0  0.8        0          1.1       1.7   60.00           2.4       0.2\n"]}],"source":["print(\"\\nShape of training data:\", train_data.shape)\n","print(\"First 5 rows of training data:\\n\", train_data.head(5))\n","print(\"\\nShape of test data:\", test_data.shape)\n","print(\"First 5 rows of test data:\\n\", test_data.head(5))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95,"status":"ok","timestamp":1746264571330,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"1YOqfRGLPLjK","outputId":"dbfba3c5-745a-404f-e472-76e305253547"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Shape of X_train: (154, 7)\n","Shape of y_train: (154,)\n","Shape of X_test: (78, 7)\n","Shape of y_test: (78,)\n"]}],"source":["X_train = train_data.iloc[:, :-1]\n","y_train = train_data.iloc[:, -1]\n","X_test = test_data.iloc[:, :-1]\n","y_test = test_data.iloc[:, -1]\n","x_test= X_test\n","print(\"\\nShape of X_train:\", X_train.shape)\n","print(\"Shape of y_train:\", y_train.shape)\n","print(\"Shape of X_test:\", X_test.shape)\n","print(\"Shape of y_test:\", y_test.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1746264571333,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"8Uw5ISznPMaa","outputId":"2a268cea-8ed2-4d1b-e72d-f094971cb94e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","First five rows of normalized X_train:\n","[[-1.30505288 -0.05072804 -0.49867969  1.41932674  0.51129506  1.91265145\n","  -0.75772712]\n"," [-1.30505288 -0.05072804 -0.49867969  1.53187891  0.18675076  1.91265145\n","  -0.75772712]\n"," [ 1.56606345  1.51169548 -0.49867969 -0.94426887  0.06192603 -0.69389788\n","  -0.5721613 ]\n"," [ 0.13050529  2.37970854 -0.49867969  1.41932674  1.28520839 -0.70064672\n","  -0.69587185]\n"," [-1.30505288 -0.9187411   0.57841248 -0.26895584 -0.68702234 -0.6706519\n","  -0.04639146]]\n","\n","First five rows of normalized X_test:\n","[[ 1.56606345 -1.09234371  0.36299405 -0.71916453 -1.06149653 -0.67665086\n","  -0.20102964]\n"," [ 0.13050529 -0.65833718 -0.49867969 -1.6195819  -0.76191718 -0.70252139\n","   1.34535224]\n"," [ 0.13050529 -0.83193979  0.0398664  -0.0438515   0.51129506 -0.6781506\n","   0.17010201]\n"," [ 1.56606345 -0.31113196 -0.49867969 -0.94426887 -0.36247805 -0.69764723\n","  -0.41752311]\n"," [ 0.13050529 -0.65833718 -0.49867969 -0.60661235 -0.71198729  1.53771627\n","  -0.38659547]]\n"]}],"source":["# Apply z-score normalization\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Print the first five rows of the normalized data\n","print(\"\\nFirst five rows of normalized X_train:\")\n","print(X_train[:5])\n","\n","print(\"\\nFirst five rows of normalized X_test:\")\n","print(X_test[:5])"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"PHT6BWytPScM","executionInfo":{"status":"ok","timestamp":1746264571335,"user_tz":-330,"elapsed":1,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}}},"outputs":[],"source":["# Define the model classes\n","model_classes = {\n","    'Random Forest': RandomForestRegressor,\n","    'Gradient Boosting': GradientBoostingRegressor,\n","    'XGBoost': XGBRegressor,\n","    'LightGBM': LGBMRegressor,\n","    'GPBoost': GPBoostRegressor,\n","    'CatBoost': CatBoostRegressor,\n","    'NGBoost': NGBRegressor\n","}\n","\n","feature_names = ['Ps', 'Pw', 'skew', 'Velocity', 'Depth', 'D50', 'Gradation']\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"iM8V0dbeWGr2","executionInfo":{"status":"ok","timestamp":1746264571424,"user_tz":-330,"elapsed":88,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}}},"outputs":[],"source":["def plot_best_scores(best_scores_ran, excel_file_path):\n","    # Extract the best pruner for each model based on RMSE and correlation coefficient\n","    best_rmse_scores = {}\n","    best_corr_coef_scores = {}\n","\n","    for (model_name, pruner_name), scores in best_scores_ran.items():\n","        # Initialize if not already present\n","        if model_name not in best_rmse_scores:\n","            best_rmse_scores[model_name] = (scores['test_rmse'], pruner_name)\n","        if model_name not in best_corr_coef_scores:\n","            best_corr_coef_scores[model_name] = (scores['test_corr_coef'], pruner_name)\n","\n","        # Update if better scores are found\n","        if scores['test_rmse'] < best_rmse_scores[model_name][0]:\n","            best_rmse_scores[model_name] = (scores['test_rmse'], pruner_name)\n","        if scores['test_corr_coef'] > best_corr_coef_scores[model_name][0]:\n","            best_corr_coef_scores[model_name] = (scores['test_corr_coef'], pruner_name)\n","\n","    # Prepare data for plotting\n","    model_names_rmse = [f\"{model} ({pruner})\" for model, (rmse, pruner) in best_rmse_scores.items()]\n","    rmse_values = [rmse for rmse, _ in best_rmse_scores.values()]\n","\n","    model_names_corr = [f\"{model} ({pruner})\" for model, (corr, pruner) in best_corr_coef_scores.items()]\n","    corr_values = [corr for corr, _ in best_corr_coef_scores.values()]\n","\n","    # Plot RMSE\n","    plt.figure(figsize=(12, 6))\n","    bars_rmse = plt.bar(model_names_rmse, rmse_values, color='skyblue')\n","\n","    # Highlight the best model\n","    best_rmse_index = np.argmin(rmse_values)\n","    bars_rmse[best_rmse_index].set_color('orange')\n","\n","    # Annotate the bars with the RMSE scores\n","    for i, bar in enumerate(bars_rmse):\n","        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05,\n","                 f'{rmse_values[i]:.5f}', ha='center', va='bottom', color='black')\n","\n","    # Add labels and title for the RMSE bar chart\n","    plt.xlabel('Model (Pruner)')\n","    plt.ylabel('Test RMSE')\n","    plt.title('Best Test RMSE for Each Model')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.tight_layout()\n","    rmse_image_path = 'rmse_plot.png'\n","    plt.savefig(rmse_image_path)\n","    plt.close()\n","\n","    # Plot Correlation Coefficient\n","    plt.figure(figsize=(12, 6))\n","    bars_corr = plt.bar(model_names_corr, corr_values, color='lightgreen')\n","\n","    # Highlight the best model\n","    best_corr_index = np.argmax(corr_values)\n","    bars_corr[best_corr_index].set_color('orange')\n","\n","    # Annotate the bars with the correlation coefficient scores\n","    for i, bar in enumerate(bars_corr):\n","        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05,\n","                 f'{corr_values[i]:.5f}', ha='center', va='bottom', color='black')\n","\n","    # Add labels and title for the correlation coefficient bar chart\n","    plt.xlabel('Model (Pruner)')\n","    plt.ylabel('Correlation Coefficient')\n","    plt.title('Best Correlation Coefficient for Each Model')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.tight_layout()\n","    corr_image_path = 'corr_plot.png'\n","    plt.savefig(corr_image_path)\n","    plt.close()\n","\n","    # Load the existing Excel file\n","    workbook = load_workbook(excel_file_path)\n","\n","    # Create a new sheet for the plots\n","    sheet_name = 'Best Models Plots'\n","    if sheet_name in workbook.sheetnames:\n","        sheet = workbook[sheet_name]\n","    else:\n","        sheet = workbook.create_sheet(title=sheet_name)\n","\n","    # Insert images into the new Excel sheet\n","    img_rmse = Image(rmse_image_path)\n","    img_corr = Image(corr_image_path)\n","\n","    # Insert images\n","    sheet.add_image(img_rmse, 'A1')\n","    sheet.add_image(img_corr, 'A20')  # Adjust the position as needed\n","\n","    # Save the workbook\n","    workbook.save(excel_file_path)\n","\n","    # Clean up the image files\n","    os.remove(rmse_image_path)\n","    os.remove(corr_image_path)\n","\n","# Example usage\n","# plot_best_scores(best_scores_ran, 'path_to_your_excel_file.xlsx')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"v9rnFhjC3pKl","executionInfo":{"status":"ok","timestamp":1746264571477,"user_tz":-330,"elapsed":52,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}}},"outputs":[],"source":["def generate_interpretml_explanations_summary_pruners(\n","    results_dict, X_train, y_train, X_test, feature_names, instance_indices=None, excel_file_path=None\n","):\n","    if instance_indices is None:\n","        instance_indices = range(len(X_test))\n","    elif isinstance(instance_indices, int):\n","        instance_indices = [instance_indices]\n","\n","    valid_indices = [idx for idx in instance_indices if 0 <= idx < len(X_test)]\n","    if not valid_indices:\n","        print(\"No valid instance indices provided.\")\n","        return\n","\n","    if isinstance(X_test, pd.DataFrame):\n","        instances_to_explain = X_test.iloc[valid_indices]\n","    else:\n","        instances_to_explain = X_test[valid_indices]\n","\n","    best_model_pruners = {}\n","    for model_key, model_info in results_dict.items():\n","        if isinstance(model_key, tuple):\n","            model_name, pruner_name = model_key\n","        else:\n","            model_name = model_key\n","            pruner_name = None\n","\n","        best_score = model_info.get('best_score')\n","        if best_score is None:\n","            print(f\"No 'best_score' found for {model_key}. Skipping this combination.\")\n","            continue\n","\n","        if model_name not in best_model_pruners:\n","            best_model_pruners[model_name] = {\n","                'pruner_name': pruner_name,\n","                'model_info': model_info,\n","                'best_score': best_score\n","            }\n","        else:\n","            current_best_score = best_model_pruners[model_name]['best_score']\n","            if best_score < current_best_score:\n","                best_model_pruners[model_name] = {\n","                    'pruner_name': pruner_name,\n","                    'model_info': model_info,\n","                    'best_score': best_score\n","                }\n","\n","    for model_name, info in best_model_pruners.items():\n","        pruner_name = info['pruner_name']\n","        model_info = info['model_info']\n","        best_params = model_info['best_params']\n","        model_class = model_classes.get(model_name)\n","\n","        if model_class is None:\n","            print(f\"Model {model_name} is not supported or not available.\")\n","            continue\n","\n","        if model_name == 'CatBoost':\n","            best_params['verbose'] = 0\n","\n","        model = model_class(**best_params)\n","        model.fit(X_train, y_train)\n","\n","        def predict_fn(data):\n","            return model.predict(data)\n","\n","        if isinstance(X_train, pd.DataFrame):\n","            data_for_explainer = X_train.values\n","        else:\n","            data_for_explainer = X_train\n","\n","        if isinstance(instances_to_explain, pd.DataFrame):\n","            data_for_explanation = instances_to_explain.values\n","        else:\n","            data_for_explanation = instances_to_explain\n","\n","        # Generate LIME explanations\n","        lime_explainer = LimeTabular(\n","            predict_fn,\n","            data=data_for_explainer,\n","            feature_names=feature_names,\n","            random_state=1,\n","            mode='regression'\n","        )\n","        lime_explanation = lime_explainer.explain_local(data_for_explanation)\n","\n","        feature_importances_lime = {}\n","        num_instances = len(valid_indices)\n","\n","        for idx in range(num_instances):\n","            explanation = lime_explanation.data(idx)\n","            for feature_name, feature_score in zip(explanation['names'], explanation['scores']):\n","                feature_importances_lime[feature_name] = feature_importances_lime.get(feature_name, 0) + abs(feature_score)\n","\n","        feature_importances_lime = {k: v / num_instances for k, v in feature_importances_lime.items()}\n","        feature_importances_lime = {k: round(v, 3) for k, v in feature_importances_lime.items()}\n","\n","        # Generate SHAP explanations using ShapKernel\n","        try:\n","            shap_explainer = ShapKernel(predict_fn, data_for_explainer, feature_names=feature_names)\n","            shap_explanation = shap_explainer.explain_local(data_for_explanation)\n","\n","            feature_importances_shap = {}\n","            for idx in range(num_instances):\n","                explanation = shap_explanation.data(idx)\n","                for feature_name, feature_score in zip(explanation['names'], explanation['scores']):\n","                    feature_importances_shap[feature_name] = feature_importances_shap.get(feature_name, 0) + abs(feature_score)\n","\n","            feature_importances_shap = {k: v / num_instances for k, v in feature_importances_shap.items()}\n","            feature_importances_shap = {k: round(v, 3) for k, v in feature_importances_shap.items()}\n","        except Exception as e:\n","            print(f\"Could not compute SHAP values for model {model_name}: {e}\")\n","            continue\n","\n","        # Plot LIME and SHAP feature importances side by side\n","        fig, axes = plt.subplots(1, 2, figsize=(34, 36))\n","\n","        # Plot LIME feature importances\n","        lime_importances_df = pd.DataFrame.from_dict(\n","            feature_importances_lime, orient='index', columns=['importance']\n","        )\n","        lime_importances_df.sort_values(by='importance', ascending=False, inplace=True)\n","        lime_importances_df.plot(kind='bar', legend=False, color='skyblue', ax=axes[0])\n","        axes[0].set_title(f\"LIME Feature Importances for {model_name}\")\n","        axes[0].set_ylabel(\"Average Absolute Importance Score\")\n","        axes[0].set_xlabel(\"Features\")\n","        axes[0].tick_params(axis='x', rotation=45)\n","\n","        for p in axes[0].patches:\n","            height = p.get_height()\n","            axes[0].annotate(f'{height:.3f}',\n","                             (p.get_x() + p.get_width() / 2., height),\n","                             ha='center', va='bottom', fontsize=8)\n","\n","        # Plot SHAP feature importances\n","        shap_importances_df = pd.DataFrame.from_dict(\n","            feature_importances_shap, orient='index', columns=['importance']\n","        )\n","        shap_importances_df.sort_values(by='importance', ascending=False, inplace=True)\n","        shap_importances_df.plot(kind='bar', legend=False, color='orange', ax=axes[1])\n","        axes[1].set_title(f\"SHAP Feature Importances for {model_name}\")\n","        axes[1].set_ylabel(\"Average Absolute SHAP Value\")\n","        axes[1].set_xlabel(\"Features\")\n","        axes[1].tick_params(axis='x', rotation=45)\n","\n","        for p in axes[1].patches:\n","            height = p.get_height()\n","            axes[1].annotate(f'{height:.3f}',\n","                             (p.get_x() + p.get_width() / 2., height),\n","                             ha='center', va='bottom', fontsize=8)\n","\n","        plt.tight_layout()\n","\n","        # Save plots as images\n","        image_path = f'feature_importances_{model_name}.png'\n","        fig.savefig(image_path)\n","        plt.close(fig)\n","\n","        # Optionally insert images and scores into an Excel file\n","        if excel_file_path:\n","            workbook = load_workbook(excel_file_path)\n","            sheet_name = f'{model_name} Explanations'\n","            if sheet_name in workbook.sheetnames:\n","                sheet = workbook[sheet_name]\n","            else:\n","                sheet = workbook.create_sheet(title=sheet_name)\n","\n","            # Insert images into the new Excel sheet\n","            img = Image(image_path)\n","            sheet.add_image(img, 'A1')\n","\n","            # Create a new sheet for feature importance scores\n","            scores_sheet_name = f'{model_name} Scores'\n","            if scores_sheet_name in workbook.sheetnames:\n","                scores_sheet = workbook[scores_sheet_name]\n","            else:\n","                scores_sheet = workbook.create_sheet(title=scores_sheet_name)\n","\n","            # Write LIME scores\n","            scores_sheet.append(['Feature', 'LIME Importance'])\n","            for feature, importance in feature_importances_lime.items():\n","                scores_sheet.append([feature, importance])\n","\n","            # Write SHAP scores\n","            scores_sheet.append(['Feature', 'SHAP Importance'])\n","            for feature, importance in feature_importances_shap.items():\n","                scores_sheet.append([feature, importance])\n","\n","            # Save the workbook\n","            workbook.save(excel_file_path)\n","\n","            # Clean up the image file\n","            os.remove(image_path)"]},{"cell_type":"markdown","metadata":{"id":"Z_-QSaTL3pKm"},"source":["# **Autosampler by Optuna**"]},{"cell_type":"code","source":["# Suppress Optuna's verbose output\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","# Define objective and metric functions for PGBM\n","def mseloss_objective(yhat, y, sample_weight=None):\n","    if not torch.is_tensor(yhat):\n","        yhat = torch.from_numpy(np.array(yhat)).float()\n","    if not torch.is_tensor(y):\n","        y = torch.from_numpy(np.array(y)).float()\n","    gradient = yhat - y\n","    hessian = torch.ones_like(yhat)\n","    return gradient, hessian\n","\n","def rmseloss_metric(yhat, y, sample_weight=None):\n","    if not torch.is_tensor(yhat):\n","        yhat = torch.from_numpy(np.array(yhat)).float()\n","    if not torch.is_tensor(y):\n","        y = torch.from_numpy(np.array(y)).float()\n","    loss = torch.sqrt(torch.mean((yhat - y) ** 2))\n","    return loss\n","\n","def hyperparameter_tuning_all(X_train, y_train, X_test, y_test, excel_path):\n","    X_train = np.array(X_train)\n","    y_train = np.array(y_train)\n","    X_test = np.array(X_test)\n","    y_test = np.array(y_test)\n","\n","    models = {\n","        'Random Forest': (RandomForestRegressor, {\n","            'n_estimators': [100, 200, 300, 500, 700],\n","            'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n","            'max_depth': [None, 10, 20, 30, 40],\n","            'min_samples_split': [2, 5, 10, 0.01],\n","            'min_samples_leaf': [1, 3, 5, 0.01],\n","            'min_weight_fraction_leaf': [0.0, 0.01, 0.1, 0.2],\n","            'max_features': [1.0, 'sqrt', 'log2', 0.3, 0.5],\n","            'max_leaf_nodes': [None, 50, 100, 200],\n","            'min_impurity_decrease': [0.0, 0.01, 0.1, 0.2],\n","            'n_jobs': [-1],\n","            'random_state': [42],\n","            'verbose': [0],\n","            'warm_start': [False],\n","            'ccp_alpha': [0.0, 0.001, 0.01, 0.05, 0.1]\n","        }),\n","        'Gradient Boosting': (GradientBoostingRegressor, {\n","            'loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n","            'n_estimators': [100, 200, 300, 500, 700],\n","            'subsample': [1.0, 0.9, 0.7, 0.5],\n","            'criterion': ['friedman_mse', 'squared_error'],\n","            'min_samples_split': [2, 5, 10, 0.01],\n","            'min_samples_leaf': [1, 3, 5, 0.01],\n","            'min_weight_fraction_leaf': [0.0, 0.01, 0.05, 0.1],\n","            'max_depth': [3, 5, 7, 10],\n","            'min_impurity_decrease': [0.0, 0.01, 0.1],\n","            'init': [None],\n","            'random_state': [42],\n","            'max_features': [None, 'sqrt', 'log2', 0.5],\n","            'alpha': [0.9, 0.5, 0.1],\n","            'verbose': [0],\n","            'max_leaf_nodes': [None, 10, 30, 50],\n","            'warm_start': [False],\n","            'validation_fraction': [0.1],\n","            'n_iter_no_change': [None, 10, 20],\n","            'tol': [1e-4, 1e-3],\n","            'ccp_alpha': [0.0, 0.001, 0.01]\n","        }),\n","        'XGBoost': (XGBRegressor, {\n","            'n_estimators': [100, 200, 300, 400, 500],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","            'max_depth': [3, 5, 7],\n","            'min_child_weight': [1, 3, 5],\n","            'gamma': [0, 0.1, 0.5, 1],\n","            'subsample': [0.5, 0.6, 0.7, 0.8, 0.9],\n","            'colsample_bytree': [0.5, 0.7, 0.9],\n","            'colsample_bylevel': [0.5, 0.7, 0.9],\n","            'reg_alpha': [0, 0.01, 0.1, 1],\n","            'reg_lambda': [0.1, 1, 5, 10],\n","            'objective': ['reg:squarederror'],\n","            'random_state': [42],\n","            'n_jobs': [-1]\n","        }),\n","        'LightGBM': (LGBMRegressor, {\n","            'n_estimators': [100, 200, 300, 400, 500],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","            'num_leaves': [15, 31, 63],\n","            'max_depth': [3, 5, 7, -1],\n","            'min_child_samples': [1, 5, 10, 20],\n","            'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n","            'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n","            'reg_alpha': [0, 0.01, 0.1, 1],\n","            'reg_lambda': [0, 0.1, 1, 10],\n","            'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1],\n","            'bagging_freq': [0, 1, 5],\n","            'objective': ['regression'],\n","            'random_state': [42],\n","            'n_jobs': [-1],\n","            'verbose': [-1]\n","        }),\n","        'GPBoost': (GPBoostRegressor, {\n","            'n_estimators': [100, 200, 300, 400, 500],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","            'max_depth': [3, 5, 7, -1],\n","            'num_leaves': [15, 31, 63],\n","            'min_child_samples': [1, 5, 10, 20],\n","            'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n","            'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n","            'reg_alpha': [0, 0.1, 0.5, 1.0],\n","            'reg_lambda': [0, 0.1, 0.5, 1.0],\n","            'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1],\n","            'random_state': [42],\n","            'n_jobs': [-1],\n","            'verbose': [-1]\n","        }),\n","        'CatBoost': (CatBoostRegressor, {\n","            'iterations': [200, 500, 1000],\n","            'learning_rate': [0.01, 0.03, 0.05, 0.1],\n","            'depth': [4, 6, 8, 10],\n","            'l2_leaf_reg': [1, 3, 5, 7, 9],\n","            'border_count': [32, 64, 128],\n","            'min_data_in_leaf': [1, 5, 10, 20],\n","            'rsm': [0.6, 0.8, 1.0],\n","            'bagging_temperature': [0, 1, 10],\n","            'random_seed': [42],\n","            'verbose': [0]\n","        }),\n","        'NGBoost': (NGBRegressor, {\n","            'n_estimators': [200, 500, 1000],\n","            'learning_rate': [0.01, 0.03, 0.05, 0.1],\n","            'natural_gradient': [True, False],\n","            'minibatch_frac': [0.5, 0.7, 0.9, 1.0],\n","            'col_sample': [0.5, 0.7, 0.9, 1.0],\n","            'Dist': [Normal],\n","            'Score': [LogScore],\n","            'random_state': [42],\n","            'verbose': [0]\n","        }),\n","        'HistGradientBoosting': (HistGradientBoostingRegressor, {\n","            'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","            'max_iter': [100, 200, 300, 400, 500],\n","            'max_depth': [3, 5, 7, None],\n","            'min_samples_leaf': [5, 10, 20],\n","            'max_leaf_nodes': [15, 31, 63, None],\n","            'l2_regularization': [0.0, 0.1, 0.5, 1.0],\n","            'max_bins': [64, 128, 255],\n","            'early_stopping': [True, False],\n","            'validation_fraction': [0.1, 0.2],\n","            'n_iter_no_change': [5, 10, 15],\n","            'loss': ['squared_error'],\n","            'random_state': [42],\n","            'verbose': [0]\n","        }),\n","        'PGBM': (PGBM, {}) # PGBM is handled separately\n","    }\n","\n","\n","    pruners = [\n","        optuna.pruners.MedianPruner(),\n","        optuna.pruners.NopPruner(),\n","        optuna.pruners.PatientPruner(optuna.pruners.MedianPruner(), patience=3),\n","        optuna.pruners.PercentilePruner(25.0),\n","        optuna.pruners.SuccessiveHalvingPruner(),\n","        optuna.pruners.HyperbandPruner(),\n","        optuna.pruners.ThresholdPruner(lower=0.1),\n","        optuna.pruners.WilcoxonPruner()\n","    ]\n","\n","    best_scores = {}\n","    predictions_df = pd.DataFrame({'Actual': y_test})\n","\n","    for model_name, (model_class, param_space) in models.items():\n","        for pruner in pruners:\n","            pruner_name = pruner.__class__.__name__\n","            print(f\"Running Optuna for {model_name} with {pruner_name}...\")\n","            try:\n","                sampler = optunahub.load_module(\"samplers/auto_sampler\").AutoSampler()\n","                study = optuna.create_study(direction='minimize', sampler=sampler, pruner=pruner)\n","\n","                if model_name == 'PGBM':\n","                    def pgbm_objective(trial):\n","                        params = {\n","                            'n_estimators': trial.suggest_categorical('n_estimators', [100, 200, 300, 500]),\n","                            'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.05, 0.1, 0.15]),\n","                            'max_leaves': trial.suggest_int('max_leaves', 15, 63),\n","                            'min_split_gain': trial.suggest_categorical('min_split_gain', [0.0, 0.1, 0.5, 1.0]),\n","                            'reg_lambda': trial.suggest_categorical('reg_lambda', [0.1, 1.0, 5.0, 10.0]),\n","                            'feature_fraction': trial.suggest_categorical('feature_fraction', [0.5, 0.7, 0.9, 1.0]),\n","                            'bagging_fraction': trial.suggest_categorical('bagging_fraction', [0.5, 0.7, 0.9, 1.0]),\n","                            'tree_correlation': trial.suggest_categorical('tree_correlation', [0.0, 0.1, 0.2, 0.3]),\n","                            'min_data_in_leaf': trial.suggest_categorical('min_data_in_leaf', [3, 5, 10, 20]),\n","                            'max_bin': trial.suggest_categorical('max_bin', [64, 128, 256]),\n","                            'distribution': trial.suggest_categorical('distribution', ['normal', 'studentt', 'laplace']),\n","                            'objective': 'mse',\n","                            'metric': 'rmse',\n","                            'random_state': 42,\n","                            'verbose': 0\n","                        }\n","\n","                        model = PGBM()\n","                        model.train((X_train, y_train), objective=mseloss_objective, metric=rmseloss_metric, params=params)\n","                        y_pred = model.predict(X_test)\n","                        mse = mean_squared_error(y_test, y_pred)\n","                        return mse\n","\n","                    study.optimize(pgbm_objective, n_trials=50)\n","                else:\n","                    def objective(trial, model_name, model_class, param_space):\n","                        params = {}\n","                        for key, values in param_space.items():\n","                            if isinstance(values, list):\n","                                params[key] = trial.suggest_categorical(key, values)\n","                            elif isinstance(values, tuple):\n","                                if len(values) == 2:\n","                                    params[key] = trial.suggest_float(key, values[0], values[1])\n","                                elif len(values) == 3 and isinstance(values[2], bool) and values[2]:\n","                                    params[key] = trial.suggest_int(key, values[0], values[1])\n","                                else:\n","                                    raise ValueError(f\"Invalid parameter range for {key}\")\n","\n","                        model = model_class(**params)\n","                        model.fit(X_train, y_train)\n","                        y_pred = model.predict(X_test)\n","                        mse = mean_squared_error(y_test, y_pred)\n","                        return mse\n","\n","                    study.optimize(lambda trial: objective(trial, model_name, model_class, param_space), n_trials=50)\n","\n","                best_params = study.best_params\n","                best_model = model_class(**best_params) if model_name != 'PGBM' else PGBM()\n","                if model_name == 'PGBM':\n","                    best_model.train((X_train, y_train), objective=mseloss_objective, metric=rmseloss_metric, params=best_params)\n","                else:\n","                    best_model.fit(X_train, y_train)\n","                y_pred = best_model.predict(X_test)\n","\n","                mse = mean_squared_error(y_test, y_pred)\n","                rmse = np.sqrt(mse)\n","                corr_coef = np.corrcoef(y_test, y_pred)[0, 1]\n","\n","                # Save predictions to DataFrame\n","                predictions_df[f'{model_name}_{pruner_name}_Predicted'] = y_pred\n","\n","                best_scores[(model_name, pruner_name)] = {\n","                    'best_score': mse,\n","                    'best_params': best_params,\n","                    'test_mse': mse,\n","                    'test_rmse': rmse,\n","                    'test_corr_coef': corr_coef,\n","                    'pruner': pruner_name\n","                }\n","                print(f\"Best MSE for {model_name} with {pruner_name}: {mse} with params: {best_params}\")\n","                print(f\"Best RMSE for {model_name} with {pruner_name}: {rmse}\")\n","                print(f\"Correlation Coefficient for {model_name} with {pruner_name}: {corr_coef}\")\n","            except Exception as e:\n","                print(f\"Failed to run Optuna for {model_name} with {pruner_name}. Error: {e}\")\n","\n","    # Write predictions to Excel\n","    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a') as writer:\n","        predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n","\n","    if best_scores:\n","        best_model_name, best_pruner_name = min(best_scores, key=lambda k: best_scores[k]['test_mse'])\n","        best_model_info = best_scores[(best_model_name, best_pruner_name)]\n","        print(f\"\\nBest model on test data: {best_model_name} with {best_pruner_name}\")\n","        print(f\"Test MSE: {best_model_info['test_mse']}\")\n","        print(f\"Test RMSE: {best_model_info['test_rmse']}\")\n","        print(f\"Correlation Coefficient: {best_model_info['test_corr_coef']}\")\n","        print(f\"Best Parameters: {best_model_info['best_params']}\")\n","        print(f\"Pruner Used: {best_model_info['pruner']}\")\n","    else:\n","        print(\"No valid model configurations found.\")\n","\n","    return best_scores\n","\n","# Example usage\n","best_scores_autosampler = hyperparameter_tuning_all(X_train, y_train, X_test, y_test, \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/HyperParameter_Tuning/test.xlsx\")"],"metadata":{"id":"cuiOvohCUDm8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d1dc030-60d9-4231-de73-8913c97d5d41","executionInfo":{"status":"ok","timestamp":1746268591667,"user_tz":-330,"elapsed":4020189,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Running Optuna for Random Forest with MedianPruner...\n","Best MSE for Random Forest with MedianPruner: 0.11795962820512826 with params: {'n_estimators': 100, 'criterion': 'absolute_error', 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 'log2', 'max_leaf_nodes': 100, 'min_impurity_decrease': 0.0, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.0}\n","Best RMSE for Random Forest with MedianPruner: 0.3434525122999223\n","Correlation Coefficient for Random Forest with MedianPruner: 0.9522984425706565\n","Running Optuna for Random Forest with NopPruner...\n","Best MSE for Random Forest with NopPruner: 0.12337467665679205 with params: {'n_estimators': 200, 'criterion': 'squared_error', 'max_depth': 30, 'min_samples_split': 0.01, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 0.3, 'max_leaf_nodes': 50, 'min_impurity_decrease': 0.0, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.0}\n","Best RMSE for Random Forest with NopPruner: 0.3512473155154243\n","Correlation Coefficient for Random Forest with NopPruner: 0.947717133922788\n","Running Optuna for Random Forest with PatientPruner...\n","Best MSE for Random Forest with PatientPruner: 0.12400594306324769 with params: {'n_estimators': 500, 'criterion': 'friedman_mse', 'max_depth': 30, 'min_samples_split': 0.01, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 0.3, 'max_leaf_nodes': 200, 'min_impurity_decrease': 0.0, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.0}\n","Best RMSE for Random Forest with PatientPruner: 0.35214477571482966\n","Correlation Coefficient for Random Forest with PatientPruner: 0.9475381334576092\n","Running Optuna for Random Forest with PercentilePruner...\n","Best MSE for Random Forest with PercentilePruner: 0.12347172109059805 with params: {'n_estimators': 500, 'criterion': 'squared_error', 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 'log2', 'max_leaf_nodes': 200, 'min_impurity_decrease': 0.0, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.0}\n","Best RMSE for Random Forest with PercentilePruner: 0.3513854309595064\n","Correlation Coefficient for Random Forest with PercentilePruner: 0.9478099007435906\n","Running Optuna for Random Forest with SuccessiveHalvingPruner...\n","Best MSE for Random Forest with SuccessiveHalvingPruner: 0.15545241861963746 with params: {'n_estimators': 700, 'criterion': 'friedman_mse', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.01, 'max_features': 0.5, 'max_leaf_nodes': 200, 'min_impurity_decrease': 0.0, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.0}\n","Best RMSE for Random Forest with SuccessiveHalvingPruner: 0.39427454726324584\n","Correlation Coefficient for Random Forest with SuccessiveHalvingPruner: 0.9333474018537554\n","Running Optuna for Random Forest with HyperbandPruner...\n","Best MSE for Random Forest with HyperbandPruner: 0.13547401750844537 with params: {'n_estimators': 100, 'criterion': 'friedman_mse', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.01, 'max_features': 0.5, 'max_leaf_nodes': 200, 'min_impurity_decrease': 0.01, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.001}\n","Best RMSE for Random Forest with HyperbandPruner: 0.3680679522974601\n","Correlation Coefficient for Random Forest with HyperbandPruner: 0.9413267703115014\n","Running Optuna for Random Forest with ThresholdPruner...\n","Best MSE for Random Forest with ThresholdPruner: 0.14608459691483422 with params: {'n_estimators': 200, 'criterion': 'friedman_mse', 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.01, 'max_features': 0.5, 'max_leaf_nodes': 50, 'min_impurity_decrease': 0.01, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.0}\n","Best RMSE for Random Forest with ThresholdPruner: 0.3822101475822355\n","Correlation Coefficient for Random Forest with ThresholdPruner: 0.9377441169295209\n","Running Optuna for Random Forest with WilcoxonPruner...\n","Best MSE for Random Forest with WilcoxonPruner: 0.11646959476999029 with params: {'n_estimators': 100, 'criterion': 'friedman_mse', 'max_depth': 40, 'min_samples_split': 0.01, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 0.5, 'max_leaf_nodes': 100, 'min_impurity_decrease': 0.1, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.001}\n","Best RMSE for Random Forest with WilcoxonPruner: 0.34127641988568486\n","Correlation Coefficient for Random Forest with WilcoxonPruner: 0.9483822442439112\n","Running Optuna for Gradient Boosting with MedianPruner...\n","Best MSE for Gradient Boosting with MedianPruner: 0.10596035268056564 with params: {'loss': 'squared_error', 'learning_rate': 0.2, 'n_estimators': 200, 'subsample': 1.0, 'criterion': 'squared_error', 'min_samples_split': 0.01, 'min_samples_leaf': 0.01, 'min_weight_fraction_leaf': 0.01, 'max_depth': 7, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': None, 'alpha': 0.9, 'verbose': 0, 'max_leaf_nodes': 50, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'tol': 0.001, 'ccp_alpha': 0.0}\n","Best RMSE for Gradient Boosting with MedianPruner: 0.3255155183406248\n","Correlation Coefficient for Gradient Boosting with MedianPruner: 0.9531771509079551\n","Running Optuna for Gradient Boosting with NopPruner...\n","Best MSE for Gradient Boosting with NopPruner: 0.09092491782126226 with params: {'loss': 'squared_error', 'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.9, 'criterion': 'friedman_mse', 'min_samples_split': 0.01, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.01, 'max_depth': 5, 'min_impurity_decrease': 0.01, 'init': None, 'random_state': 42, 'max_features': 'sqrt', 'alpha': 0.9, 'verbose': 0, 'max_leaf_nodes': 30, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 20, 'tol': 0.0001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with NopPruner: 0.3015375894001646\n","Correlation Coefficient for Gradient Boosting with NopPruner: 0.9591644441671107\n","Running Optuna for Gradient Boosting with PatientPruner...\n","Best MSE for Gradient Boosting with PatientPruner: 0.132559903174519 with params: {'loss': 'absolute_error', 'learning_rate': 0.2, 'n_estimators': 100, 'subsample': 1.0, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 0.01, 'min_weight_fraction_leaf': 0.0, 'max_depth': 7, 'min_impurity_decrease': 0.01, 'init': None, 'random_state': 42, 'max_features': 'log2', 'alpha': 0.9, 'verbose': 0, 'max_leaf_nodes': None, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 20, 'tol': 0.001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with PatientPruner: 0.36408776850440744\n","Correlation Coefficient for Gradient Boosting with PatientPruner: 0.9400804032538103\n","Running Optuna for Gradient Boosting with PercentilePruner...\n","Best MSE for Gradient Boosting with PercentilePruner: 0.09343437955546878 with params: {'loss': 'squared_error', 'learning_rate': 0.2, 'n_estimators': 200, 'subsample': 0.9, 'criterion': 'squared_error', 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_depth': 5, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': 'log2', 'alpha': 0.5, 'verbose': 0, 'max_leaf_nodes': 30, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'tol': 0.001, 'ccp_alpha': 0.0}\n","Best RMSE for Gradient Boosting with PercentilePruner: 0.3056703772946747\n","Correlation Coefficient for Gradient Boosting with PercentilePruner: 0.9570270978772224\n","Running Optuna for Gradient Boosting with SuccessiveHalvingPruner...\n","Best MSE for Gradient Boosting with SuccessiveHalvingPruner: 0.09324863155240691 with params: {'loss': 'squared_error', 'learning_rate': 0.1, 'n_estimators': 500, 'subsample': 0.9, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.01, 'max_depth': 5, 'min_impurity_decrease': 0.1, 'init': None, 'random_state': 42, 'max_features': 0.5, 'alpha': 0.9, 'verbose': 0, 'max_leaf_nodes': None, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 20, 'tol': 0.001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with SuccessiveHalvingPruner: 0.305366389035216\n","Correlation Coefficient for Gradient Boosting with SuccessiveHalvingPruner: 0.958191410403308\n","Running Optuna for Gradient Boosting with HyperbandPruner...\n","Best MSE for Gradient Boosting with HyperbandPruner: 0.12057594312974565 with params: {'loss': 'squared_error', 'learning_rate': 0.05, 'n_estimators': 700, 'subsample': 0.5, 'criterion': 'friedman_mse', 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.01, 'max_depth': 7, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': 0.5, 'alpha': 0.1, 'verbose': 0, 'max_leaf_nodes': 10, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': None, 'tol': 0.001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with HyperbandPruner: 0.34724046873851794\n","Correlation Coefficient for Gradient Boosting with HyperbandPruner: 0.94468016076508\n","Running Optuna for Gradient Boosting with ThresholdPruner...\n","Best MSE for Gradient Boosting with ThresholdPruner: 0.1055538748788425 with params: {'loss': 'squared_error', 'learning_rate': 0.2, 'n_estimators': 100, 'subsample': 0.9, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 0.01, 'min_weight_fraction_leaf': 0.01, 'max_depth': 10, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': 'sqrt', 'alpha': 0.1, 'verbose': 0, 'max_leaf_nodes': 50, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'tol': 0.001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with ThresholdPruner: 0.324890558309783\n","Correlation Coefficient for Gradient Boosting with ThresholdPruner: 0.9525689662324699\n","Running Optuna for Gradient Boosting with WilcoxonPruner...\n","Best MSE for Gradient Boosting with WilcoxonPruner: 0.13197016823417743 with params: {'loss': 'absolute_error', 'learning_rate': 0.05, 'n_estimators': 300, 'subsample': 0.7, 'criterion': 'friedman_mse', 'min_samples_split': 0.01, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.01, 'max_depth': 7, 'min_impurity_decrease': 0.01, 'init': None, 'random_state': 42, 'max_features': 0.5, 'alpha': 0.1, 'verbose': 0, 'max_leaf_nodes': 30, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': None, 'tol': 0.0001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with WilcoxonPruner: 0.36327698555534377\n","Correlation Coefficient for Gradient Boosting with WilcoxonPruner: 0.9415931294299945\n","Running Optuna for XGBoost with MedianPruner...\n","Best MSE for XGBoost with MedianPruner: 0.0898705681968317 with params: {'n_estimators': 200, 'learning_rate': 0.15, 'max_depth': 7, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with MedianPruner: 0.2997842027139384\n","Correlation Coefficient for XGBoost with MedianPruner: 0.9594189532708957\n","Running Optuna for XGBoost with NopPruner...\n","Best MSE for XGBoost with NopPruner: 0.10599083202474795 with params: {'n_estimators': 200, 'learning_rate': 0.15, 'max_depth': 5, 'min_child_weight': 5, 'gamma': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.5, 'reg_alpha': 1, 'reg_lambda': 5, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with NopPruner: 0.32556233201147206\n","Correlation Coefficient for XGBoost with NopPruner: 0.9532795599622089\n","Running Optuna for XGBoost with PatientPruner...\n","Best MSE for XGBoost with PatientPruner: 0.12245313501106483 with params: {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with PatientPruner: 0.3499330436112955\n","Correlation Coefficient for XGBoost with PatientPruner: 0.9433938208785971\n","Running Optuna for XGBoost with PercentilePruner...\n","Best MSE for XGBoost with PercentilePruner: 0.1018908667230901 with params: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 1, 'gamma': 0, 'subsample': 0.5, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.7, 'reg_alpha': 0, 'reg_lambda': 0.1, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with PercentilePruner: 0.3192034879557084\n","Correlation Coefficient for XGBoost with PercentilePruner: 0.953708845404612\n","Running Optuna for XGBoost with SuccessiveHalvingPruner...\n","Best MSE for XGBoost with SuccessiveHalvingPruner: 0.08218333690994077 with params: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 7, 'min_child_weight': 1, 'gamma': 0, 'subsample': 0.5, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.7, 'reg_alpha': 0.01, 'reg_lambda': 0.1, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with SuccessiveHalvingPruner: 0.28667636266344104\n","Correlation Coefficient for XGBoost with SuccessiveHalvingPruner: 0.9630434798497448\n","Running Optuna for XGBoost with HyperbandPruner...\n","Best MSE for XGBoost with HyperbandPruner: 0.10063554832884712 with params: {'n_estimators': 100, 'learning_rate': 0.15, 'max_depth': 7, 'min_child_weight': 1, 'gamma': 0, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.5, 'reg_alpha': 0, 'reg_lambda': 1, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with HyperbandPruner: 0.31723106457099554\n","Correlation Coefficient for XGBoost with HyperbandPruner: 0.9535886104929195\n","Running Optuna for XGBoost with ThresholdPruner...\n","Best MSE for XGBoost with ThresholdPruner: 0.10787578291600165 with params: {'n_estimators': 400, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0, 'subsample': 0.8, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.5, 'reg_alpha': 0, 'reg_lambda': 1, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with ThresholdPruner: 0.3284444898548332\n","Correlation Coefficient for XGBoost with ThresholdPruner: 0.9536947891782032\n","Running Optuna for XGBoost with WilcoxonPruner...\n","Best MSE for XGBoost with WilcoxonPruner: 0.10272987541052153 with params: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 1, 'gamma': 0, 'subsample': 0.9, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.5, 'reg_alpha': 0, 'reg_lambda': 0.1, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with WilcoxonPruner: 0.32051501588930514\n","Correlation Coefficient for XGBoost with WilcoxonPruner: 0.9528817104164768\n","Running Optuna for LightGBM with MedianPruner...\n","Best MSE for LightGBM with MedianPruner: 0.08510702468210275 with params: {'n_estimators': 100, 'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 7, 'min_child_samples': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0, 'reg_lambda': 0.1, 'min_child_weight': 0.1, 'bagging_freq': 5, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with MedianPruner: 0.2917310828178971\n","Correlation Coefficient for LightGBM with MedianPruner: 0.9610640651363059\n","Running Optuna for LightGBM with NopPruner...\n","Best MSE for LightGBM with NopPruner: 0.09797286644562232 with params: {'n_estimators': 300, 'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 3, 'min_child_samples': 1, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 1, 'min_child_weight': 0.01, 'bagging_freq': 0, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with NopPruner: 0.313006176369768\n","Correlation Coefficient for LightGBM with NopPruner: 0.955388850374431\n","Running Optuna for LightGBM with PatientPruner...\n","Best MSE for LightGBM with PatientPruner: 0.08620134294019038 with params: {'n_estimators': 100, 'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_child_samples': 1, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'min_child_weight': 1e-05, 'bagging_freq': 5, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with PatientPruner: 0.2936006521453765\n","Correlation Coefficient for LightGBM with PatientPruner: 0.9611118650021173\n","Running Optuna for LightGBM with PercentilePruner...\n","Best MSE for LightGBM with PercentilePruner: 0.09138899576548488 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 5, 'min_child_samples': 1, 'subsample': 1.0, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0, 'min_child_weight': 0.1, 'bagging_freq': 0, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with PercentilePruner: 0.3023061292224901\n","Correlation Coefficient for LightGBM with PercentilePruner: 0.9580295441872354\n","Running Optuna for LightGBM with SuccessiveHalvingPruner...\n","Best MSE for LightGBM with SuccessiveHalvingPruner: 0.08318288231943329 with params: {'n_estimators': 200, 'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 7, 'min_child_samples': 1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.01, 'reg_lambda': 0, 'min_child_weight': 1e-05, 'bagging_freq': 1, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with SuccessiveHalvingPruner: 0.28841442807084616\n","Correlation Coefficient for LightGBM with SuccessiveHalvingPruner: 0.961997957666191\n","Running Optuna for LightGBM with HyperbandPruner...\n","Best MSE for LightGBM with HyperbandPruner: 0.08551885335198639 with params: {'n_estimators': 200, 'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_child_samples': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0, 'min_child_weight': 0.01, 'bagging_freq': 1, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with HyperbandPruner: 0.2924360671189284\n","Correlation Coefficient for LightGBM with HyperbandPruner: 0.9613405547497119\n","Running Optuna for LightGBM with ThresholdPruner...\n","Best MSE for LightGBM with ThresholdPruner: 0.09005684150695638 with params: {'n_estimators': 100, 'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_child_samples': 1, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.1, 'reg_lambda': 0, 'min_child_weight': 0.001, 'bagging_freq': 1, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with ThresholdPruner: 0.3000947208915151\n","Correlation Coefficient for LightGBM with ThresholdPruner: 0.9586824287835334\n","Running Optuna for LightGBM with WilcoxonPruner...\n","Best MSE for LightGBM with WilcoxonPruner: 0.09291600232378894 with params: {'n_estimators': 100, 'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_child_samples': 1, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.01, 'reg_lambda': 0.1, 'min_child_weight': 0.001, 'bagging_freq': 0, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with WilcoxonPruner: 0.30482126291285677\n","Correlation Coefficient for LightGBM with WilcoxonPruner: 0.9577137271606543\n","Running Optuna for GPBoost with MedianPruner...\n","Best MSE for GPBoost with MedianPruner: 0.10013123794553873 with params: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': -1, 'num_leaves': 15, 'min_child_samples': 1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'min_child_weight': 1e-05, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with MedianPruner: 0.3164352033916876\n","Correlation Coefficient for GPBoost with MedianPruner: 0.9540221235653149\n","Running Optuna for GPBoost with NopPruner...\n","Best MSE for GPBoost with NopPruner: 0.1036340627359684 with params: {'n_estimators': 200, 'learning_rate': 0.15, 'max_depth': 3, 'num_leaves': 15, 'min_child_samples': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 1.0, 'reg_lambda': 0.1, 'min_child_weight': 0.01, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with NopPruner: 0.3219224483256307\n","Correlation Coefficient for GPBoost with NopPruner: 0.9525582574157486\n","Running Optuna for GPBoost with PatientPruner...\n","Best MSE for GPBoost with PatientPruner: 0.0936923020400716 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 7, 'num_leaves': 63, 'min_child_samples': 1, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 0, 'reg_lambda': 0.1, 'min_child_weight': 0.1, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with PatientPruner: 0.30609198297255613\n","Correlation Coefficient for GPBoost with PatientPruner: 0.9569897018244895\n","Running Optuna for GPBoost with PercentilePruner...\n","Best MSE for GPBoost with PercentilePruner: 0.09823357699600549 with params: {'n_estimators': 200, 'learning_rate': 0.15, 'max_depth': 3, 'num_leaves': 15, 'min_child_samples': 1, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'min_child_weight': 0.01, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with PercentilePruner: 0.31342236199098095\n","Correlation Coefficient for GPBoost with PercentilePruner: 0.9556105168749771\n","Running Optuna for GPBoost with SuccessiveHalvingPruner...\n","Best MSE for GPBoost with SuccessiveHalvingPruner: 0.09902817795971754 with params: {'n_estimators': 400, 'learning_rate': 0.01, 'max_depth': 7, 'num_leaves': 63, 'min_child_samples': 1, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.1, 'reg_lambda': 0, 'min_child_weight': 1e-05, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with SuccessiveHalvingPruner: 0.31468742898266133\n","Correlation Coefficient for GPBoost with SuccessiveHalvingPruner: 0.9546589186328368\n","Running Optuna for GPBoost with HyperbandPruner...\n","Best MSE for GPBoost with HyperbandPruner: 0.09973817655873879 with params: {'n_estimators': 400, 'learning_rate': 0.1, 'max_depth': 3, 'num_leaves': 63, 'min_child_samples': 1, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'min_child_weight': 0.01, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with HyperbandPruner: 0.3158135154782626\n","Correlation Coefficient for GPBoost with HyperbandPruner: 0.9545961643114624\n","Running Optuna for GPBoost with ThresholdPruner...\n","Best MSE for GPBoost with ThresholdPruner: 0.09878181048966037 with params: {'n_estimators': 400, 'learning_rate': 0.1, 'max_depth': 3, 'num_leaves': 31, 'min_child_samples': 1, 'subsample': 1.0, 'colsample_bytree': 0.7, 'reg_alpha': 0, 'reg_lambda': 0.5, 'min_child_weight': 0.1, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with ThresholdPruner: 0.31429573730749255\n","Correlation Coefficient for GPBoost with ThresholdPruner: 0.9552029073187112\n","Running Optuna for GPBoost with WilcoxonPruner...\n","Best MSE for GPBoost with WilcoxonPruner: 0.0987853693895994 with params: {'n_estimators': 100, 'learning_rate': 0.15, 'max_depth': 3, 'num_leaves': 31, 'min_child_samples': 1, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'min_child_weight': 0.001, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with WilcoxonPruner: 0.3143013989622054\n","Correlation Coefficient for GPBoost with WilcoxonPruner: 0.9545465834260042\n","Running Optuna for CatBoost with MedianPruner...\n","Best MSE for CatBoost with MedianPruner: 0.10106934356001397 with params: {'iterations': 200, 'learning_rate': 0.05, 'depth': 10, 'l2_leaf_reg': 1, 'border_count': 32, 'min_data_in_leaf': 1, 'rsm': 0.6, 'bagging_temperature': 1, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with MedianPruner: 0.3179140505860255\n","Correlation Coefficient for CatBoost with MedianPruner: 0.9546386164786963\n","Running Optuna for CatBoost with NopPruner...\n","Best MSE for CatBoost with NopPruner: 0.10208631062341576 with params: {'iterations': 200, 'learning_rate': 0.1, 'depth': 10, 'l2_leaf_reg': 5, 'border_count': 32, 'min_data_in_leaf': 1, 'rsm': 0.6, 'bagging_temperature': 1, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with NopPruner: 0.3195094844029137\n","Correlation Coefficient for CatBoost with NopPruner: 0.9536489292255467\n","Running Optuna for CatBoost with PatientPruner...\n","Best MSE for CatBoost with PatientPruner: 0.1003834647979198 with params: {'iterations': 200, 'learning_rate': 0.1, 'depth': 8, 'l2_leaf_reg': 9, 'border_count': 32, 'min_data_in_leaf': 1, 'rsm': 0.6, 'bagging_temperature': 1, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with PatientPruner: 0.3168334969631838\n","Correlation Coefficient for CatBoost with PatientPruner: 0.9548895428536669\n","Running Optuna for CatBoost with PercentilePruner...\n","Best MSE for CatBoost with PercentilePruner: 0.10305473754773768 with params: {'iterations': 1000, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 9, 'border_count': 32, 'min_data_in_leaf': 20, 'rsm': 0.6, 'bagging_temperature': 1, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with PercentilePruner: 0.3210213973362799\n","Correlation Coefficient for CatBoost with PercentilePruner: 0.9525240172898933\n","Running Optuna for CatBoost with SuccessiveHalvingPruner...\n","Best MSE for CatBoost with SuccessiveHalvingPruner: 0.1003834647979198 with params: {'iterations': 200, 'learning_rate': 0.1, 'depth': 8, 'l2_leaf_reg': 9, 'border_count': 32, 'min_data_in_leaf': 20, 'rsm': 0.6, 'bagging_temperature': 1, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with SuccessiveHalvingPruner: 0.3168334969631838\n","Correlation Coefficient for CatBoost with SuccessiveHalvingPruner: 0.9548895428536669\n","Running Optuna for CatBoost with HyperbandPruner...\n","Best MSE for CatBoost with HyperbandPruner: 0.10146578295486733 with params: {'iterations': 1000, 'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 7, 'border_count': 32, 'min_data_in_leaf': 20, 'rsm': 0.6, 'bagging_temperature': 10, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with HyperbandPruner: 0.31853694127191484\n","Correlation Coefficient for CatBoost with HyperbandPruner: 0.9532680684984001\n","Running Optuna for CatBoost with ThresholdPruner...\n","Best MSE for CatBoost with ThresholdPruner: 0.09767295423337319 with params: {'iterations': 200, 'learning_rate': 0.05, 'depth': 8, 'l2_leaf_reg': 3, 'border_count': 32, 'min_data_in_leaf': 1, 'rsm': 0.6, 'bagging_temperature': 1, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with ThresholdPruner: 0.31252672563058215\n","Correlation Coefficient for CatBoost with ThresholdPruner: 0.9555811756306276\n","Running Optuna for CatBoost with WilcoxonPruner...\n","Best MSE for CatBoost with WilcoxonPruner: 0.10301394884876003 with params: {'iterations': 1000, 'learning_rate': 0.03, 'depth': 10, 'l2_leaf_reg': 1, 'border_count': 32, 'min_data_in_leaf': 20, 'rsm': 0.6, 'bagging_temperature': 10, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with WilcoxonPruner: 0.3209578614845881\n","Correlation Coefficient for CatBoost with WilcoxonPruner: 0.9533780849549102\n","Running Optuna for NGBoost with MedianPruner...\n","Best MSE for NGBoost with MedianPruner: 0.1152894704292283 with params: {'n_estimators': 500, 'learning_rate': 0.1, 'natural_gradient': True, 'minibatch_frac': 0.7, 'col_sample': 0.7, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with MedianPruner: 0.3395430317783422\n","Correlation Coefficient for NGBoost with MedianPruner: 0.94829948182159\n","Running Optuna for NGBoost with NopPruner...\n","Best MSE for NGBoost with NopPruner: 0.1053248721899002 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'natural_gradient': True, 'minibatch_frac': 0.9, 'col_sample': 0.5, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with NopPruner: 0.3245379364417975\n","Correlation Coefficient for NGBoost with NopPruner: 0.9515051422827133\n","Running Optuna for NGBoost with PatientPruner...\n","Best MSE for NGBoost with PatientPruner: 0.10814930538358006 with params: {'n_estimators': 200, 'learning_rate': 0.03, 'natural_gradient': True, 'minibatch_frac': 0.9, 'col_sample': 0.5, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with PatientPruner: 0.32886061695432617\n","Correlation Coefficient for NGBoost with PatientPruner: 0.9502270469565367\n","Running Optuna for NGBoost with PercentilePruner...\n","Best MSE for NGBoost with PercentilePruner: 0.11056190619997897 with params: {'n_estimators': 200, 'learning_rate': 0.05, 'natural_gradient': True, 'minibatch_frac': 0.7, 'col_sample': 0.5, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with PercentilePruner: 0.33250850545509203\n","Correlation Coefficient for NGBoost with PercentilePruner: 0.9491964948699997\n","Running Optuna for NGBoost with SuccessiveHalvingPruner...\n","Best MSE for NGBoost with SuccessiveHalvingPruner: 0.09867440584340595 with params: {'n_estimators': 500, 'learning_rate': 0.1, 'natural_gradient': True, 'minibatch_frac': 0.7, 'col_sample': 0.7, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with SuccessiveHalvingPruner: 0.31412482525805874\n","Correlation Coefficient for NGBoost with SuccessiveHalvingPruner: 0.9555069328657247\n","Running Optuna for NGBoost with HyperbandPruner...\n","Best MSE for NGBoost with HyperbandPruner: 0.09920488951527161 with params: {'n_estimators': 200, 'learning_rate': 0.1, 'natural_gradient': True, 'minibatch_frac': 0.7, 'col_sample': 0.7, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with HyperbandPruner: 0.314968076978083\n","Correlation Coefficient for NGBoost with HyperbandPruner: 0.955324861950893\n","Running Optuna for NGBoost with ThresholdPruner...\n","Best MSE for NGBoost with ThresholdPruner: 0.10398453727198938 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'natural_gradient': True, 'minibatch_frac': 0.9, 'col_sample': 0.5, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with ThresholdPruner: 0.32246633509870354\n","Correlation Coefficient for NGBoost with ThresholdPruner: 0.9521192503088859\n","Running Optuna for NGBoost with WilcoxonPruner...\n","Best MSE for NGBoost with WilcoxonPruner: 0.11995572624494273 with params: {'n_estimators': 500, 'learning_rate': 0.1, 'natural_gradient': True, 'minibatch_frac': 0.7, 'col_sample': 0.7, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with WilcoxonPruner: 0.34634625195740565\n","Correlation Coefficient for NGBoost with WilcoxonPruner: 0.9448380125317961\n","Running Optuna for HistGradientBoosting with MedianPruner...\n","Best MSE for HistGradientBoosting with MedianPruner: 0.12180860652701989 with params: {'learning_rate': 0.15, 'max_iter': 100, 'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 31, 'l2_regularization': 0.1, 'max_bins': 64, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 5, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with MedianPruner: 0.34901089743304564\n","Correlation Coefficient for HistGradientBoosting with MedianPruner: 0.9435922436271997\n","Running Optuna for HistGradientBoosting with NopPruner...\n","Best MSE for HistGradientBoosting with NopPruner: 0.13828861645367616 with params: {'learning_rate': 0.15, 'max_iter': 500, 'max_depth': 3, 'min_samples_leaf': 5, 'max_leaf_nodes': 31, 'l2_regularization': 0.1, 'max_bins': 64, 'early_stopping': True, 'validation_fraction': 0.2, 'n_iter_no_change': 10, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with NopPruner: 0.37187177420943923\n","Correlation Coefficient for HistGradientBoosting with NopPruner: 0.9383213746817468\n","Running Optuna for HistGradientBoosting with PatientPruner...\n","Best MSE for HistGradientBoosting with PatientPruner: 0.1264288808167698 with params: {'learning_rate': 0.1, 'max_iter': 100, 'max_depth': 3, 'min_samples_leaf': 5, 'max_leaf_nodes': 31, 'l2_regularization': 1.0, 'max_bins': 64, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with PatientPruner: 0.35556839119467554\n","Correlation Coefficient for HistGradientBoosting with PatientPruner: 0.9412981893132774\n","Running Optuna for HistGradientBoosting with PercentilePruner...\n","Best MSE for HistGradientBoosting with PercentilePruner: 0.12530530053567965 with params: {'learning_rate': 0.15, 'max_iter': 400, 'max_depth': 3, 'min_samples_leaf': 5, 'max_leaf_nodes': 15, 'l2_regularization': 0.1, 'max_bins': 64, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 15, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with PercentilePruner: 0.3539848874396754\n","Correlation Coefficient for HistGradientBoosting with PercentilePruner: 0.9419192007539792\n","Running Optuna for HistGradientBoosting with SuccessiveHalvingPruner...\n","Best MSE for HistGradientBoosting with SuccessiveHalvingPruner: 0.12672316359882632 with params: {'learning_rate': 0.1, 'max_iter': 100, 'max_depth': 3, 'min_samples_leaf': 5, 'max_leaf_nodes': None, 'l2_regularization': 0.0, 'max_bins': 64, 'early_stopping': True, 'validation_fraction': 0.2, 'n_iter_no_change': 15, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with SuccessiveHalvingPruner: 0.35598197089013695\n","Correlation Coefficient for HistGradientBoosting with SuccessiveHalvingPruner: 0.9424579886786292\n","Running Optuna for HistGradientBoosting with HyperbandPruner...\n","Best MSE for HistGradientBoosting with HyperbandPruner: 0.12097258218439053 with params: {'learning_rate': 0.15, 'max_iter': 500, 'max_depth': 5, 'min_samples_leaf': 5, 'max_leaf_nodes': 15, 'l2_regularization': 0.0, 'max_bins': 64, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with HyperbandPruner: 0.34781113004674036\n","Correlation Coefficient for HistGradientBoosting with HyperbandPruner: 0.9438746742321596\n","Running Optuna for HistGradientBoosting with ThresholdPruner...\n","Best MSE for HistGradientBoosting with ThresholdPruner: 0.13941846187656182 with params: {'learning_rate': 0.1, 'max_iter': 400, 'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 31, 'l2_regularization': 0.5, 'max_bins': 64, 'early_stopping': True, 'validation_fraction': 0.2, 'n_iter_no_change': 15, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with ThresholdPruner: 0.37338781699000545\n","Correlation Coefficient for HistGradientBoosting with ThresholdPruner: 0.937127149302789\n","Running Optuna for HistGradientBoosting with WilcoxonPruner...\n","Best MSE for HistGradientBoosting with WilcoxonPruner: 0.1155150567364688 with params: {'learning_rate': 0.1, 'max_iter': 400, 'max_depth': 3, 'min_samples_leaf': 5, 'max_leaf_nodes': 63, 'l2_regularization': 1.0, 'max_bins': 64, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 15, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with WilcoxonPruner: 0.3398750604802724\n","Correlation Coefficient for HistGradientBoosting with WilcoxonPruner: 0.9469491597776423\n","Running Optuna for PGBM with MedianPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/500, Train metric: 1.2152\n","Estimator 1/500, Train metric: 1.1683\n","Estimator 2/500, Train metric: 1.1249\n","Estimator 3/500, Train metric: 1.0798\n","Estimator 4/500, Train metric: 1.0346\n","Estimator 5/500, Train metric: 0.9933\n","Estimator 6/500, Train metric: 0.9538\n","Estimator 7/500, Train metric: 0.9181\n","Estimator 8/500, Train metric: 0.8834\n","Estimator 9/500, Train metric: 0.8531\n","Estimator 10/500, Train metric: 0.8167\n","Estimator 11/500, Train metric: 0.7995\n","Estimator 12/500, Train metric: 0.7756\n","Estimator 13/500, Train metric: 0.7471\n","Estimator 14/500, Train metric: 0.7208\n","Estimator 15/500, Train metric: 0.6957\n","Estimator 16/500, Train metric: 0.6749\n","Estimator 17/500, Train metric: 0.6500\n","Estimator 18/500, Train metric: 0.6323\n","Estimator 19/500, Train metric: 0.6159\n","Estimator 20/500, Train metric: 0.5970\n","Estimator 21/500, Train metric: 0.5769\n","Estimator 22/500, Train metric: 0.5634\n","Estimator 23/500, Train metric: 0.5487\n","Estimator 24/500, Train metric: 0.5337\n","Estimator 25/500, Train metric: 0.5166\n","Estimator 26/500, Train metric: 0.5064\n","Estimator 27/500, Train metric: 0.4926\n","Estimator 28/500, Train metric: 0.4806\n","Estimator 29/500, Train metric: 0.4694\n","Estimator 30/500, Train metric: 0.4657\n","Estimator 31/500, Train metric: 0.4567\n","Estimator 32/500, Train metric: 0.4469\n","Estimator 33/500, Train metric: 0.4400\n","Estimator 34/500, Train metric: 0.4307\n","Estimator 35/500, Train metric: 0.4224\n","Estimator 36/500, Train metric: 0.4137\n","Estimator 37/500, Train metric: 0.4071\n","Estimator 38/500, Train metric: 0.3983\n","Estimator 39/500, Train metric: 0.3912\n","Estimator 40/500, Train metric: 0.3832\n","Estimator 41/500, Train metric: 0.3766\n","Estimator 42/500, Train metric: 0.3712\n","Estimator 43/500, Train metric: 0.3654\n","Estimator 44/500, Train metric: 0.3620\n","Estimator 45/500, Train metric: 0.3584\n","Estimator 46/500, Train metric: 0.3555\n","Estimator 47/500, Train metric: 0.3496\n","Estimator 48/500, Train metric: 0.3465\n","Estimator 49/500, Train metric: 0.3446\n","Estimator 50/500, Train metric: 0.3414\n","Estimator 51/500, Train metric: 0.3353\n","Estimator 52/500, Train metric: 0.3304\n","Estimator 53/500, Train metric: 0.3262\n","Estimator 54/500, Train metric: 0.3202\n","Estimator 55/500, Train metric: 0.3166\n","Estimator 56/500, Train metric: 0.3123\n","Estimator 57/500, Train metric: 0.3078\n","Estimator 58/500, Train metric: 0.3049\n","Estimator 59/500, Train metric: 0.3039\n","Estimator 60/500, Train metric: 0.3002\n","Estimator 61/500, Train metric: 0.2972\n","Estimator 62/500, Train metric: 0.2957\n","Estimator 63/500, Train metric: 0.2916\n","Estimator 64/500, Train metric: 0.2888\n","Estimator 65/500, Train metric: 0.2861\n","Estimator 66/500, Train metric: 0.2851\n","Estimator 67/500, Train metric: 0.2838\n","Estimator 68/500, Train metric: 0.2825\n","Estimator 69/500, Train metric: 0.2801\n","Estimator 70/500, Train metric: 0.2789\n","Estimator 71/500, Train metric: 0.2768\n","Estimator 72/500, Train metric: 0.2742\n","Estimator 73/500, Train metric: 0.2725\n","Estimator 74/500, Train metric: 0.2704\n","Estimator 75/500, Train metric: 0.2688\n","Estimator 76/500, Train metric: 0.2662\n","Estimator 77/500, Train metric: 0.2650\n","Estimator 78/500, Train metric: 0.2636\n","Estimator 79/500, Train metric: 0.2618\n","Estimator 80/500, Train metric: 0.2600\n","Estimator 81/500, Train metric: 0.2586\n","Estimator 82/500, Train metric: 0.2561\n","Estimator 83/500, Train metric: 0.2545\n","Estimator 84/500, Train metric: 0.2524\n","Estimator 85/500, Train metric: 0.2508\n","Estimator 86/500, Train metric: 0.2489\n","Estimator 87/500, Train metric: 0.2477\n","Estimator 88/500, Train metric: 0.2471\n","Estimator 89/500, Train metric: 0.2451\n","Estimator 90/500, Train metric: 0.2447\n","Estimator 91/500, Train metric: 0.2429\n","Estimator 92/500, Train metric: 0.2403\n","Estimator 93/500, Train metric: 0.2384\n","Estimator 94/500, Train metric: 0.2374\n","Estimator 95/500, Train metric: 0.2360\n","Estimator 96/500, Train metric: 0.2330\n","Estimator 97/500, Train metric: 0.2315\n","Estimator 98/500, Train metric: 0.2293\n","Estimator 99/500, Train metric: 0.2253\n","Estimator 100/500, Train metric: 0.2233\n","Estimator 101/500, Train metric: 0.2227\n","Estimator 102/500, Train metric: 0.2210\n","Estimator 103/500, Train metric: 0.2194\n","Estimator 104/500, Train metric: 0.2171\n","Estimator 105/500, Train metric: 0.2159\n","Estimator 106/500, Train metric: 0.2158\n","Estimator 107/500, Train metric: 0.2133\n","Estimator 108/500, Train metric: 0.2116\n","Estimator 109/500, Train metric: 0.2101\n","Estimator 110/500, Train metric: 0.2090\n","Estimator 111/500, Train metric: 0.2066\n","Estimator 112/500, Train metric: 0.2052\n","Estimator 113/500, Train metric: 0.2033\n","Estimator 114/500, Train metric: 0.2019\n","Estimator 115/500, Train metric: 0.2003\n","Estimator 116/500, Train metric: 0.1986\n","Estimator 117/500, Train metric: 0.1975\n","Estimator 118/500, Train metric: 0.1966\n","Estimator 119/500, Train metric: 0.1962\n","Estimator 120/500, Train metric: 0.1942\n","Estimator 121/500, Train metric: 0.1931\n","Estimator 122/500, Train metric: 0.1923\n","Estimator 123/500, Train metric: 0.1905\n","Estimator 124/500, Train metric: 0.1900\n","Estimator 125/500, Train metric: 0.1893\n","Estimator 126/500, Train metric: 0.1883\n","Estimator 127/500, Train metric: 0.1877\n","Estimator 128/500, Train metric: 0.1852\n","Estimator 129/500, Train metric: 0.1845\n","Estimator 130/500, Train metric: 0.1840\n","Estimator 131/500, Train metric: 0.1825\n","Estimator 132/500, Train metric: 0.1819\n","Estimator 133/500, Train metric: 0.1814\n","Estimator 134/500, Train metric: 0.1806\n","Estimator 135/500, Train metric: 0.1796\n","Estimator 136/500, Train metric: 0.1788\n","Estimator 137/500, Train metric: 0.1780\n","Estimator 138/500, Train metric: 0.1753\n","Estimator 139/500, Train metric: 0.1732\n","Estimator 140/500, Train metric: 0.1719\n","Estimator 141/500, Train metric: 0.1694\n","Estimator 142/500, Train metric: 0.1675\n","Estimator 143/500, Train metric: 0.1666\n","Estimator 144/500, Train metric: 0.1658\n","Estimator 145/500, Train metric: 0.1653\n","Estimator 146/500, Train metric: 0.1644\n","Estimator 147/500, Train metric: 0.1636\n","Estimator 148/500, Train metric: 0.1632\n","Estimator 149/500, Train metric: 0.1624\n","Estimator 150/500, Train metric: 0.1619\n","Estimator 151/500, Train metric: 0.1616\n","Estimator 152/500, Train metric: 0.1601\n","Estimator 153/500, Train metric: 0.1592\n","Estimator 154/500, Train metric: 0.1583\n","Estimator 155/500, Train metric: 0.1562\n","Estimator 156/500, Train metric: 0.1549\n","Estimator 157/500, Train metric: 0.1538\n","Estimator 158/500, Train metric: 0.1524\n","Estimator 159/500, Train metric: 0.1518\n","Estimator 160/500, Train metric: 0.1507\n","Estimator 161/500, Train metric: 0.1498\n","Estimator 162/500, Train metric: 0.1483\n","Estimator 163/500, Train metric: 0.1479\n","Estimator 164/500, Train metric: 0.1480\n","Estimator 165/500, Train metric: 0.1473\n","Estimator 166/500, Train metric: 0.1466\n","Estimator 167/500, Train metric: 0.1463\n","Estimator 168/500, Train metric: 0.1461\n","Estimator 169/500, Train metric: 0.1457\n","Estimator 170/500, Train metric: 0.1455\n","Estimator 171/500, Train metric: 0.1445\n","Estimator 172/500, Train metric: 0.1435\n","Estimator 173/500, Train metric: 0.1426\n","Estimator 174/500, Train metric: 0.1421\n","Estimator 175/500, Train metric: 0.1408\n","Estimator 176/500, Train metric: 0.1396\n","Estimator 177/500, Train metric: 0.1386\n","Estimator 178/500, Train metric: 0.1385\n","Estimator 179/500, Train metric: 0.1384\n","Estimator 180/500, Train metric: 0.1372\n","Estimator 181/500, Train metric: 0.1366\n","Estimator 182/500, Train metric: 0.1356\n","Estimator 183/500, Train metric: 0.1354\n","Estimator 184/500, Train metric: 0.1344\n","Estimator 185/500, Train metric: 0.1340\n","Estimator 186/500, Train metric: 0.1331\n","Estimator 187/500, Train metric: 0.1321\n","Estimator 188/500, Train metric: 0.1312\n","Estimator 189/500, Train metric: 0.1307\n","Estimator 190/500, Train metric: 0.1300\n","Estimator 191/500, Train metric: 0.1290\n","Estimator 192/500, Train metric: 0.1284\n","Estimator 193/500, Train metric: 0.1277\n","Estimator 194/500, Train metric: 0.1271\n","Estimator 195/500, Train metric: 0.1259\n","Estimator 196/500, Train metric: 0.1248\n","Estimator 197/500, Train metric: 0.1245\n","Estimator 198/500, Train metric: 0.1236\n","Estimator 199/500, Train metric: 0.1226\n","Estimator 200/500, Train metric: 0.1220\n","Estimator 201/500, Train metric: 0.1210\n","Estimator 202/500, Train metric: 0.1204\n","Estimator 203/500, Train metric: 0.1194\n","Estimator 204/500, Train metric: 0.1192\n","Estimator 205/500, Train metric: 0.1185\n","Estimator 206/500, Train metric: 0.1176\n","Estimator 207/500, Train metric: 0.1171\n","Estimator 208/500, Train metric: 0.1168\n","Estimator 209/500, Train metric: 0.1162\n","Estimator 210/500, Train metric: 0.1157\n","Estimator 211/500, Train metric: 0.1149\n","Estimator 212/500, Train metric: 0.1145\n","Estimator 213/500, Train metric: 0.1144\n","Estimator 214/500, Train metric: 0.1138\n","Estimator 215/500, Train metric: 0.1134\n","Estimator 216/500, Train metric: 0.1129\n","Estimator 217/500, Train metric: 0.1122\n","Estimator 218/500, Train metric: 0.1109\n","Estimator 219/500, Train metric: 0.1102\n","Estimator 220/500, Train metric: 0.1093\n","Estimator 221/500, Train metric: 0.1088\n","Estimator 222/500, Train metric: 0.1080\n","Estimator 223/500, Train metric: 0.1078\n","Estimator 224/500, Train metric: 0.1077\n","Estimator 225/500, Train metric: 0.1073\n","Estimator 226/500, Train metric: 0.1068\n","Estimator 227/500, Train metric: 0.1066\n","Estimator 228/500, Train metric: 0.1062\n","Estimator 229/500, Train metric: 0.1053\n","Estimator 230/500, Train metric: 0.1044\n","Estimator 231/500, Train metric: 0.1041\n","Estimator 232/500, Train metric: 0.1039\n","Estimator 233/500, Train metric: 0.1035\n","Estimator 234/500, Train metric: 0.1029\n","Estimator 235/500, Train metric: 0.1020\n","Estimator 236/500, Train metric: 0.1016\n","Estimator 237/500, Train metric: 0.1007\n","Estimator 238/500, Train metric: 0.1003\n","Estimator 239/500, Train metric: 0.0995\n","Estimator 240/500, Train metric: 0.0987\n","Estimator 241/500, Train metric: 0.0980\n","Estimator 242/500, Train metric: 0.0971\n","Estimator 243/500, Train metric: 0.0966\n","Estimator 244/500, Train metric: 0.0959\n","Estimator 245/500, Train metric: 0.0952\n","Estimator 246/500, Train metric: 0.0946\n","Estimator 247/500, Train metric: 0.0941\n","Estimator 248/500, Train metric: 0.0939\n","Estimator 249/500, Train metric: 0.0935\n","Estimator 250/500, Train metric: 0.0930\n","Estimator 251/500, Train metric: 0.0923\n","Estimator 252/500, Train metric: 0.0919\n","Estimator 253/500, Train metric: 0.0917\n","Estimator 254/500, Train metric: 0.0915\n","Estimator 255/500, Train metric: 0.0912\n","Estimator 256/500, Train metric: 0.0908\n","Estimator 257/500, Train metric: 0.0902\n","Estimator 258/500, Train metric: 0.0894\n","Estimator 259/500, Train metric: 0.0892\n","Estimator 260/500, Train metric: 0.0887\n","Estimator 261/500, Train metric: 0.0883\n","Estimator 262/500, Train metric: 0.0877\n","Estimator 263/500, Train metric: 0.0875\n","Estimator 264/500, Train metric: 0.0874\n","Estimator 265/500, Train metric: 0.0868\n","Estimator 266/500, Train metric: 0.0865\n","Estimator 267/500, Train metric: 0.0862\n","Estimator 268/500, Train metric: 0.0859\n","Estimator 269/500, Train metric: 0.0857\n","Estimator 270/500, Train metric: 0.0853\n","Estimator 271/500, Train metric: 0.0848\n","Estimator 272/500, Train metric: 0.0845\n","Estimator 273/500, Train metric: 0.0842\n","Estimator 274/500, Train metric: 0.0839\n","Estimator 275/500, Train metric: 0.0840\n","Estimator 276/500, Train metric: 0.0834\n","Estimator 277/500, Train metric: 0.0832\n","Estimator 278/500, Train metric: 0.0830\n","Estimator 279/500, Train metric: 0.0828\n","Estimator 280/500, Train metric: 0.0827\n","Estimator 281/500, Train metric: 0.0827\n","Estimator 282/500, Train metric: 0.0822\n","Estimator 283/500, Train metric: 0.0819\n","Estimator 284/500, Train metric: 0.0815\n","Estimator 285/500, Train metric: 0.0812\n","Estimator 286/500, Train metric: 0.0807\n","Estimator 287/500, Train metric: 0.0802\n","Estimator 288/500, Train metric: 0.0798\n","Estimator 289/500, Train metric: 0.0796\n","Estimator 290/500, Train metric: 0.0794\n","Estimator 291/500, Train metric: 0.0791\n","Estimator 292/500, Train metric: 0.0784\n","Estimator 293/500, Train metric: 0.0779\n","Estimator 294/500, Train metric: 0.0776\n","Estimator 295/500, Train metric: 0.0774\n","Estimator 296/500, Train metric: 0.0769\n","Estimator 297/500, Train metric: 0.0763\n","Estimator 298/500, Train metric: 0.0761\n","Estimator 299/500, Train metric: 0.0756\n","Estimator 300/500, Train metric: 0.0756\n","Estimator 301/500, Train metric: 0.0754\n","Estimator 302/500, Train metric: 0.0748\n","Estimator 303/500, Train metric: 0.0748\n","Estimator 304/500, Train metric: 0.0745\n","Estimator 305/500, Train metric: 0.0744\n","Estimator 306/500, Train metric: 0.0740\n","Estimator 307/500, Train metric: 0.0738\n","Estimator 308/500, Train metric: 0.0736\n","Estimator 309/500, Train metric: 0.0733\n","Estimator 310/500, Train metric: 0.0732\n","Estimator 311/500, Train metric: 0.0727\n","Estimator 312/500, Train metric: 0.0727\n","Estimator 313/500, Train metric: 0.0725\n","Estimator 314/500, Train metric: 0.0723\n","Estimator 315/500, Train metric: 0.0721\n","Estimator 316/500, Train metric: 0.0719\n","Estimator 317/500, Train metric: 0.0715\n","Estimator 318/500, Train metric: 0.0713\n","Estimator 319/500, Train metric: 0.0709\n","Estimator 320/500, Train metric: 0.0705\n","Estimator 321/500, Train metric: 0.0701\n","Estimator 322/500, Train metric: 0.0700\n","Estimator 323/500, Train metric: 0.0696\n","Estimator 324/500, Train metric: 0.0695\n","Estimator 325/500, Train metric: 0.0692\n","Estimator 326/500, Train metric: 0.0686\n","Estimator 327/500, Train metric: 0.0684\n","Estimator 328/500, Train metric: 0.0680\n","Estimator 329/500, Train metric: 0.0678\n","Estimator 330/500, Train metric: 0.0674\n","Estimator 331/500, Train metric: 0.0672\n","Estimator 332/500, Train metric: 0.0670\n","Estimator 333/500, Train metric: 0.0667\n","Estimator 334/500, Train metric: 0.0666\n","Estimator 335/500, Train metric: 0.0664\n","Estimator 336/500, Train metric: 0.0663\n","Estimator 337/500, Train metric: 0.0656\n","Estimator 338/500, Train metric: 0.0654\n","Estimator 339/500, Train metric: 0.0650\n","Estimator 340/500, Train metric: 0.0649\n","Estimator 341/500, Train metric: 0.0648\n","Estimator 342/500, Train metric: 0.0642\n","Estimator 343/500, Train metric: 0.0640\n","Estimator 344/500, Train metric: 0.0637\n","Estimator 345/500, Train metric: 0.0633\n","Estimator 346/500, Train metric: 0.0631\n","Estimator 347/500, Train metric: 0.0628\n","Estimator 348/500, Train metric: 0.0624\n","Estimator 349/500, Train metric: 0.0622\n","Estimator 350/500, Train metric: 0.0619\n","Estimator 351/500, Train metric: 0.0617\n","Estimator 352/500, Train metric: 0.0614\n","Estimator 353/500, Train metric: 0.0612\n","Estimator 354/500, Train metric: 0.0609\n","Estimator 355/500, Train metric: 0.0608\n","Estimator 356/500, Train metric: 0.0607\n","Estimator 357/500, Train metric: 0.0605\n","Estimator 358/500, Train metric: 0.0604\n","Estimator 359/500, Train metric: 0.0600\n","Estimator 360/500, Train metric: 0.0597\n","Estimator 361/500, Train metric: 0.0594\n","Estimator 362/500, Train metric: 0.0593\n","Estimator 363/500, Train metric: 0.0591\n","Estimator 364/500, Train metric: 0.0587\n","Estimator 365/500, Train metric: 0.0583\n","Estimator 366/500, Train metric: 0.0582\n","Estimator 367/500, Train metric: 0.0579\n","Estimator 368/500, Train metric: 0.0579\n","Estimator 369/500, Train metric: 0.0579\n","Estimator 370/500, Train metric: 0.0577\n","Estimator 371/500, Train metric: 0.0575\n","Estimator 372/500, Train metric: 0.0571\n","Estimator 373/500, Train metric: 0.0567\n","Estimator 374/500, Train metric: 0.0565\n","Estimator 375/500, Train metric: 0.0564\n","Estimator 376/500, Train metric: 0.0562\n","Estimator 377/500, Train metric: 0.0559\n","Estimator 378/500, Train metric: 0.0555\n","Estimator 379/500, Train metric: 0.0554\n","Estimator 380/500, Train metric: 0.0551\n","Estimator 381/500, Train metric: 0.0549\n","Estimator 382/500, Train metric: 0.0548\n","Estimator 383/500, Train metric: 0.0545\n","Estimator 384/500, Train metric: 0.0545\n","Estimator 385/500, Train metric: 0.0540\n","Estimator 386/500, Train metric: 0.0539\n","Estimator 387/500, Train metric: 0.0537\n","Estimator 388/500, Train metric: 0.0534\n","Estimator 389/500, Train metric: 0.0533\n","Estimator 390/500, Train metric: 0.0531\n","Estimator 391/500, Train metric: 0.0528\n","Estimator 392/500, Train metric: 0.0529\n","Estimator 393/500, Train metric: 0.0527\n","Estimator 394/500, Train metric: 0.0527\n","Estimator 395/500, Train metric: 0.0525\n","Estimator 396/500, Train metric: 0.0522\n","Estimator 397/500, Train metric: 0.0519\n","Estimator 398/500, Train metric: 0.0516\n","Estimator 399/500, Train metric: 0.0515\n","Estimator 400/500, Train metric: 0.0513\n","Estimator 401/500, Train metric: 0.0510\n","Estimator 402/500, Train metric: 0.0509\n","Estimator 403/500, Train metric: 0.0507\n","Estimator 404/500, Train metric: 0.0506\n","Estimator 405/500, Train metric: 0.0503\n","Estimator 406/500, Train metric: 0.0502\n","Estimator 407/500, Train metric: 0.0501\n","Estimator 408/500, Train metric: 0.0500\n","Estimator 409/500, Train metric: 0.0498\n","Estimator 410/500, Train metric: 0.0495\n","Estimator 411/500, Train metric: 0.0494\n","Estimator 412/500, Train metric: 0.0491\n","Estimator 413/500, Train metric: 0.0490\n","Estimator 414/500, Train metric: 0.0488\n","Estimator 415/500, Train metric: 0.0485\n","Estimator 416/500, Train metric: 0.0485\n","Estimator 417/500, Train metric: 0.0485\n","Estimator 418/500, Train metric: 0.0483\n","Estimator 419/500, Train metric: 0.0480\n","Estimator 420/500, Train metric: 0.0478\n","Estimator 421/500, Train metric: 0.0476\n","Estimator 422/500, Train metric: 0.0474\n","Estimator 423/500, Train metric: 0.0473\n","Estimator 424/500, Train metric: 0.0471\n","Estimator 425/500, Train metric: 0.0469\n","Estimator 426/500, Train metric: 0.0468\n","Estimator 427/500, Train metric: 0.0466\n","Estimator 428/500, Train metric: 0.0465\n","Estimator 429/500, Train metric: 0.0462\n","Estimator 430/500, Train metric: 0.0460\n","Estimator 431/500, Train metric: 0.0459\n","Estimator 432/500, Train metric: 0.0458\n","Estimator 433/500, Train metric: 0.0458\n","Estimator 434/500, Train metric: 0.0457\n","Estimator 435/500, Train metric: 0.0456\n","Estimator 436/500, Train metric: 0.0453\n","Estimator 437/500, Train metric: 0.0452\n","Estimator 438/500, Train metric: 0.0450\n","Estimator 439/500, Train metric: 0.0448\n","Estimator 440/500, Train metric: 0.0446\n","Estimator 441/500, Train metric: 0.0444\n","Estimator 442/500, Train metric: 0.0442\n","Estimator 443/500, Train metric: 0.0440\n","Estimator 444/500, Train metric: 0.0438\n","Estimator 445/500, Train metric: 0.0437\n","Estimator 446/500, Train metric: 0.0435\n","Estimator 447/500, Train metric: 0.0434\n","Estimator 448/500, Train metric: 0.0433\n","Estimator 449/500, Train metric: 0.0433\n","Estimator 450/500, Train metric: 0.0429\n","Estimator 451/500, Train metric: 0.0429\n","Estimator 452/500, Train metric: 0.0427\n","Estimator 453/500, Train metric: 0.0426\n","Estimator 454/500, Train metric: 0.0426\n","Estimator 455/500, Train metric: 0.0424\n","Estimator 456/500, Train metric: 0.0423\n","Estimator 457/500, Train metric: 0.0421\n","Estimator 458/500, Train metric: 0.0420\n","Estimator 459/500, Train metric: 0.0420\n","Estimator 460/500, Train metric: 0.0419\n","Estimator 461/500, Train metric: 0.0419\n","Estimator 462/500, Train metric: 0.0419\n","Estimator 463/500, Train metric: 0.0419\n","Estimator 464/500, Train metric: 0.0419\n","Estimator 465/500, Train metric: 0.0417\n","Estimator 466/500, Train metric: 0.0416\n","Estimator 467/500, Train metric: 0.0416\n","Estimator 468/500, Train metric: 0.0414\n","Estimator 469/500, Train metric: 0.0411\n","Estimator 470/500, Train metric: 0.0410\n","Estimator 471/500, Train metric: 0.0409\n","Estimator 472/500, Train metric: 0.0409\n","Estimator 473/500, Train metric: 0.0408\n","Estimator 474/500, Train metric: 0.0406\n","Estimator 475/500, Train metric: 0.0406\n","Estimator 476/500, Train metric: 0.0405\n","Estimator 477/500, Train metric: 0.0404\n","Estimator 478/500, Train metric: 0.0402\n","Estimator 479/500, Train metric: 0.0400\n","Estimator 480/500, Train metric: 0.0399\n","Estimator 481/500, Train metric: 0.0398\n","Estimator 482/500, Train metric: 0.0397\n","Estimator 483/500, Train metric: 0.0396\n","Estimator 484/500, Train metric: 0.0395\n","Estimator 485/500, Train metric: 0.0394\n","Estimator 486/500, Train metric: 0.0394\n","Estimator 487/500, Train metric: 0.0393\n","Estimator 488/500, Train metric: 0.0392\n","Estimator 489/500, Train metric: 0.0392\n","Estimator 490/500, Train metric: 0.0391\n","Estimator 491/500, Train metric: 0.0390\n","Estimator 492/500, Train metric: 0.0390\n","Estimator 493/500, Train metric: 0.0389\n","Estimator 494/500, Train metric: 0.0388\n","Estimator 495/500, Train metric: 0.0387\n","Estimator 496/500, Train metric: 0.0386\n","Estimator 497/500, Train metric: 0.0386\n","Estimator 498/500, Train metric: 0.0385\n","Estimator 499/500, Train metric: 0.0384\n","Best MSE for PGBM with MedianPruner: 0.12343258517328114 with params: {'n_estimators': 500, 'learning_rate': 0.05, 'max_leaves': 54, 'min_split_gain': 0.0, 'reg_lambda': 0.1, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'tree_correlation': 0.2, 'min_data_in_leaf': 3, 'max_bin': 64, 'distribution': 'laplace'}\n","Best RMSE for PGBM with MedianPruner: 0.3513297385267594\n","Correlation Coefficient for PGBM with MedianPruner: 0.9433598369720617\n","Running Optuna for PGBM with NopPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/200, Train metric: 1.1728\n","Estimator 1/200, Train metric: 1.0897\n","Estimator 2/200, Train metric: 1.0165\n","Estimator 3/200, Train metric: 0.9496\n","Estimator 4/200, Train metric: 0.8816\n","Estimator 5/200, Train metric: 0.8306\n","Estimator 6/200, Train metric: 0.7779\n","Estimator 7/200, Train metric: 0.7464\n","Estimator 8/200, Train metric: 0.7007\n","Estimator 9/200, Train metric: 0.6746\n","Estimator 10/200, Train metric: 0.6410\n","Estimator 11/200, Train metric: 0.6167\n","Estimator 12/200, Train metric: 0.5948\n","Estimator 13/200, Train metric: 0.5754\n","Estimator 14/200, Train metric: 0.5584\n","Estimator 15/200, Train metric: 0.5479\n","Estimator 16/200, Train metric: 0.5309\n","Estimator 17/200, Train metric: 0.5175\n","Estimator 18/200, Train metric: 0.5072\n","Estimator 19/200, Train metric: 0.4964\n","Estimator 20/200, Train metric: 0.4954\n","Estimator 21/200, Train metric: 0.4875\n","Estimator 22/200, Train metric: 0.4778\n","Estimator 23/200, Train metric: 0.4755\n","Estimator 24/200, Train metric: 0.4691\n","Estimator 25/200, Train metric: 0.4671\n","Estimator 26/200, Train metric: 0.4637\n","Estimator 27/200, Train metric: 0.4640\n","Estimator 28/200, Train metric: 0.4611\n","Estimator 29/200, Train metric: 0.4551\n","Estimator 30/200, Train metric: 0.4522\n","Estimator 31/200, Train metric: 0.4484\n","Estimator 32/200, Train metric: 0.4480\n","Estimator 33/200, Train metric: 0.4431\n","Estimator 34/200, Train metric: 0.4393\n","Estimator 35/200, Train metric: 0.4343\n","Estimator 36/200, Train metric: 0.4324\n","Estimator 37/200, Train metric: 0.4319\n","Estimator 38/200, Train metric: 0.4276\n","Estimator 39/200, Train metric: 0.4259\n","Estimator 40/200, Train metric: 0.4189\n","Estimator 41/200, Train metric: 0.4138\n","Estimator 42/200, Train metric: 0.4094\n","Estimator 43/200, Train metric: 0.4068\n","Estimator 44/200, Train metric: 0.4045\n","Estimator 45/200, Train metric: 0.4010\n","Estimator 46/200, Train metric: 0.3990\n","Estimator 47/200, Train metric: 0.3968\n","Estimator 48/200, Train metric: 0.3942\n","Estimator 49/200, Train metric: 0.3929\n","Estimator 50/200, Train metric: 0.3933\n","Estimator 51/200, Train metric: 0.3911\n","Estimator 52/200, Train metric: 0.3872\n","Estimator 53/200, Train metric: 0.3833\n","Estimator 54/200, Train metric: 0.3813\n","Estimator 55/200, Train metric: 0.3816\n","Estimator 56/200, Train metric: 0.3808\n","Estimator 57/200, Train metric: 0.3759\n","Estimator 58/200, Train metric: 0.3744\n","Estimator 59/200, Train metric: 0.3715\n","Estimator 60/200, Train metric: 0.3721\n","Estimator 61/200, Train metric: 0.3704\n","Estimator 62/200, Train metric: 0.3696\n","Estimator 63/200, Train metric: 0.3672\n","Estimator 64/200, Train metric: 0.3666\n","Estimator 65/200, Train metric: 0.3652\n","Estimator 66/200, Train metric: 0.3650\n","Estimator 67/200, Train metric: 0.3636\n","Estimator 68/200, Train metric: 0.3629\n","Estimator 69/200, Train metric: 0.3616\n","Estimator 70/200, Train metric: 0.3602\n","Estimator 71/200, Train metric: 0.3573\n","Estimator 72/200, Train metric: 0.3548\n","Estimator 73/200, Train metric: 0.3509\n","Estimator 74/200, Train metric: 0.3509\n","Estimator 75/200, Train metric: 0.3486\n","Estimator 76/200, Train metric: 0.3474\n","Estimator 77/200, Train metric: 0.3440\n","Estimator 78/200, Train metric: 0.3408\n","Estimator 79/200, Train metric: 0.3388\n","Estimator 80/200, Train metric: 0.3360\n","Estimator 81/200, Train metric: 0.3358\n","Estimator 82/200, Train metric: 0.3356\n","Estimator 83/200, Train metric: 0.3355\n","Estimator 84/200, Train metric: 0.3329\n","Estimator 85/200, Train metric: 0.3325\n","Estimator 86/200, Train metric: 0.3304\n","Estimator 87/200, Train metric: 0.3312\n","Estimator 88/200, Train metric: 0.3314\n","Estimator 89/200, Train metric: 0.3285\n","Estimator 90/200, Train metric: 0.3277\n","Estimator 91/200, Train metric: 0.3274\n","Estimator 92/200, Train metric: 0.3260\n","Estimator 93/200, Train metric: 0.3243\n","Estimator 94/200, Train metric: 0.3235\n","Estimator 95/200, Train metric: 0.3231\n","Estimator 96/200, Train metric: 0.3230\n","Estimator 97/200, Train metric: 0.3216\n","Estimator 98/200, Train metric: 0.3200\n","Estimator 99/200, Train metric: 0.3181\n","Estimator 100/200, Train metric: 0.3170\n","Estimator 101/200, Train metric: 0.3167\n","Estimator 102/200, Train metric: 0.3166\n","Estimator 103/200, Train metric: 0.3159\n","Estimator 104/200, Train metric: 0.3143\n","Estimator 105/200, Train metric: 0.3132\n","Estimator 106/200, Train metric: 0.3118\n","Estimator 107/200, Train metric: 0.3117\n","Estimator 108/200, Train metric: 0.3109\n","Estimator 109/200, Train metric: 0.3089\n","Estimator 110/200, Train metric: 0.3084\n","Estimator 111/200, Train metric: 0.3051\n","Estimator 112/200, Train metric: 0.3046\n","Estimator 113/200, Train metric: 0.3036\n","Estimator 114/200, Train metric: 0.3029\n","Estimator 115/200, Train metric: 0.2992\n","Estimator 116/200, Train metric: 0.2993\n","Estimator 117/200, Train metric: 0.2995\n","Estimator 118/200, Train metric: 0.2992\n","Estimator 119/200, Train metric: 0.2987\n","Estimator 120/200, Train metric: 0.2967\n","Estimator 121/200, Train metric: 0.2960\n","Estimator 122/200, Train metric: 0.2952\n","Estimator 123/200, Train metric: 0.2938\n","Estimator 124/200, Train metric: 0.2919\n","Estimator 125/200, Train metric: 0.2924\n","Estimator 126/200, Train metric: 0.2908\n","Estimator 127/200, Train metric: 0.2905\n","Estimator 128/200, Train metric: 0.2886\n","Estimator 129/200, Train metric: 0.2884\n","Estimator 130/200, Train metric: 0.2875\n","Estimator 131/200, Train metric: 0.2873\n","Estimator 132/200, Train metric: 0.2861\n","Estimator 133/200, Train metric: 0.2857\n","Estimator 134/200, Train metric: 0.2852\n","Estimator 135/200, Train metric: 0.2840\n","Estimator 136/200, Train metric: 0.2838\n","Estimator 137/200, Train metric: 0.2831\n","Estimator 138/200, Train metric: 0.2824\n","Estimator 139/200, Train metric: 0.2826\n","Estimator 140/200, Train metric: 0.2814\n","Estimator 141/200, Train metric: 0.2785\n","Estimator 142/200, Train metric: 0.2781\n","Estimator 143/200, Train metric: 0.2777\n","Estimator 144/200, Train metric: 0.2773\n","Estimator 145/200, Train metric: 0.2766\n","Estimator 146/200, Train metric: 0.2759\n","Estimator 147/200, Train metric: 0.2735\n","Estimator 148/200, Train metric: 0.2725\n","Estimator 149/200, Train metric: 0.2713\n","Estimator 150/200, Train metric: 0.2712\n","Estimator 151/200, Train metric: 0.2699\n","Estimator 152/200, Train metric: 0.2693\n","Estimator 153/200, Train metric: 0.2686\n","Estimator 154/200, Train metric: 0.2685\n","Estimator 155/200, Train metric: 0.2679\n","Estimator 156/200, Train metric: 0.2661\n","Estimator 157/200, Train metric: 0.2649\n","Estimator 158/200, Train metric: 0.2645\n","Estimator 159/200, Train metric: 0.2644\n","Estimator 160/200, Train metric: 0.2639\n","Estimator 161/200, Train metric: 0.2633\n","Estimator 162/200, Train metric: 0.2610\n","Estimator 163/200, Train metric: 0.2604\n","Estimator 164/200, Train metric: 0.2596\n","Estimator 165/200, Train metric: 0.2587\n","Estimator 166/200, Train metric: 0.2573\n","Estimator 167/200, Train metric: 0.2574\n","Estimator 168/200, Train metric: 0.2566\n","Estimator 169/200, Train metric: 0.2561\n","Estimator 170/200, Train metric: 0.2560\n","Estimator 171/200, Train metric: 0.2560\n","Estimator 172/200, Train metric: 0.2559\n","Estimator 173/200, Train metric: 0.2530\n","Estimator 174/200, Train metric: 0.2531\n","Estimator 175/200, Train metric: 0.2530\n","Estimator 176/200, Train metric: 0.2521\n","Estimator 177/200, Train metric: 0.2518\n","Estimator 178/200, Train metric: 0.2506\n","Estimator 179/200, Train metric: 0.2506\n","Estimator 180/200, Train metric: 0.2504\n","Estimator 181/200, Train metric: 0.2498\n","Estimator 182/200, Train metric: 0.2483\n","Estimator 183/200, Train metric: 0.2481\n","Estimator 184/200, Train metric: 0.2481\n","Estimator 185/200, Train metric: 0.2480\n","Estimator 186/200, Train metric: 0.2481\n","Estimator 187/200, Train metric: 0.2481\n","Estimator 188/200, Train metric: 0.2471\n","Estimator 189/200, Train metric: 0.2472\n","Estimator 190/200, Train metric: 0.2471\n","Estimator 191/200, Train metric: 0.2471\n","Estimator 192/200, Train metric: 0.2467\n","Estimator 193/200, Train metric: 0.2467\n","Estimator 194/200, Train metric: 0.2460\n","Estimator 195/200, Train metric: 0.2455\n","Estimator 196/200, Train metric: 0.2451\n","Estimator 197/200, Train metric: 0.2429\n","Estimator 198/200, Train metric: 0.2424\n","Estimator 199/200, Train metric: 0.2419\n","Best MSE for PGBM with NopPruner: 0.1267295201974275 with params: {'n_estimators': 200, 'learning_rate': 0.15, 'max_leaves': 35, 'min_split_gain': 0.1, 'reg_lambda': 5.0, 'feature_fraction': 1.0, 'bagging_fraction': 0.5, 'tree_correlation': 0.3, 'min_data_in_leaf': 5, 'max_bin': 64, 'distribution': 'studentt'}\n","Best RMSE for PGBM with NopPruner: 0.35599089903735953\n","Correlation Coefficient for PGBM with NopPruner: 0.941140480780901\n","Running Optuna for PGBM with PatientPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/300, Train metric: 1.1157\n","Estimator 1/300, Train metric: 0.9956\n","Estimator 2/300, Train metric: 0.8902\n","Estimator 3/300, Train metric: 0.8107\n","Estimator 4/300, Train metric: 0.7254\n","Estimator 5/300, Train metric: 0.6730\n","Estimator 6/300, Train metric: 0.6209\n","Estimator 7/300, Train metric: 0.5865\n","Estimator 8/300, Train metric: 0.5417\n","Estimator 9/300, Train metric: 0.5194\n","Estimator 10/300, Train metric: 0.4975\n","Estimator 11/300, Train metric: 0.4796\n","Estimator 12/300, Train metric: 0.4593\n","Estimator 13/300, Train metric: 0.4502\n","Estimator 14/300, Train metric: 0.4397\n","Estimator 15/300, Train metric: 0.4330\n","Estimator 16/300, Train metric: 0.4225\n","Estimator 17/300, Train metric: 0.4151\n","Estimator 18/300, Train metric: 0.4050\n","Estimator 19/300, Train metric: 0.4015\n","Estimator 20/300, Train metric: 0.4012\n","Estimator 21/300, Train metric: 0.3924\n","Estimator 22/300, Train metric: 0.3888\n","Estimator 23/300, Train metric: 0.3902\n","Estimator 24/300, Train metric: 0.3882\n","Estimator 25/300, Train metric: 0.3871\n","Estimator 26/300, Train metric: 0.3861\n","Estimator 27/300, Train metric: 0.3826\n","Estimator 28/300, Train metric: 0.3826\n","Estimator 29/300, Train metric: 0.3810\n","Estimator 30/300, Train metric: 0.3789\n","Estimator 31/300, Train metric: 0.3776\n","Estimator 32/300, Train metric: 0.3759\n","Estimator 33/300, Train metric: 0.3689\n","Estimator 34/300, Train metric: 0.3628\n","Estimator 35/300, Train metric: 0.3543\n","Estimator 36/300, Train metric: 0.3541\n","Estimator 37/300, Train metric: 0.3552\n","Estimator 38/300, Train metric: 0.3462\n","Estimator 39/300, Train metric: 0.3461\n","Estimator 40/300, Train metric: 0.3432\n","Estimator 41/300, Train metric: 0.3431\n","Estimator 42/300, Train metric: 0.3432\n","Estimator 43/300, Train metric: 0.3405\n","Estimator 44/300, Train metric: 0.3382\n","Estimator 45/300, Train metric: 0.3317\n","Estimator 46/300, Train metric: 0.3318\n","Estimator 47/300, Train metric: 0.3321\n","Estimator 48/300, Train metric: 0.3319\n","Estimator 49/300, Train metric: 0.3319\n","Estimator 50/300, Train metric: 0.3316\n","Estimator 51/300, Train metric: 0.3316\n","Estimator 52/300, Train metric: 0.3316\n","Estimator 53/300, Train metric: 0.3316\n","Estimator 54/300, Train metric: 0.3320\n","Estimator 55/300, Train metric: 0.3323\n","Estimator 56/300, Train metric: 0.3329\n","Estimator 57/300, Train metric: 0.3317\n","Estimator 58/300, Train metric: 0.3303\n","Estimator 59/300, Train metric: 0.3302\n","Estimator 60/300, Train metric: 0.3301\n","Estimator 61/300, Train metric: 0.3268\n","Estimator 62/300, Train metric: 0.3269\n","Estimator 63/300, Train metric: 0.3261\n","Estimator 64/300, Train metric: 0.3257\n","Estimator 65/300, Train metric: 0.3256\n","Estimator 66/300, Train metric: 0.3256\n","Estimator 67/300, Train metric: 0.3256\n","Estimator 68/300, Train metric: 0.3256\n","Estimator 69/300, Train metric: 0.3247\n","Estimator 70/300, Train metric: 0.3262\n","Estimator 71/300, Train metric: 0.3262\n","Estimator 72/300, Train metric: 0.3262\n","Estimator 73/300, Train metric: 0.3246\n","Estimator 74/300, Train metric: 0.3246\n","Estimator 75/300, Train metric: 0.3246\n","Estimator 76/300, Train metric: 0.3238\n","Estimator 77/300, Train metric: 0.3238\n","Estimator 78/300, Train metric: 0.3242\n","Estimator 79/300, Train metric: 0.3207\n","Estimator 80/300, Train metric: 0.3208\n","Estimator 81/300, Train metric: 0.3204\n","Estimator 82/300, Train metric: 0.3204\n","Estimator 83/300, Train metric: 0.3206\n","Estimator 84/300, Train metric: 0.3169\n","Estimator 85/300, Train metric: 0.3160\n","Estimator 86/300, Train metric: 0.3148\n","Estimator 87/300, Train metric: 0.3158\n","Estimator 88/300, Train metric: 0.3137\n","Estimator 89/300, Train metric: 0.3137\n","Estimator 90/300, Train metric: 0.3128\n","Estimator 91/300, Train metric: 0.3128\n","Estimator 92/300, Train metric: 0.3121\n","Estimator 93/300, Train metric: 0.3123\n","Estimator 94/300, Train metric: 0.3123\n","Estimator 95/300, Train metric: 0.3122\n","Estimator 96/300, Train metric: 0.3124\n","Estimator 97/300, Train metric: 0.3124\n","Estimator 98/300, Train metric: 0.3124\n","Estimator 99/300, Train metric: 0.3124\n","Estimator 100/300, Train metric: 0.3124\n","Estimator 101/300, Train metric: 0.3135\n","Estimator 102/300, Train metric: 0.3127\n","Estimator 103/300, Train metric: 0.3128\n","Estimator 104/300, Train metric: 0.3104\n","Estimator 105/300, Train metric: 0.3104\n","Estimator 106/300, Train metric: 0.3104\n","Estimator 107/300, Train metric: 0.3103\n","Estimator 108/300, Train metric: 0.3103\n","Estimator 109/300, Train metric: 0.3078\n","Estimator 110/300, Train metric: 0.3077\n","Estimator 111/300, Train metric: 0.3068\n","Estimator 112/300, Train metric: 0.3065\n","Estimator 113/300, Train metric: 0.3064\n","Estimator 114/300, Train metric: 0.3065\n","Estimator 115/300, Train metric: 0.3065\n","Estimator 116/300, Train metric: 0.3065\n","Estimator 117/300, Train metric: 0.3059\n","Estimator 118/300, Train metric: 0.3062\n","Estimator 119/300, Train metric: 0.3061\n","Estimator 120/300, Train metric: 0.3061\n","Estimator 121/300, Train metric: 0.3061\n","Estimator 122/300, Train metric: 0.3062\n","Estimator 123/300, Train metric: 0.3058\n","Estimator 124/300, Train metric: 0.3057\n","Estimator 125/300, Train metric: 0.3066\n","Estimator 126/300, Train metric: 0.3066\n","Estimator 127/300, Train metric: 0.3066\n","Estimator 128/300, Train metric: 0.3066\n","Estimator 129/300, Train metric: 0.3066\n","Estimator 130/300, Train metric: 0.3066\n","Estimator 131/300, Train metric: 0.3068\n","Estimator 132/300, Train metric: 0.3070\n","Estimator 133/300, Train metric: 0.3071\n","Estimator 134/300, Train metric: 0.3049\n","Estimator 135/300, Train metric: 0.3040\n","Estimator 136/300, Train metric: 0.3040\n","Estimator 137/300, Train metric: 0.3040\n","Estimator 138/300, Train metric: 0.3035\n","Estimator 139/300, Train metric: 0.3016\n","Estimator 140/300, Train metric: 0.3017\n","Estimator 141/300, Train metric: 0.3018\n","Estimator 142/300, Train metric: 0.3018\n","Estimator 143/300, Train metric: 0.3017\n","Estimator 144/300, Train metric: 0.3018\n","Estimator 145/300, Train metric: 0.3017\n","Estimator 146/300, Train metric: 0.3009\n","Estimator 147/300, Train metric: 0.3007\n","Estimator 148/300, Train metric: 0.3006\n","Estimator 149/300, Train metric: 0.2994\n","Estimator 150/300, Train metric: 0.2994\n","Estimator 151/300, Train metric: 0.2994\n","Estimator 152/300, Train metric: 0.2994\n","Estimator 153/300, Train metric: 0.2995\n","Estimator 154/300, Train metric: 0.2994\n","Estimator 155/300, Train metric: 0.2995\n","Estimator 156/300, Train metric: 0.2994\n","Estimator 157/300, Train metric: 0.2995\n","Estimator 158/300, Train metric: 0.2995\n","Estimator 159/300, Train metric: 0.2994\n","Estimator 160/300, Train metric: 0.2990\n","Estimator 161/300, Train metric: 0.2991\n","Estimator 162/300, Train metric: 0.2990\n","Estimator 163/300, Train metric: 0.2980\n","Estimator 164/300, Train metric: 0.2980\n","Estimator 165/300, Train metric: 0.2980\n","Estimator 166/300, Train metric: 0.2980\n","Estimator 167/300, Train metric: 0.2980\n","Estimator 168/300, Train metric: 0.2980\n","Estimator 169/300, Train metric: 0.2980\n","Estimator 170/300, Train metric: 0.2980\n","Estimator 171/300, Train metric: 0.2980\n","Estimator 172/300, Train metric: 0.2981\n","Estimator 173/300, Train metric: 0.2981\n","Estimator 174/300, Train metric: 0.2982\n","Estimator 175/300, Train metric: 0.2984\n","Estimator 176/300, Train metric: 0.2984\n","Estimator 177/300, Train metric: 0.2986\n","Estimator 178/300, Train metric: 0.2985\n","Estimator 179/300, Train metric: 0.2983\n","Estimator 180/300, Train metric: 0.2969\n","Estimator 181/300, Train metric: 0.2954\n","Estimator 182/300, Train metric: 0.2954\n","Estimator 183/300, Train metric: 0.2954\n","Estimator 184/300, Train metric: 0.2954\n","Estimator 185/300, Train metric: 0.2950\n","Estimator 186/300, Train metric: 0.2951\n","Estimator 187/300, Train metric: 0.2950\n","Estimator 188/300, Train metric: 0.2942\n","Estimator 189/300, Train metric: 0.2932\n","Estimator 190/300, Train metric: 0.2932\n","Estimator 191/300, Train metric: 0.2932\n","Estimator 192/300, Train metric: 0.2932\n","Estimator 193/300, Train metric: 0.2936\n","Estimator 194/300, Train metric: 0.2927\n","Estimator 195/300, Train metric: 0.2927\n","Estimator 196/300, Train metric: 0.2929\n","Estimator 197/300, Train metric: 0.2928\n","Estimator 198/300, Train metric: 0.2927\n","Estimator 199/300, Train metric: 0.2927\n","Estimator 200/300, Train metric: 0.2926\n","Estimator 201/300, Train metric: 0.2925\n","Estimator 202/300, Train metric: 0.2925\n","Estimator 203/300, Train metric: 0.2925\n","Estimator 204/300, Train metric: 0.2924\n","Estimator 205/300, Train metric: 0.2920\n","Estimator 206/300, Train metric: 0.2917\n","Estimator 207/300, Train metric: 0.2917\n","Estimator 208/300, Train metric: 0.2892\n","Estimator 209/300, Train metric: 0.2886\n","Estimator 210/300, Train metric: 0.2886\n","Estimator 211/300, Train metric: 0.2886\n","Estimator 212/300, Train metric: 0.2886\n","Estimator 213/300, Train metric: 0.2887\n","Estimator 214/300, Train metric: 0.2888\n","Estimator 215/300, Train metric: 0.2888\n","Estimator 216/300, Train metric: 0.2890\n","Estimator 217/300, Train metric: 0.2903\n","Estimator 218/300, Train metric: 0.2891\n","Estimator 219/300, Train metric: 0.2887\n","Estimator 220/300, Train metric: 0.2885\n","Estimator 221/300, Train metric: 0.2885\n","Estimator 222/300, Train metric: 0.2886\n","Estimator 223/300, Train metric: 0.2885\n","Estimator 224/300, Train metric: 0.2884\n","Estimator 225/300, Train metric: 0.2885\n","Estimator 226/300, Train metric: 0.2885\n","Estimator 227/300, Train metric: 0.2886\n","Estimator 228/300, Train metric: 0.2884\n","Estimator 229/300, Train metric: 0.2878\n","Estimator 230/300, Train metric: 0.2878\n","Estimator 231/300, Train metric: 0.2878\n","Estimator 232/300, Train metric: 0.2873\n","Estimator 233/300, Train metric: 0.2873\n","Estimator 234/300, Train metric: 0.2872\n","Estimator 235/300, Train metric: 0.2873\n","Estimator 236/300, Train metric: 0.2874\n","Estimator 237/300, Train metric: 0.2873\n","Estimator 238/300, Train metric: 0.2865\n","Estimator 239/300, Train metric: 0.2865\n","Estimator 240/300, Train metric: 0.2865\n","Estimator 241/300, Train metric: 0.2861\n","Estimator 242/300, Train metric: 0.2861\n","Estimator 243/300, Train metric: 0.2861\n","Estimator 244/300, Train metric: 0.2861\n","Estimator 245/300, Train metric: 0.2861\n","Estimator 246/300, Train metric: 0.2862\n","Estimator 247/300, Train metric: 0.2862\n","Estimator 248/300, Train metric: 0.2859\n","Estimator 249/300, Train metric: 0.2858\n","Estimator 250/300, Train metric: 0.2858\n","Estimator 251/300, Train metric: 0.2858\n","Estimator 252/300, Train metric: 0.2858\n","Estimator 253/300, Train metric: 0.2858\n","Estimator 254/300, Train metric: 0.2858\n","Estimator 255/300, Train metric: 0.2858\n","Estimator 256/300, Train metric: 0.2858\n","Estimator 257/300, Train metric: 0.2850\n","Estimator 258/300, Train metric: 0.2850\n","Estimator 259/300, Train metric: 0.2851\n","Estimator 260/300, Train metric: 0.2850\n","Estimator 261/300, Train metric: 0.2850\n","Estimator 262/300, Train metric: 0.2850\n","Estimator 263/300, Train metric: 0.2850\n","Estimator 264/300, Train metric: 0.2850\n","Estimator 265/300, Train metric: 0.2850\n","Estimator 266/300, Train metric: 0.2837\n","Estimator 267/300, Train metric: 0.2837\n","Estimator 268/300, Train metric: 0.2837\n","Estimator 269/300, Train metric: 0.2837\n","Estimator 270/300, Train metric: 0.2837\n","Estimator 271/300, Train metric: 0.2837\n","Estimator 272/300, Train metric: 0.2837\n","Estimator 273/300, Train metric: 0.2838\n","Estimator 274/300, Train metric: 0.2841\n","Estimator 275/300, Train metric: 0.2840\n","Estimator 276/300, Train metric: 0.2840\n","Estimator 277/300, Train metric: 0.2840\n","Estimator 278/300, Train metric: 0.2840\n","Estimator 279/300, Train metric: 0.2840\n","Estimator 280/300, Train metric: 0.2840\n","Estimator 281/300, Train metric: 0.2840\n","Estimator 282/300, Train metric: 0.2840\n","Estimator 283/300, Train metric: 0.2850\n","Estimator 284/300, Train metric: 0.2841\n","Estimator 285/300, Train metric: 0.2842\n","Estimator 286/300, Train metric: 0.2840\n","Estimator 287/300, Train metric: 0.2841\n","Estimator 288/300, Train metric: 0.2841\n","Estimator 289/300, Train metric: 0.2843\n","Estimator 290/300, Train metric: 0.2843\n","Estimator 291/300, Train metric: 0.2844\n","Estimator 292/300, Train metric: 0.2846\n","Estimator 293/300, Train metric: 0.2847\n","Estimator 294/300, Train metric: 0.2845\n","Estimator 295/300, Train metric: 0.2828\n","Estimator 296/300, Train metric: 0.2826\n","Estimator 297/300, Train metric: 0.2825\n","Estimator 298/300, Train metric: 0.2826\n","Estimator 299/300, Train metric: 0.2823\n","Best MSE for PGBM with PatientPruner: 0.129824463608949 with params: {'n_estimators': 300, 'learning_rate': 0.15, 'max_leaves': 38, 'min_split_gain': 0.5, 'reg_lambda': 0.1, 'feature_fraction': 1.0, 'bagging_fraction': 0.5, 'tree_correlation': 0.0, 'min_data_in_leaf': 3, 'max_bin': 64, 'distribution': 'laplace'}\n","Best RMSE for PGBM with PatientPruner: 0.3603116201414395\n","Correlation Coefficient for PGBM with PatientPruner: 0.9407616347982253\n","Running Optuna for PGBM with PercentilePruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/500, Train metric: 1.2128\n","Estimator 1/500, Train metric: 1.1607\n","Estimator 2/500, Train metric: 1.1143\n","Estimator 3/500, Train metric: 1.0657\n","Estimator 4/500, Train metric: 1.0225\n","Estimator 5/500, Train metric: 0.9790\n","Estimator 6/500, Train metric: 0.9394\n","Estimator 7/500, Train metric: 0.8998\n","Estimator 8/500, Train metric: 0.8629\n","Estimator 9/500, Train metric: 0.8294\n","Estimator 10/500, Train metric: 0.7976\n","Estimator 11/500, Train metric: 0.7684\n","Estimator 12/500, Train metric: 0.7383\n","Estimator 13/500, Train metric: 0.7111\n","Estimator 14/500, Train metric: 0.6834\n","Estimator 15/500, Train metric: 0.6578\n","Estimator 16/500, Train metric: 0.6349\n","Estimator 17/500, Train metric: 0.6109\n","Estimator 18/500, Train metric: 0.5887\n","Estimator 19/500, Train metric: 0.5676\n","Estimator 20/500, Train metric: 0.5483\n","Estimator 21/500, Train metric: 0.5282\n","Estimator 22/500, Train metric: 0.5110\n","Estimator 23/500, Train metric: 0.4958\n","Estimator 24/500, Train metric: 0.4820\n","Estimator 25/500, Train metric: 0.4670\n","Estimator 26/500, Train metric: 0.4550\n","Estimator 27/500, Train metric: 0.4439\n","Estimator 28/500, Train metric: 0.4318\n","Estimator 29/500, Train metric: 0.4202\n","Estimator 30/500, Train metric: 0.4076\n","Estimator 31/500, Train metric: 0.3969\n","Estimator 32/500, Train metric: 0.3869\n","Estimator 33/500, Train metric: 0.3779\n","Estimator 34/500, Train metric: 0.3693\n","Estimator 35/500, Train metric: 0.3615\n","Estimator 36/500, Train metric: 0.3542\n","Estimator 37/500, Train metric: 0.3475\n","Estimator 38/500, Train metric: 0.3414\n","Estimator 39/500, Train metric: 0.3357\n","Estimator 40/500, Train metric: 0.3304\n","Estimator 41/500, Train metric: 0.3255\n","Estimator 42/500, Train metric: 0.3194\n","Estimator 43/500, Train metric: 0.3153\n","Estimator 44/500, Train metric: 0.3113\n","Estimator 45/500, Train metric: 0.3064\n","Estimator 46/500, Train metric: 0.3030\n","Estimator 47/500, Train metric: 0.2999\n","Estimator 48/500, Train metric: 0.2949\n","Estimator 49/500, Train metric: 0.2915\n","Estimator 50/500, Train metric: 0.2890\n","Estimator 51/500, Train metric: 0.2839\n","Estimator 52/500, Train metric: 0.2818\n","Estimator 53/500, Train metric: 0.2794\n","Estimator 54/500, Train metric: 0.2759\n","Estimator 55/500, Train metric: 0.2714\n","Estimator 56/500, Train metric: 0.2676\n","Estimator 57/500, Train metric: 0.2652\n","Estimator 58/500, Train metric: 0.2634\n","Estimator 59/500, Train metric: 0.2613\n","Estimator 60/500, Train metric: 0.2585\n","Estimator 61/500, Train metric: 0.2565\n","Estimator 62/500, Train metric: 0.2546\n","Estimator 63/500, Train metric: 0.2521\n","Estimator 64/500, Train metric: 0.2497\n","Estimator 65/500, Train metric: 0.2476\n","Estimator 66/500, Train metric: 0.2460\n","Estimator 67/500, Train metric: 0.2445\n","Estimator 68/500, Train metric: 0.2432\n","Estimator 69/500, Train metric: 0.2419\n","Estimator 70/500, Train metric: 0.2402\n","Estimator 71/500, Train metric: 0.2390\n","Estimator 72/500, Train metric: 0.2390\n","Estimator 73/500, Train metric: 0.2374\n","Estimator 74/500, Train metric: 0.2374\n","Estimator 75/500, Train metric: 0.2365\n","Estimator 76/500, Train metric: 0.2352\n","Estimator 77/500, Train metric: 0.2351\n","Estimator 78/500, Train metric: 0.2336\n","Estimator 79/500, Train metric: 0.2331\n","Estimator 80/500, Train metric: 0.2318\n","Estimator 81/500, Train metric: 0.2315\n","Estimator 82/500, Train metric: 0.2302\n","Estimator 83/500, Train metric: 0.2302\n","Estimator 84/500, Train metric: 0.2280\n","Estimator 85/500, Train metric: 0.2280\n","Estimator 86/500, Train metric: 0.2280\n","Estimator 87/500, Train metric: 0.2280\n","Estimator 88/500, Train metric: 0.2280\n","Estimator 89/500, Train metric: 0.2280\n","Estimator 90/500, Train metric: 0.2280\n","Estimator 91/500, Train metric: 0.2280\n","Estimator 92/500, Train metric: 0.2280\n","Estimator 93/500, Train metric: 0.2280\n","Estimator 94/500, Train metric: 0.2280\n","Estimator 95/500, Train metric: 0.2280\n","Estimator 96/500, Train metric: 0.2280\n","Estimator 97/500, Train metric: 0.2280\n","Estimator 98/500, Train metric: 0.2280\n","Estimator 99/500, Train metric: 0.2280\n","Estimator 100/500, Train metric: 0.2280\n","Estimator 101/500, Train metric: 0.2280\n","Estimator 102/500, Train metric: 0.2280\n","Estimator 103/500, Train metric: 0.2280\n","Estimator 104/500, Train metric: 0.2280\n","Estimator 105/500, Train metric: 0.2280\n","Estimator 106/500, Train metric: 0.2280\n","Estimator 107/500, Train metric: 0.2280\n","Estimator 108/500, Train metric: 0.2280\n","Estimator 109/500, Train metric: 0.2280\n","Estimator 110/500, Train metric: 0.2280\n","Estimator 111/500, Train metric: 0.2280\n","Estimator 112/500, Train metric: 0.2280\n","Estimator 113/500, Train metric: 0.2280\n","Estimator 114/500, Train metric: 0.2280\n","Estimator 115/500, Train metric: 0.2280\n","Estimator 116/500, Train metric: 0.2280\n","Estimator 117/500, Train metric: 0.2280\n","Estimator 118/500, Train metric: 0.2280\n","Estimator 119/500, Train metric: 0.2280\n","Estimator 120/500, Train metric: 0.2280\n","Estimator 121/500, Train metric: 0.2280\n","Estimator 122/500, Train metric: 0.2280\n","Estimator 123/500, Train metric: 0.2280\n","Estimator 124/500, Train metric: 0.2280\n","Estimator 125/500, Train metric: 0.2280\n","Estimator 126/500, Train metric: 0.2280\n","Estimator 127/500, Train metric: 0.2280\n","Estimator 128/500, Train metric: 0.2280\n","Estimator 129/500, Train metric: 0.2280\n","Estimator 130/500, Train metric: 0.2280\n","Estimator 131/500, Train metric: 0.2280\n","Estimator 132/500, Train metric: 0.2280\n","Estimator 133/500, Train metric: 0.2280\n","Estimator 134/500, Train metric: 0.2280\n","Estimator 135/500, Train metric: 0.2280\n","Estimator 136/500, Train metric: 0.2280\n","Estimator 137/500, Train metric: 0.2280\n","Estimator 138/500, Train metric: 0.2280\n","Estimator 139/500, Train metric: 0.2280\n","Estimator 140/500, Train metric: 0.2280\n","Estimator 141/500, Train metric: 0.2280\n","Estimator 142/500, Train metric: 0.2280\n","Estimator 143/500, Train metric: 0.2280\n","Estimator 144/500, Train metric: 0.2280\n","Estimator 145/500, Train metric: 0.2280\n","Estimator 146/500, Train metric: 0.2280\n","Estimator 147/500, Train metric: 0.2280\n","Estimator 148/500, Train metric: 0.2280\n","Estimator 149/500, Train metric: 0.2280\n","Estimator 150/500, Train metric: 0.2280\n","Estimator 151/500, Train metric: 0.2280\n","Estimator 152/500, Train metric: 0.2280\n","Estimator 153/500, Train metric: 0.2280\n","Estimator 154/500, Train metric: 0.2280\n","Estimator 155/500, Train metric: 0.2280\n","Estimator 156/500, Train metric: 0.2280\n","Estimator 157/500, Train metric: 0.2280\n","Estimator 158/500, Train metric: 0.2280\n","Estimator 159/500, Train metric: 0.2280\n","Estimator 160/500, Train metric: 0.2280\n","Estimator 161/500, Train metric: 0.2280\n","Estimator 162/500, Train metric: 0.2280\n","Estimator 163/500, Train metric: 0.2280\n","Estimator 164/500, Train metric: 0.2280\n","Estimator 165/500, Train metric: 0.2280\n","Estimator 166/500, Train metric: 0.2280\n","Estimator 167/500, Train metric: 0.2280\n","Estimator 168/500, Train metric: 0.2280\n","Estimator 169/500, Train metric: 0.2280\n","Estimator 170/500, Train metric: 0.2280\n","Estimator 171/500, Train metric: 0.2280\n","Estimator 172/500, Train metric: 0.2280\n","Estimator 173/500, Train metric: 0.2280\n","Estimator 174/500, Train metric: 0.2280\n","Estimator 175/500, Train metric: 0.2280\n","Estimator 176/500, Train metric: 0.2280\n","Estimator 177/500, Train metric: 0.2280\n","Estimator 178/500, Train metric: 0.2280\n","Estimator 179/500, Train metric: 0.2280\n","Estimator 180/500, Train metric: 0.2280\n","Estimator 181/500, Train metric: 0.2280\n","Estimator 182/500, Train metric: 0.2280\n","Estimator 183/500, Train metric: 0.2280\n","Estimator 184/500, Train metric: 0.2280\n","Estimator 185/500, Train metric: 0.2280\n","Estimator 186/500, Train metric: 0.2280\n","Estimator 187/500, Train metric: 0.2280\n","Estimator 188/500, Train metric: 0.2280\n","Estimator 189/500, Train metric: 0.2280\n","Estimator 190/500, Train metric: 0.2280\n","Estimator 191/500, Train metric: 0.2280\n","Estimator 192/500, Train metric: 0.2280\n","Estimator 193/500, Train metric: 0.2280\n","Estimator 194/500, Train metric: 0.2280\n","Estimator 195/500, Train metric: 0.2280\n","Estimator 196/500, Train metric: 0.2280\n","Estimator 197/500, Train metric: 0.2280\n","Estimator 198/500, Train metric: 0.2280\n","Estimator 199/500, Train metric: 0.2280\n","Estimator 200/500, Train metric: 0.2280\n","Estimator 201/500, Train metric: 0.2280\n","Estimator 202/500, Train metric: 0.2280\n","Estimator 203/500, Train metric: 0.2280\n","Estimator 204/500, Train metric: 0.2280\n","Estimator 205/500, Train metric: 0.2280\n","Estimator 206/500, Train metric: 0.2280\n","Estimator 207/500, Train metric: 0.2280\n","Estimator 208/500, Train metric: 0.2280\n","Estimator 209/500, Train metric: 0.2280\n","Estimator 210/500, Train metric: 0.2280\n","Estimator 211/500, Train metric: 0.2280\n","Estimator 212/500, Train metric: 0.2280\n","Estimator 213/500, Train metric: 0.2280\n","Estimator 214/500, Train metric: 0.2280\n","Estimator 215/500, Train metric: 0.2280\n","Estimator 216/500, Train metric: 0.2280\n","Estimator 217/500, Train metric: 0.2280\n","Estimator 218/500, Train metric: 0.2280\n","Estimator 219/500, Train metric: 0.2280\n","Estimator 220/500, Train metric: 0.2280\n","Estimator 221/500, Train metric: 0.2280\n","Estimator 222/500, Train metric: 0.2280\n","Estimator 223/500, Train metric: 0.2280\n","Estimator 224/500, Train metric: 0.2280\n","Estimator 225/500, Train metric: 0.2280\n","Estimator 226/500, Train metric: 0.2280\n","Estimator 227/500, Train metric: 0.2280\n","Estimator 228/500, Train metric: 0.2280\n","Estimator 229/500, Train metric: 0.2280\n","Estimator 230/500, Train metric: 0.2280\n","Estimator 231/500, Train metric: 0.2280\n","Estimator 232/500, Train metric: 0.2280\n","Estimator 233/500, Train metric: 0.2280\n","Estimator 234/500, Train metric: 0.2280\n","Estimator 235/500, Train metric: 0.2280\n","Estimator 236/500, Train metric: 0.2280\n","Estimator 237/500, Train metric: 0.2280\n","Estimator 238/500, Train metric: 0.2280\n","Estimator 239/500, Train metric: 0.2280\n","Estimator 240/500, Train metric: 0.2280\n","Estimator 241/500, Train metric: 0.2280\n","Estimator 242/500, Train metric: 0.2280\n","Estimator 243/500, Train metric: 0.2280\n","Estimator 244/500, Train metric: 0.2280\n","Estimator 245/500, Train metric: 0.2280\n","Estimator 246/500, Train metric: 0.2280\n","Estimator 247/500, Train metric: 0.2280\n","Estimator 248/500, Train metric: 0.2280\n","Estimator 249/500, Train metric: 0.2280\n","Estimator 250/500, Train metric: 0.2280\n","Estimator 251/500, Train metric: 0.2280\n","Estimator 252/500, Train metric: 0.2280\n","Estimator 253/500, Train metric: 0.2280\n","Estimator 254/500, Train metric: 0.2280\n","Estimator 255/500, Train metric: 0.2280\n","Estimator 256/500, Train metric: 0.2280\n","Estimator 257/500, Train metric: 0.2280\n","Estimator 258/500, Train metric: 0.2280\n","Estimator 259/500, Train metric: 0.2280\n","Estimator 260/500, Train metric: 0.2280\n","Estimator 261/500, Train metric: 0.2280\n","Estimator 262/500, Train metric: 0.2280\n","Estimator 263/500, Train metric: 0.2280\n","Estimator 264/500, Train metric: 0.2280\n","Estimator 265/500, Train metric: 0.2280\n","Estimator 266/500, Train metric: 0.2280\n","Estimator 267/500, Train metric: 0.2280\n","Estimator 268/500, Train metric: 0.2280\n","Estimator 269/500, Train metric: 0.2280\n","Estimator 270/500, Train metric: 0.2280\n","Estimator 271/500, Train metric: 0.2280\n","Estimator 272/500, Train metric: 0.2280\n","Estimator 273/500, Train metric: 0.2280\n","Estimator 274/500, Train metric: 0.2280\n","Estimator 275/500, Train metric: 0.2280\n","Estimator 276/500, Train metric: 0.2280\n","Estimator 277/500, Train metric: 0.2280\n","Estimator 278/500, Train metric: 0.2280\n","Estimator 279/500, Train metric: 0.2280\n","Estimator 280/500, Train metric: 0.2280\n","Estimator 281/500, Train metric: 0.2280\n","Estimator 282/500, Train metric: 0.2280\n","Estimator 283/500, Train metric: 0.2280\n","Estimator 284/500, Train metric: 0.2280\n","Estimator 285/500, Train metric: 0.2280\n","Estimator 286/500, Train metric: 0.2280\n","Estimator 287/500, Train metric: 0.2280\n","Estimator 288/500, Train metric: 0.2280\n","Estimator 289/500, Train metric: 0.2280\n","Estimator 290/500, Train metric: 0.2280\n","Estimator 291/500, Train metric: 0.2280\n","Estimator 292/500, Train metric: 0.2280\n","Estimator 293/500, Train metric: 0.2280\n","Estimator 294/500, Train metric: 0.2280\n","Estimator 295/500, Train metric: 0.2280\n","Estimator 296/500, Train metric: 0.2280\n","Estimator 297/500, Train metric: 0.2280\n","Estimator 298/500, Train metric: 0.2280\n","Estimator 299/500, Train metric: 0.2280\n","Estimator 300/500, Train metric: 0.2280\n","Estimator 301/500, Train metric: 0.2280\n","Estimator 302/500, Train metric: 0.2280\n","Estimator 303/500, Train metric: 0.2280\n","Estimator 304/500, Train metric: 0.2280\n","Estimator 305/500, Train metric: 0.2280\n","Estimator 306/500, Train metric: 0.2280\n","Estimator 307/500, Train metric: 0.2280\n","Estimator 308/500, Train metric: 0.2280\n","Estimator 309/500, Train metric: 0.2280\n","Estimator 310/500, Train metric: 0.2280\n","Estimator 311/500, Train metric: 0.2280\n","Estimator 312/500, Train metric: 0.2280\n","Estimator 313/500, Train metric: 0.2280\n","Estimator 314/500, Train metric: 0.2280\n","Estimator 315/500, Train metric: 0.2280\n","Estimator 316/500, Train metric: 0.2280\n","Estimator 317/500, Train metric: 0.2280\n","Estimator 318/500, Train metric: 0.2280\n","Estimator 319/500, Train metric: 0.2280\n","Estimator 320/500, Train metric: 0.2280\n","Estimator 321/500, Train metric: 0.2280\n","Estimator 322/500, Train metric: 0.2280\n","Estimator 323/500, Train metric: 0.2280\n","Estimator 324/500, Train metric: 0.2280\n","Estimator 325/500, Train metric: 0.2280\n","Estimator 326/500, Train metric: 0.2280\n","Estimator 327/500, Train metric: 0.2280\n","Estimator 328/500, Train metric: 0.2280\n","Estimator 329/500, Train metric: 0.2280\n","Estimator 330/500, Train metric: 0.2280\n","Estimator 331/500, Train metric: 0.2280\n","Estimator 332/500, Train metric: 0.2280\n","Estimator 333/500, Train metric: 0.2280\n","Estimator 334/500, Train metric: 0.2280\n","Estimator 335/500, Train metric: 0.2280\n","Estimator 336/500, Train metric: 0.2280\n","Estimator 337/500, Train metric: 0.2280\n","Estimator 338/500, Train metric: 0.2280\n","Estimator 339/500, Train metric: 0.2280\n","Estimator 340/500, Train metric: 0.2280\n","Estimator 341/500, Train metric: 0.2280\n","Estimator 342/500, Train metric: 0.2280\n","Estimator 343/500, Train metric: 0.2280\n","Estimator 344/500, Train metric: 0.2280\n","Estimator 345/500, Train metric: 0.2280\n","Estimator 346/500, Train metric: 0.2280\n","Estimator 347/500, Train metric: 0.2280\n","Estimator 348/500, Train metric: 0.2280\n","Estimator 349/500, Train metric: 0.2280\n","Estimator 350/500, Train metric: 0.2280\n","Estimator 351/500, Train metric: 0.2280\n","Estimator 352/500, Train metric: 0.2280\n","Estimator 353/500, Train metric: 0.2280\n","Estimator 354/500, Train metric: 0.2280\n","Estimator 355/500, Train metric: 0.2280\n","Estimator 356/500, Train metric: 0.2280\n","Estimator 357/500, Train metric: 0.2280\n","Estimator 358/500, Train metric: 0.2280\n","Estimator 359/500, Train metric: 0.2280\n","Estimator 360/500, Train metric: 0.2280\n","Estimator 361/500, Train metric: 0.2280\n","Estimator 362/500, Train metric: 0.2280\n","Estimator 363/500, Train metric: 0.2280\n","Estimator 364/500, Train metric: 0.2280\n","Estimator 365/500, Train metric: 0.2280\n","Estimator 366/500, Train metric: 0.2280\n","Estimator 367/500, Train metric: 0.2280\n","Estimator 368/500, Train metric: 0.2280\n","Estimator 369/500, Train metric: 0.2280\n","Estimator 370/500, Train metric: 0.2280\n","Estimator 371/500, Train metric: 0.2280\n","Estimator 372/500, Train metric: 0.2280\n","Estimator 373/500, Train metric: 0.2280\n","Estimator 374/500, Train metric: 0.2280\n","Estimator 375/500, Train metric: 0.2280\n","Estimator 376/500, Train metric: 0.2280\n","Estimator 377/500, Train metric: 0.2280\n","Estimator 378/500, Train metric: 0.2280\n","Estimator 379/500, Train metric: 0.2280\n","Estimator 380/500, Train metric: 0.2280\n","Estimator 381/500, Train metric: 0.2280\n","Estimator 382/500, Train metric: 0.2280\n","Estimator 383/500, Train metric: 0.2280\n","Estimator 384/500, Train metric: 0.2280\n","Estimator 385/500, Train metric: 0.2280\n","Estimator 386/500, Train metric: 0.2280\n","Estimator 387/500, Train metric: 0.2280\n","Estimator 388/500, Train metric: 0.2280\n","Estimator 389/500, Train metric: 0.2280\n","Estimator 390/500, Train metric: 0.2280\n","Estimator 391/500, Train metric: 0.2280\n","Estimator 392/500, Train metric: 0.2280\n","Estimator 393/500, Train metric: 0.2280\n","Estimator 394/500, Train metric: 0.2280\n","Estimator 395/500, Train metric: 0.2280\n","Estimator 396/500, Train metric: 0.2280\n","Estimator 397/500, Train metric: 0.2280\n","Estimator 398/500, Train metric: 0.2280\n","Estimator 399/500, Train metric: 0.2280\n","Estimator 400/500, Train metric: 0.2280\n","Estimator 401/500, Train metric: 0.2280\n","Estimator 402/500, Train metric: 0.2280\n","Estimator 403/500, Train metric: 0.2280\n","Estimator 404/500, Train metric: 0.2280\n","Estimator 405/500, Train metric: 0.2280\n","Estimator 406/500, Train metric: 0.2280\n","Estimator 407/500, Train metric: 0.2280\n","Estimator 408/500, Train metric: 0.2280\n","Estimator 409/500, Train metric: 0.2280\n","Estimator 410/500, Train metric: 0.2280\n","Estimator 411/500, Train metric: 0.2280\n","Estimator 412/500, Train metric: 0.2280\n","Estimator 413/500, Train metric: 0.2280\n","Estimator 414/500, Train metric: 0.2280\n","Estimator 415/500, Train metric: 0.2280\n","Estimator 416/500, Train metric: 0.2280\n","Estimator 417/500, Train metric: 0.2280\n","Estimator 418/500, Train metric: 0.2280\n","Estimator 419/500, Train metric: 0.2280\n","Estimator 420/500, Train metric: 0.2280\n","Estimator 421/500, Train metric: 0.2280\n","Estimator 422/500, Train metric: 0.2280\n","Estimator 423/500, Train metric: 0.2280\n","Estimator 424/500, Train metric: 0.2280\n","Estimator 425/500, Train metric: 0.2280\n","Estimator 426/500, Train metric: 0.2280\n","Estimator 427/500, Train metric: 0.2280\n","Estimator 428/500, Train metric: 0.2280\n","Estimator 429/500, Train metric: 0.2280\n","Estimator 430/500, Train metric: 0.2280\n","Estimator 431/500, Train metric: 0.2280\n","Estimator 432/500, Train metric: 0.2280\n","Estimator 433/500, Train metric: 0.2280\n","Estimator 434/500, Train metric: 0.2280\n","Estimator 435/500, Train metric: 0.2280\n","Estimator 436/500, Train metric: 0.2280\n","Estimator 437/500, Train metric: 0.2280\n","Estimator 438/500, Train metric: 0.2280\n","Estimator 439/500, Train metric: 0.2280\n","Estimator 440/500, Train metric: 0.2280\n","Estimator 441/500, Train metric: 0.2280\n","Estimator 442/500, Train metric: 0.2280\n","Estimator 443/500, Train metric: 0.2280\n","Estimator 444/500, Train metric: 0.2280\n","Estimator 445/500, Train metric: 0.2280\n","Estimator 446/500, Train metric: 0.2280\n","Estimator 447/500, Train metric: 0.2280\n","Estimator 448/500, Train metric: 0.2280\n","Estimator 449/500, Train metric: 0.2280\n","Estimator 450/500, Train metric: 0.2280\n","Estimator 451/500, Train metric: 0.2280\n","Estimator 452/500, Train metric: 0.2280\n","Estimator 453/500, Train metric: 0.2280\n","Estimator 454/500, Train metric: 0.2280\n","Estimator 455/500, Train metric: 0.2280\n","Estimator 456/500, Train metric: 0.2280\n","Estimator 457/500, Train metric: 0.2280\n","Estimator 458/500, Train metric: 0.2280\n","Estimator 459/500, Train metric: 0.2280\n","Estimator 460/500, Train metric: 0.2280\n","Estimator 461/500, Train metric: 0.2280\n","Estimator 462/500, Train metric: 0.2280\n","Estimator 463/500, Train metric: 0.2280\n","Estimator 464/500, Train metric: 0.2280\n","Estimator 465/500, Train metric: 0.2280\n","Estimator 466/500, Train metric: 0.2280\n","Estimator 467/500, Train metric: 0.2280\n","Estimator 468/500, Train metric: 0.2280\n","Estimator 469/500, Train metric: 0.2280\n","Estimator 470/500, Train metric: 0.2280\n","Estimator 471/500, Train metric: 0.2280\n","Estimator 472/500, Train metric: 0.2280\n","Estimator 473/500, Train metric: 0.2280\n","Estimator 474/500, Train metric: 0.2280\n","Estimator 475/500, Train metric: 0.2280\n","Estimator 476/500, Train metric: 0.2280\n","Estimator 477/500, Train metric: 0.2280\n","Estimator 478/500, Train metric: 0.2280\n","Estimator 479/500, Train metric: 0.2280\n","Estimator 480/500, Train metric: 0.2280\n","Estimator 481/500, Train metric: 0.2280\n","Estimator 482/500, Train metric: 0.2280\n","Estimator 483/500, Train metric: 0.2280\n","Estimator 484/500, Train metric: 0.2280\n","Estimator 485/500, Train metric: 0.2280\n","Estimator 486/500, Train metric: 0.2280\n","Estimator 487/500, Train metric: 0.2280\n","Estimator 488/500, Train metric: 0.2280\n","Estimator 489/500, Train metric: 0.2280\n","Estimator 490/500, Train metric: 0.2280\n","Estimator 491/500, Train metric: 0.2280\n","Estimator 492/500, Train metric: 0.2280\n","Estimator 493/500, Train metric: 0.2280\n","Estimator 494/500, Train metric: 0.2280\n","Estimator 495/500, Train metric: 0.2280\n","Estimator 496/500, Train metric: 0.2280\n","Estimator 497/500, Train metric: 0.2280\n","Estimator 498/500, Train metric: 0.2280\n","Estimator 499/500, Train metric: 0.2280\n","Best MSE for PGBM with PercentilePruner: 0.1034742435248506 with params: {'n_estimators': 500, 'learning_rate': 0.05, 'max_leaves': 30, 'min_split_gain': 0.1, 'reg_lambda': 0.1, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'tree_correlation': 0.3, 'min_data_in_leaf': 3, 'max_bin': 64, 'distribution': 'laplace'}\n","Best RMSE for PGBM with PercentilePruner: 0.3216741262906462\n","Correlation Coefficient for PGBM with PercentilePruner: 0.9526262297145519\n","Running Optuna for PGBM with SuccessiveHalvingPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/100, Train metric: 1.1031\n","Estimator 1/100, Train metric: 0.9614\n","Estimator 2/100, Train metric: 0.8437\n","Estimator 3/100, Train metric: 0.7432\n","Estimator 4/100, Train metric: 0.6615\n","Estimator 5/100, Train metric: 0.5884\n","Estimator 6/100, Train metric: 0.5210\n","Estimator 7/100, Train metric: 0.4718\n","Estimator 8/100, Train metric: 0.4300\n","Estimator 9/100, Train metric: 0.3937\n","Estimator 10/100, Train metric: 0.3633\n","Estimator 11/100, Train metric: 0.3385\n","Estimator 12/100, Train metric: 0.3191\n","Estimator 13/100, Train metric: 0.3044\n","Estimator 14/100, Train metric: 0.2911\n","Estimator 15/100, Train metric: 0.2781\n","Estimator 16/100, Train metric: 0.2688\n","Estimator 17/100, Train metric: 0.2612\n","Estimator 18/100, Train metric: 0.2555\n","Estimator 19/100, Train metric: 0.2474\n","Estimator 20/100, Train metric: 0.2453\n","Estimator 21/100, Train metric: 0.2426\n","Estimator 22/100, Train metric: 0.2359\n","Estimator 23/100, Train metric: 0.2302\n","Estimator 24/100, Train metric: 0.2292\n","Estimator 25/100, Train metric: 0.2236\n","Estimator 26/100, Train metric: 0.2203\n","Estimator 27/100, Train metric: 0.2183\n","Estimator 28/100, Train metric: 0.2183\n","Estimator 29/100, Train metric: 0.2183\n","Estimator 30/100, Train metric: 0.2183\n","Estimator 31/100, Train metric: 0.2183\n","Estimator 32/100, Train metric: 0.2183\n","Estimator 33/100, Train metric: 0.2183\n","Estimator 34/100, Train metric: 0.2183\n","Estimator 35/100, Train metric: 0.2183\n","Estimator 36/100, Train metric: 0.2183\n","Estimator 37/100, Train metric: 0.2183\n","Estimator 38/100, Train metric: 0.2183\n","Estimator 39/100, Train metric: 0.2183\n","Estimator 40/100, Train metric: 0.2183\n","Estimator 41/100, Train metric: 0.2183\n","Estimator 42/100, Train metric: 0.2183\n","Estimator 43/100, Train metric: 0.2183\n","Estimator 44/100, Train metric: 0.2183\n","Estimator 45/100, Train metric: 0.2183\n","Estimator 46/100, Train metric: 0.2183\n","Estimator 47/100, Train metric: 0.2183\n","Estimator 48/100, Train metric: 0.2183\n","Estimator 49/100, Train metric: 0.2183\n","Estimator 50/100, Train metric: 0.2183\n","Estimator 51/100, Train metric: 0.2183\n","Estimator 52/100, Train metric: 0.2183\n","Estimator 53/100, Train metric: 0.2183\n","Estimator 54/100, Train metric: 0.2183\n","Estimator 55/100, Train metric: 0.2183\n","Estimator 56/100, Train metric: 0.2183\n","Estimator 57/100, Train metric: 0.2183\n","Estimator 58/100, Train metric: 0.2183\n","Estimator 59/100, Train metric: 0.2183\n","Estimator 60/100, Train metric: 0.2183\n","Estimator 61/100, Train metric: 0.2183\n","Estimator 62/100, Train metric: 0.2183\n","Estimator 63/100, Train metric: 0.2183\n","Estimator 64/100, Train metric: 0.2183\n","Estimator 65/100, Train metric: 0.2183\n","Estimator 66/100, Train metric: 0.2183\n","Estimator 67/100, Train metric: 0.2183\n","Estimator 68/100, Train metric: 0.2183\n","Estimator 69/100, Train metric: 0.2183\n","Estimator 70/100, Train metric: 0.2183\n","Estimator 71/100, Train metric: 0.2183\n","Estimator 72/100, Train metric: 0.2183\n","Estimator 73/100, Train metric: 0.2183\n","Estimator 74/100, Train metric: 0.2183\n","Estimator 75/100, Train metric: 0.2183\n","Estimator 76/100, Train metric: 0.2183\n","Estimator 77/100, Train metric: 0.2183\n","Estimator 78/100, Train metric: 0.2183\n","Estimator 79/100, Train metric: 0.2183\n","Estimator 80/100, Train metric: 0.2183\n","Estimator 81/100, Train metric: 0.2183\n","Estimator 82/100, Train metric: 0.2183\n","Estimator 83/100, Train metric: 0.2183\n","Estimator 84/100, Train metric: 0.2183\n","Estimator 85/100, Train metric: 0.2183\n","Estimator 86/100, Train metric: 0.2183\n","Estimator 87/100, Train metric: 0.2183\n","Estimator 88/100, Train metric: 0.2183\n","Estimator 89/100, Train metric: 0.2183\n","Estimator 90/100, Train metric: 0.2183\n","Estimator 91/100, Train metric: 0.2183\n","Estimator 92/100, Train metric: 0.2183\n","Estimator 93/100, Train metric: 0.2183\n","Estimator 94/100, Train metric: 0.2183\n","Estimator 95/100, Train metric: 0.2183\n","Estimator 96/100, Train metric: 0.2183\n","Estimator 97/100, Train metric: 0.2183\n","Estimator 98/100, Train metric: 0.2183\n","Estimator 99/100, Train metric: 0.2183\n","Best MSE for PGBM with SuccessiveHalvingPruner: 0.07826943068929365 with params: {'n_estimators': 100, 'learning_rate': 0.15, 'max_leaves': 31, 'min_split_gain': 0.1, 'reg_lambda': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 1.0, 'tree_correlation': 0.1, 'min_data_in_leaf': 3, 'max_bin': 64, 'distribution': 'normal'}\n","Best RMSE for PGBM with SuccessiveHalvingPruner: 0.27976674335827273\n","Correlation Coefficient for PGBM with SuccessiveHalvingPruner: 0.9647067432415465\n","Running Optuna for PGBM with HyperbandPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/300, Train metric: 1.1324\n","Estimator 1/300, Train metric: 1.0350\n","Estimator 2/300, Train metric: 0.9365\n","Estimator 3/300, Train metric: 0.8407\n","Estimator 4/300, Train metric: 0.7744\n","Estimator 5/300, Train metric: 0.7086\n","Estimator 6/300, Train metric: 0.6618\n","Estimator 7/300, Train metric: 0.6150\n","Estimator 8/300, Train metric: 0.5771\n","Estimator 9/300, Train metric: 0.5502\n","Estimator 10/300, Train metric: 0.5351\n","Estimator 11/300, Train metric: 0.5181\n","Estimator 12/300, Train metric: 0.5138\n","Estimator 13/300, Train metric: 0.4907\n","Estimator 14/300, Train metric: 0.4773\n","Estimator 15/300, Train metric: 0.4537\n","Estimator 16/300, Train metric: 0.4471\n","Estimator 17/300, Train metric: 0.4462\n","Estimator 18/300, Train metric: 0.4442\n","Estimator 19/300, Train metric: 0.4389\n","Estimator 20/300, Train metric: 0.4258\n","Estimator 21/300, Train metric: 0.4204\n","Estimator 22/300, Train metric: 0.4128\n","Estimator 23/300, Train metric: 0.4136\n","Estimator 24/300, Train metric: 0.4108\n","Estimator 25/300, Train metric: 0.4017\n","Estimator 26/300, Train metric: 0.3945\n","Estimator 27/300, Train metric: 0.3925\n","Estimator 28/300, Train metric: 0.3859\n","Estimator 29/300, Train metric: 0.3799\n","Estimator 30/300, Train metric: 0.3832\n","Estimator 31/300, Train metric: 0.3864\n","Estimator 32/300, Train metric: 0.3811\n","Estimator 33/300, Train metric: 0.3788\n","Estimator 34/300, Train metric: 0.3757\n","Estimator 35/300, Train metric: 0.3733\n","Estimator 36/300, Train metric: 0.3704\n","Estimator 37/300, Train metric: 0.3631\n","Estimator 38/300, Train metric: 0.3634\n","Estimator 39/300, Train metric: 0.3577\n","Estimator 40/300, Train metric: 0.3501\n","Estimator 41/300, Train metric: 0.3493\n","Estimator 42/300, Train metric: 0.3428\n","Estimator 43/300, Train metric: 0.3401\n","Estimator 44/300, Train metric: 0.3387\n","Estimator 45/300, Train metric: 0.3345\n","Estimator 46/300, Train metric: 0.3331\n","Estimator 47/300, Train metric: 0.3298\n","Estimator 48/300, Train metric: 0.3291\n","Estimator 49/300, Train metric: 0.3272\n","Estimator 50/300, Train metric: 0.3241\n","Estimator 51/300, Train metric: 0.3234\n","Estimator 52/300, Train metric: 0.3172\n","Estimator 53/300, Train metric: 0.3121\n","Estimator 54/300, Train metric: 0.3070\n","Estimator 55/300, Train metric: 0.3058\n","Estimator 56/300, Train metric: 0.3052\n","Estimator 57/300, Train metric: 0.3024\n","Estimator 58/300, Train metric: 0.3035\n","Estimator 59/300, Train metric: 0.3038\n","Estimator 60/300, Train metric: 0.2997\n","Estimator 61/300, Train metric: 0.2956\n","Estimator 62/300, Train metric: 0.2945\n","Estimator 63/300, Train metric: 0.2910\n","Estimator 64/300, Train metric: 0.2869\n","Estimator 65/300, Train metric: 0.2844\n","Estimator 66/300, Train metric: 0.2795\n","Estimator 67/300, Train metric: 0.2773\n","Estimator 68/300, Train metric: 0.2751\n","Estimator 69/300, Train metric: 0.2747\n","Estimator 70/300, Train metric: 0.2737\n","Estimator 71/300, Train metric: 0.2752\n","Estimator 72/300, Train metric: 0.2720\n","Estimator 73/300, Train metric: 0.2692\n","Estimator 74/300, Train metric: 0.2657\n","Estimator 75/300, Train metric: 0.2656\n","Estimator 76/300, Train metric: 0.2644\n","Estimator 77/300, Train metric: 0.2628\n","Estimator 78/300, Train metric: 0.2594\n","Estimator 79/300, Train metric: 0.2571\n","Estimator 80/300, Train metric: 0.2554\n","Estimator 81/300, Train metric: 0.2544\n","Estimator 82/300, Train metric: 0.2522\n","Estimator 83/300, Train metric: 0.2507\n","Estimator 84/300, Train metric: 0.2480\n","Estimator 85/300, Train metric: 0.2438\n","Estimator 86/300, Train metric: 0.2404\n","Estimator 87/300, Train metric: 0.2403\n","Estimator 88/300, Train metric: 0.2376\n","Estimator 89/300, Train metric: 0.2333\n","Estimator 90/300, Train metric: 0.2312\n","Estimator 91/300, Train metric: 0.2311\n","Estimator 92/300, Train metric: 0.2305\n","Estimator 93/300, Train metric: 0.2285\n","Estimator 94/300, Train metric: 0.2275\n","Estimator 95/300, Train metric: 0.2270\n","Estimator 96/300, Train metric: 0.2251\n","Estimator 97/300, Train metric: 0.2222\n","Estimator 98/300, Train metric: 0.2205\n","Estimator 99/300, Train metric: 0.2196\n","Estimator 100/300, Train metric: 0.2176\n","Estimator 101/300, Train metric: 0.2165\n","Estimator 102/300, Train metric: 0.2160\n","Estimator 103/300, Train metric: 0.2160\n","Estimator 104/300, Train metric: 0.2161\n","Estimator 105/300, Train metric: 0.2150\n","Estimator 106/300, Train metric: 0.2149\n","Estimator 107/300, Train metric: 0.2121\n","Estimator 108/300, Train metric: 0.2112\n","Estimator 109/300, Train metric: 0.2120\n","Estimator 110/300, Train metric: 0.2108\n","Estimator 111/300, Train metric: 0.2078\n","Estimator 112/300, Train metric: 0.2066\n","Estimator 113/300, Train metric: 0.2060\n","Estimator 114/300, Train metric: 0.2060\n","Estimator 115/300, Train metric: 0.2055\n","Estimator 116/300, Train metric: 0.2055\n","Estimator 117/300, Train metric: 0.2041\n","Estimator 118/300, Train metric: 0.2046\n","Estimator 119/300, Train metric: 0.2045\n","Estimator 120/300, Train metric: 0.2041\n","Estimator 121/300, Train metric: 0.2011\n","Estimator 122/300, Train metric: 0.1999\n","Estimator 123/300, Train metric: 0.1994\n","Estimator 124/300, Train metric: 0.1993\n","Estimator 125/300, Train metric: 0.1989\n","Estimator 126/300, Train metric: 0.1984\n","Estimator 127/300, Train metric: 0.1980\n","Estimator 128/300, Train metric: 0.1961\n","Estimator 129/300, Train metric: 0.1957\n","Estimator 130/300, Train metric: 0.1939\n","Estimator 131/300, Train metric: 0.1929\n","Estimator 132/300, Train metric: 0.1926\n","Estimator 133/300, Train metric: 0.1929\n","Estimator 134/300, Train metric: 0.1927\n","Estimator 135/300, Train metric: 0.1930\n","Estimator 136/300, Train metric: 0.1928\n","Estimator 137/300, Train metric: 0.1924\n","Estimator 138/300, Train metric: 0.1921\n","Estimator 139/300, Train metric: 0.1907\n","Estimator 140/300, Train metric: 0.1905\n","Estimator 141/300, Train metric: 0.1904\n","Estimator 142/300, Train metric: 0.1904\n","Estimator 143/300, Train metric: 0.1902\n","Estimator 144/300, Train metric: 0.1899\n","Estimator 145/300, Train metric: 0.1899\n","Estimator 146/300, Train metric: 0.1901\n","Estimator 147/300, Train metric: 0.1894\n","Estimator 148/300, Train metric: 0.1888\n","Estimator 149/300, Train metric: 0.1888\n","Estimator 150/300, Train metric: 0.1885\n","Estimator 151/300, Train metric: 0.1883\n","Estimator 152/300, Train metric: 0.1880\n","Estimator 153/300, Train metric: 0.1870\n","Estimator 154/300, Train metric: 0.1875\n","Estimator 155/300, Train metric: 0.1869\n","Estimator 156/300, Train metric: 0.1867\n","Estimator 157/300, Train metric: 0.1857\n","Estimator 158/300, Train metric: 0.1854\n","Estimator 159/300, Train metric: 0.1850\n","Estimator 160/300, Train metric: 0.1840\n","Estimator 161/300, Train metric: 0.1839\n","Estimator 162/300, Train metric: 0.1830\n","Estimator 163/300, Train metric: 0.1826\n","Estimator 164/300, Train metric: 0.1826\n","Estimator 165/300, Train metric: 0.1826\n","Estimator 166/300, Train metric: 0.1827\n","Estimator 167/300, Train metric: 0.1824\n","Estimator 168/300, Train metric: 0.1824\n","Estimator 169/300, Train metric: 0.1825\n","Estimator 170/300, Train metric: 0.1825\n","Estimator 171/300, Train metric: 0.1825\n","Estimator 172/300, Train metric: 0.1826\n","Estimator 173/300, Train metric: 0.1819\n","Estimator 174/300, Train metric: 0.1819\n","Estimator 175/300, Train metric: 0.1817\n","Estimator 176/300, Train metric: 0.1811\n","Estimator 177/300, Train metric: 0.1811\n","Estimator 178/300, Train metric: 0.1811\n","Estimator 179/300, Train metric: 0.1810\n","Estimator 180/300, Train metric: 0.1812\n","Estimator 181/300, Train metric: 0.1810\n","Estimator 182/300, Train metric: 0.1810\n","Estimator 183/300, Train metric: 0.1807\n","Estimator 184/300, Train metric: 0.1807\n","Estimator 185/300, Train metric: 0.1807\n","Estimator 186/300, Train metric: 0.1807\n","Estimator 187/300, Train metric: 0.1803\n","Estimator 188/300, Train metric: 0.1803\n","Estimator 189/300, Train metric: 0.1803\n","Estimator 190/300, Train metric: 0.1801\n","Estimator 191/300, Train metric: 0.1801\n","Estimator 192/300, Train metric: 0.1801\n","Estimator 193/300, Train metric: 0.1801\n","Estimator 194/300, Train metric: 0.1794\n","Estimator 195/300, Train metric: 0.1794\n","Estimator 196/300, Train metric: 0.1794\n","Estimator 197/300, Train metric: 0.1795\n","Estimator 198/300, Train metric: 0.1793\n","Estimator 199/300, Train metric: 0.1793\n","Estimator 200/300, Train metric: 0.1793\n","Estimator 201/300, Train metric: 0.1793\n","Estimator 202/300, Train metric: 0.1793\n","Estimator 203/300, Train metric: 0.1794\n","Estimator 204/300, Train metric: 0.1794\n","Estimator 205/300, Train metric: 0.1795\n","Estimator 206/300, Train metric: 0.1795\n","Estimator 207/300, Train metric: 0.1795\n","Estimator 208/300, Train metric: 0.1794\n","Estimator 209/300, Train metric: 0.1794\n","Estimator 210/300, Train metric: 0.1793\n","Estimator 211/300, Train metric: 0.1777\n","Estimator 212/300, Train metric: 0.1781\n","Estimator 213/300, Train metric: 0.1786\n","Estimator 214/300, Train metric: 0.1778\n","Estimator 215/300, Train metric: 0.1779\n","Estimator 216/300, Train metric: 0.1778\n","Estimator 217/300, Train metric: 0.1775\n","Estimator 218/300, Train metric: 0.1776\n","Estimator 219/300, Train metric: 0.1775\n","Estimator 220/300, Train metric: 0.1775\n","Estimator 221/300, Train metric: 0.1775\n","Estimator 222/300, Train metric: 0.1771\n","Estimator 223/300, Train metric: 0.1771\n","Estimator 224/300, Train metric: 0.1771\n","Estimator 225/300, Train metric: 0.1771\n","Estimator 226/300, Train metric: 0.1768\n","Estimator 227/300, Train metric: 0.1765\n","Estimator 228/300, Train metric: 0.1763\n","Estimator 229/300, Train metric: 0.1763\n","Estimator 230/300, Train metric: 0.1759\n","Estimator 231/300, Train metric: 0.1759\n","Estimator 232/300, Train metric: 0.1757\n","Estimator 233/300, Train metric: 0.1753\n","Estimator 234/300, Train metric: 0.1750\n","Estimator 235/300, Train metric: 0.1747\n","Estimator 236/300, Train metric: 0.1746\n","Estimator 237/300, Train metric: 0.1741\n","Estimator 238/300, Train metric: 0.1740\n","Estimator 239/300, Train metric: 0.1735\n","Estimator 240/300, Train metric: 0.1728\n","Estimator 241/300, Train metric: 0.1728\n","Estimator 242/300, Train metric: 0.1728\n","Estimator 243/300, Train metric: 0.1728\n","Estimator 244/300, Train metric: 0.1729\n","Estimator 245/300, Train metric: 0.1729\n","Estimator 246/300, Train metric: 0.1728\n","Estimator 247/300, Train metric: 0.1729\n","Estimator 248/300, Train metric: 0.1731\n","Estimator 249/300, Train metric: 0.1731\n","Estimator 250/300, Train metric: 0.1731\n","Estimator 251/300, Train metric: 0.1731\n","Estimator 252/300, Train metric: 0.1731\n","Estimator 253/300, Train metric: 0.1729\n","Estimator 254/300, Train metric: 0.1724\n","Estimator 255/300, Train metric: 0.1723\n","Estimator 256/300, Train metric: 0.1724\n","Estimator 257/300, Train metric: 0.1724\n","Estimator 258/300, Train metric: 0.1724\n","Estimator 259/300, Train metric: 0.1725\n","Estimator 260/300, Train metric: 0.1726\n","Estimator 261/300, Train metric: 0.1725\n","Estimator 262/300, Train metric: 0.1725\n","Estimator 263/300, Train metric: 0.1725\n","Estimator 264/300, Train metric: 0.1723\n","Estimator 265/300, Train metric: 0.1725\n","Estimator 266/300, Train metric: 0.1725\n","Estimator 267/300, Train metric: 0.1725\n","Estimator 268/300, Train metric: 0.1728\n","Estimator 269/300, Train metric: 0.1729\n","Estimator 270/300, Train metric: 0.1729\n","Estimator 271/300, Train metric: 0.1730\n","Estimator 272/300, Train metric: 0.1730\n","Estimator 273/300, Train metric: 0.1730\n","Estimator 274/300, Train metric: 0.1730\n","Estimator 275/300, Train metric: 0.1732\n","Estimator 276/300, Train metric: 0.1727\n","Estimator 277/300, Train metric: 0.1726\n","Estimator 278/300, Train metric: 0.1729\n","Estimator 279/300, Train metric: 0.1716\n","Estimator 280/300, Train metric: 0.1712\n","Estimator 281/300, Train metric: 0.1711\n","Estimator 282/300, Train metric: 0.1711\n","Estimator 283/300, Train metric: 0.1709\n","Estimator 284/300, Train metric: 0.1706\n","Estimator 285/300, Train metric: 0.1702\n","Estimator 286/300, Train metric: 0.1698\n","Estimator 287/300, Train metric: 0.1696\n","Estimator 288/300, Train metric: 0.1696\n","Estimator 289/300, Train metric: 0.1697\n","Estimator 290/300, Train metric: 0.1696\n","Estimator 291/300, Train metric: 0.1696\n","Estimator 292/300, Train metric: 0.1696\n","Estimator 293/300, Train metric: 0.1696\n","Estimator 294/300, Train metric: 0.1696\n","Estimator 295/300, Train metric: 0.1696\n","Estimator 296/300, Train metric: 0.1696\n","Estimator 297/300, Train metric: 0.1696\n","Estimator 298/300, Train metric: 0.1693\n","Estimator 299/300, Train metric: 0.1693\n","Best MSE for PGBM with HyperbandPruner: 0.10804920612728598 with params: {'n_estimators': 300, 'learning_rate': 0.15, 'max_leaves': 52, 'min_split_gain': 0.1, 'reg_lambda': 1.0, 'feature_fraction': 0.9, 'bagging_fraction': 0.5, 'tree_correlation': 0.3, 'min_data_in_leaf': 3, 'max_bin': 64, 'distribution': 'studentt'}\n","Best RMSE for PGBM with HyperbandPruner: 0.32870839071627905\n","Correlation Coefficient for PGBM with HyperbandPruner: 0.950103255895245\n","Running Optuna for PGBM with ThresholdPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/100, Train metric: 1.1572\n","Estimator 1/100, Train metric: 1.0559\n","Estimator 2/100, Train metric: 0.9705\n","Estimator 3/100, Train metric: 0.8876\n","Estimator 4/100, Train metric: 0.8165\n","Estimator 5/100, Train metric: 0.7495\n","Estimator 6/100, Train metric: 0.6897\n","Estimator 7/100, Train metric: 0.6347\n","Estimator 8/100, Train metric: 0.5860\n","Estimator 9/100, Train metric: 0.5422\n","Estimator 10/100, Train metric: 0.5041\n","Estimator 11/100, Train metric: 0.4701\n","Estimator 12/100, Train metric: 0.4361\n","Estimator 13/100, Train metric: 0.4061\n","Estimator 14/100, Train metric: 0.3794\n","Estimator 15/100, Train metric: 0.3584\n","Estimator 16/100, Train metric: 0.3390\n","Estimator 17/100, Train metric: 0.3213\n","Estimator 18/100, Train metric: 0.3038\n","Estimator 19/100, Train metric: 0.2882\n","Estimator 20/100, Train metric: 0.2757\n","Estimator 21/100, Train metric: 0.2651\n","Estimator 22/100, Train metric: 0.2545\n","Estimator 23/100, Train metric: 0.2457\n","Estimator 24/100, Train metric: 0.2384\n","Estimator 25/100, Train metric: 0.2300\n","Estimator 26/100, Train metric: 0.2206\n","Estimator 27/100, Train metric: 0.2093\n","Estimator 28/100, Train metric: 0.2021\n","Estimator 29/100, Train metric: 0.1929\n","Estimator 30/100, Train metric: 0.1854\n","Estimator 31/100, Train metric: 0.1794\n","Estimator 32/100, Train metric: 0.1735\n","Estimator 33/100, Train metric: 0.1690\n","Estimator 34/100, Train metric: 0.1645\n","Estimator 35/100, Train metric: 0.1612\n","Estimator 36/100, Train metric: 0.1574\n","Estimator 37/100, Train metric: 0.1545\n","Estimator 38/100, Train metric: 0.1506\n","Estimator 39/100, Train metric: 0.1465\n","Estimator 40/100, Train metric: 0.1428\n","Estimator 41/100, Train metric: 0.1394\n","Estimator 42/100, Train metric: 0.1367\n","Estimator 43/100, Train metric: 0.1336\n","Estimator 44/100, Train metric: 0.1312\n","Estimator 45/100, Train metric: 0.1277\n","Estimator 46/100, Train metric: 0.1255\n","Estimator 47/100, Train metric: 0.1234\n","Estimator 48/100, Train metric: 0.1199\n","Estimator 49/100, Train metric: 0.1172\n","Estimator 50/100, Train metric: 0.1153\n","Estimator 51/100, Train metric: 0.1135\n","Estimator 52/100, Train metric: 0.1108\n","Estimator 53/100, Train metric: 0.1091\n","Estimator 54/100, Train metric: 0.1070\n","Estimator 55/100, Train metric: 0.1048\n","Estimator 56/100, Train metric: 0.1035\n","Estimator 57/100, Train metric: 0.1007\n","Estimator 58/100, Train metric: 0.0989\n","Estimator 59/100, Train metric: 0.0968\n","Estimator 60/100, Train metric: 0.0952\n","Estimator 61/100, Train metric: 0.0934\n","Estimator 62/100, Train metric: 0.0916\n","Estimator 63/100, Train metric: 0.0901\n","Estimator 64/100, Train metric: 0.0889\n","Estimator 65/100, Train metric: 0.0869\n","Estimator 66/100, Train metric: 0.0857\n","Estimator 67/100, Train metric: 0.0842\n","Estimator 68/100, Train metric: 0.0829\n","Estimator 69/100, Train metric: 0.0812\n","Estimator 70/100, Train metric: 0.0800\n","Estimator 71/100, Train metric: 0.0788\n","Estimator 72/100, Train metric: 0.0778\n","Estimator 73/100, Train metric: 0.0766\n","Estimator 74/100, Train metric: 0.0754\n","Estimator 75/100, Train metric: 0.0744\n","Estimator 76/100, Train metric: 0.0735\n","Estimator 77/100, Train metric: 0.0726\n","Estimator 78/100, Train metric: 0.0713\n","Estimator 79/100, Train metric: 0.0703\n","Estimator 80/100, Train metric: 0.0694\n","Estimator 81/100, Train metric: 0.0685\n","Estimator 82/100, Train metric: 0.0674\n","Estimator 83/100, Train metric: 0.0668\n","Estimator 84/100, Train metric: 0.0660\n","Estimator 85/100, Train metric: 0.0646\n","Estimator 86/100, Train metric: 0.0640\n","Estimator 87/100, Train metric: 0.0633\n","Estimator 88/100, Train metric: 0.0628\n","Estimator 89/100, Train metric: 0.0618\n","Estimator 90/100, Train metric: 0.0613\n","Estimator 91/100, Train metric: 0.0607\n","Estimator 92/100, Train metric: 0.0598\n","Estimator 93/100, Train metric: 0.0593\n","Estimator 94/100, Train metric: 0.0587\n","Estimator 95/100, Train metric: 0.0578\n","Estimator 96/100, Train metric: 0.0569\n","Estimator 97/100, Train metric: 0.0562\n","Estimator 98/100, Train metric: 0.0553\n","Estimator 99/100, Train metric: 0.0546\n","Best MSE for PGBM with ThresholdPruner: 0.09417793540001096 with params: {'n_estimators': 100, 'learning_rate': 0.1, 'max_leaves': 52, 'min_split_gain': 0.0, 'reg_lambda': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 1.0, 'tree_correlation': 0.0, 'min_data_in_leaf': 3, 'max_bin': 64, 'distribution': 'normal'}\n","Best RMSE for PGBM with ThresholdPruner: 0.3068842377835834\n","Correlation Coefficient for PGBM with ThresholdPruner: 0.959620971727772\n","Running Optuna for PGBM with WilcoxonPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/200, Train metric: 1.1760\n","Estimator 1/200, Train metric: 1.0869\n","Estimator 2/200, Train metric: 1.0193\n","Estimator 3/200, Train metric: 0.9559\n","Estimator 4/200, Train metric: 0.9018\n","Estimator 5/200, Train metric: 0.8494\n","Estimator 6/200, Train metric: 0.8030\n","Estimator 7/200, Train metric: 0.7574\n","Estimator 8/200, Train metric: 0.7180\n","Estimator 9/200, Train metric: 0.6825\n","Estimator 10/200, Train metric: 0.6569\n","Estimator 11/200, Train metric: 0.6337\n","Estimator 12/200, Train metric: 0.6083\n","Estimator 13/200, Train metric: 0.5842\n","Estimator 14/200, Train metric: 0.5640\n","Estimator 15/200, Train metric: 0.5472\n","Estimator 16/200, Train metric: 0.5322\n","Estimator 17/200, Train metric: 0.5161\n","Estimator 18/200, Train metric: 0.5058\n","Estimator 19/200, Train metric: 0.4951\n","Estimator 20/200, Train metric: 0.4853\n","Estimator 21/200, Train metric: 0.4756\n","Estimator 22/200, Train metric: 0.4698\n","Estimator 23/200, Train metric: 0.4622\n","Estimator 24/200, Train metric: 0.4538\n","Estimator 25/200, Train metric: 0.4466\n","Estimator 26/200, Train metric: 0.4417\n","Estimator 27/200, Train metric: 0.4337\n","Estimator 28/200, Train metric: 0.4275\n","Estimator 29/200, Train metric: 0.4237\n","Estimator 30/200, Train metric: 0.4185\n","Estimator 31/200, Train metric: 0.4134\n","Estimator 32/200, Train metric: 0.4055\n","Estimator 33/200, Train metric: 0.4002\n","Estimator 34/200, Train metric: 0.3967\n","Estimator 35/200, Train metric: 0.3931\n","Estimator 36/200, Train metric: 0.3877\n","Estimator 37/200, Train metric: 0.3848\n","Estimator 38/200, Train metric: 0.3806\n","Estimator 39/200, Train metric: 0.3780\n","Estimator 40/200, Train metric: 0.3735\n","Estimator 41/200, Train metric: 0.3702\n","Estimator 42/200, Train metric: 0.3683\n","Estimator 43/200, Train metric: 0.3643\n","Estimator 44/200, Train metric: 0.3623\n","Estimator 45/200, Train metric: 0.3585\n","Estimator 46/200, Train metric: 0.3562\n","Estimator 47/200, Train metric: 0.3547\n","Estimator 48/200, Train metric: 0.3524\n","Estimator 49/200, Train metric: 0.3486\n","Estimator 50/200, Train metric: 0.3475\n","Estimator 51/200, Train metric: 0.3446\n","Estimator 52/200, Train metric: 0.3424\n","Estimator 53/200, Train metric: 0.3389\n","Estimator 54/200, Train metric: 0.3342\n","Estimator 55/200, Train metric: 0.3332\n","Estimator 56/200, Train metric: 0.3320\n","Estimator 57/200, Train metric: 0.3288\n","Estimator 58/200, Train metric: 0.3237\n","Estimator 59/200, Train metric: 0.3197\n","Estimator 60/200, Train metric: 0.3165\n","Estimator 61/200, Train metric: 0.3149\n","Estimator 62/200, Train metric: 0.3149\n","Estimator 63/200, Train metric: 0.3126\n","Estimator 64/200, Train metric: 0.3086\n","Estimator 65/200, Train metric: 0.3083\n","Estimator 66/200, Train metric: 0.3083\n","Estimator 67/200, Train metric: 0.3069\n","Estimator 68/200, Train metric: 0.3045\n","Estimator 69/200, Train metric: 0.3029\n","Estimator 70/200, Train metric: 0.3014\n","Estimator 71/200, Train metric: 0.3008\n","Estimator 72/200, Train metric: 0.3004\n","Estimator 73/200, Train metric: 0.3001\n","Estimator 74/200, Train metric: 0.2978\n","Estimator 75/200, Train metric: 0.2979\n","Estimator 76/200, Train metric: 0.2954\n","Estimator 77/200, Train metric: 0.2948\n","Estimator 78/200, Train metric: 0.2923\n","Estimator 79/200, Train metric: 0.2923\n","Estimator 80/200, Train metric: 0.2891\n","Estimator 81/200, Train metric: 0.2891\n","Estimator 82/200, Train metric: 0.2891\n","Estimator 83/200, Train metric: 0.2873\n","Estimator 84/200, Train metric: 0.2854\n","Estimator 85/200, Train metric: 0.2825\n","Estimator 86/200, Train metric: 0.2825\n","Estimator 87/200, Train metric: 0.2807\n","Estimator 88/200, Train metric: 0.2807\n","Estimator 89/200, Train metric: 0.2807\n","Estimator 90/200, Train metric: 0.2807\n","Estimator 91/200, Train metric: 0.2804\n","Estimator 92/200, Train metric: 0.2804\n","Estimator 93/200, Train metric: 0.2804\n","Estimator 94/200, Train metric: 0.2780\n","Estimator 95/200, Train metric: 0.2780\n","Estimator 96/200, Train metric: 0.2777\n","Estimator 97/200, Train metric: 0.2777\n","Estimator 98/200, Train metric: 0.2774\n","Estimator 99/200, Train metric: 0.2774\n","Estimator 100/200, Train metric: 0.2752\n","Estimator 101/200, Train metric: 0.2737\n","Estimator 102/200, Train metric: 0.2737\n","Estimator 103/200, Train metric: 0.2723\n","Estimator 104/200, Train metric: 0.2723\n","Estimator 105/200, Train metric: 0.2723\n","Estimator 106/200, Train metric: 0.2721\n","Estimator 107/200, Train metric: 0.2721\n","Estimator 108/200, Train metric: 0.2709\n","Estimator 109/200, Train metric: 0.2709\n","Estimator 110/200, Train metric: 0.2709\n","Estimator 111/200, Train metric: 0.2709\n","Estimator 112/200, Train metric: 0.2709\n","Estimator 113/200, Train metric: 0.2702\n","Estimator 114/200, Train metric: 0.2702\n","Estimator 115/200, Train metric: 0.2702\n","Estimator 116/200, Train metric: 0.2702\n","Estimator 117/200, Train metric: 0.2700\n","Estimator 118/200, Train metric: 0.2700\n","Estimator 119/200, Train metric: 0.2700\n","Estimator 120/200, Train metric: 0.2700\n","Estimator 121/200, Train metric: 0.2700\n","Estimator 122/200, Train metric: 0.2681\n","Estimator 123/200, Train metric: 0.2681\n","Estimator 124/200, Train metric: 0.2681\n","Estimator 125/200, Train metric: 0.2681\n","Estimator 126/200, Train metric: 0.2669\n","Estimator 127/200, Train metric: 0.2669\n","Estimator 128/200, Train metric: 0.2669\n","Estimator 129/200, Train metric: 0.2656\n","Estimator 130/200, Train metric: 0.2650\n","Estimator 131/200, Train metric: 0.2650\n","Estimator 132/200, Train metric: 0.2647\n","Estimator 133/200, Train metric: 0.2646\n","Estimator 134/200, Train metric: 0.2636\n","Estimator 135/200, Train metric: 0.2636\n","Estimator 136/200, Train metric: 0.2635\n","Estimator 137/200, Train metric: 0.2635\n","Estimator 138/200, Train metric: 0.2635\n","Estimator 139/200, Train metric: 0.2635\n","Estimator 140/200, Train metric: 0.2635\n","Estimator 141/200, Train metric: 0.2635\n","Estimator 142/200, Train metric: 0.2635\n","Estimator 143/200, Train metric: 0.2635\n","Estimator 144/200, Train metric: 0.2618\n","Estimator 145/200, Train metric: 0.2618\n","Estimator 146/200, Train metric: 0.2618\n","Estimator 147/200, Train metric: 0.2618\n","Estimator 148/200, Train metric: 0.2618\n","Estimator 149/200, Train metric: 0.2618\n","Estimator 150/200, Train metric: 0.2618\n","Estimator 151/200, Train metric: 0.2618\n","Estimator 152/200, Train metric: 0.2609\n","Estimator 153/200, Train metric: 0.2606\n","Estimator 154/200, Train metric: 0.2605\n","Estimator 155/200, Train metric: 0.2605\n","Estimator 156/200, Train metric: 0.2594\n","Estimator 157/200, Train metric: 0.2594\n","Estimator 158/200, Train metric: 0.2594\n","Estimator 159/200, Train metric: 0.2594\n","Estimator 160/200, Train metric: 0.2594\n","Estimator 161/200, Train metric: 0.2590\n","Estimator 162/200, Train metric: 0.2590\n","Estimator 163/200, Train metric: 0.2590\n","Estimator 164/200, Train metric: 0.2590\n","Estimator 165/200, Train metric: 0.2590\n","Estimator 166/200, Train metric: 0.2588\n","Estimator 167/200, Train metric: 0.2588\n","Estimator 168/200, Train metric: 0.2588\n","Estimator 169/200, Train metric: 0.2587\n","Estimator 170/200, Train metric: 0.2587\n","Estimator 171/200, Train metric: 0.2587\n","Estimator 172/200, Train metric: 0.2587\n","Estimator 173/200, Train metric: 0.2587\n","Estimator 174/200, Train metric: 0.2587\n","Estimator 175/200, Train metric: 0.2587\n","Estimator 176/200, Train metric: 0.2587\n","Estimator 177/200, Train metric: 0.2587\n","Estimator 178/200, Train metric: 0.2587\n","Estimator 179/200, Train metric: 0.2587\n","Estimator 180/200, Train metric: 0.2585\n","Estimator 181/200, Train metric: 0.2586\n","Estimator 182/200, Train metric: 0.2586\n","Estimator 183/200, Train metric: 0.2585\n","Estimator 184/200, Train metric: 0.2585\n","Estimator 185/200, Train metric: 0.2585\n","Estimator 186/200, Train metric: 0.2584\n","Estimator 187/200, Train metric: 0.2578\n","Estimator 188/200, Train metric: 0.2578\n","Estimator 189/200, Train metric: 0.2578\n","Estimator 190/200, Train metric: 0.2578\n","Estimator 191/200, Train metric: 0.2578\n","Estimator 192/200, Train metric: 0.2571\n","Estimator 193/200, Train metric: 0.2571\n","Estimator 194/200, Train metric: 0.2564\n","Estimator 195/200, Train metric: 0.2564\n","Estimator 196/200, Train metric: 0.2565\n","Estimator 197/200, Train metric: 0.2565\n","Estimator 198/200, Train metric: 0.2565\n","Estimator 199/200, Train metric: 0.2563\n","Best MSE for PGBM with WilcoxonPruner: 0.11682202319670179 with params: {'n_estimators': 200, 'learning_rate': 0.15, 'max_leaves': 61, 'min_split_gain': 0.1, 'reg_lambda': 10.0, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'tree_correlation': 0.3, 'min_data_in_leaf': 3, 'max_bin': 64, 'distribution': 'studentt'}\n","Best RMSE for PGBM with WilcoxonPruner: 0.34179236854661016\n","Correlation Coefficient for PGBM with WilcoxonPruner: 0.9475122997898101\n","\n","Best model on test data: PGBM with SuccessiveHalvingPruner\n","Test MSE: 0.07826943068929365\n","Test RMSE: 0.27976674335827273\n","Correlation Coefficient: 0.9647067432415465\n","Best Parameters: {'n_estimators': 100, 'learning_rate': 0.15, 'max_leaves': 31, 'min_split_gain': 0.1, 'reg_lambda': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 1.0, 'tree_correlation': 0.1, 'min_data_in_leaf': 3, 'max_bin': 64, 'distribution': 'normal'}\n","Pruner Used: SuccessiveHalvingPruner\n"]}]},{"cell_type":"code","source":["best_scores_autosampler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdWxwbpGUSf1","executionInfo":{"status":"ok","timestamp":1746268591828,"user_tz":-330,"elapsed":163,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}},"outputId":"9a9dc3c3-56ab-4077-9331-5f0e81988d68"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{('Random Forest', 'MedianPruner'): {'best_score': 0.11795962820512826,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'absolute_error',\n","   'max_depth': 40,\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'log2',\n","   'max_leaf_nodes': 100,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.11795962820512826,\n","  'test_rmse': 0.3434525122999223,\n","  'test_corr_coef': 0.9522984425706565,\n","  'pruner': 'MedianPruner'},\n"," ('Random Forest', 'NopPruner'): {'best_score': 0.12337467665679205,\n","  'best_params': {'n_estimators': 200,\n","   'criterion': 'squared_error',\n","   'max_depth': 30,\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 0.3,\n","   'max_leaf_nodes': 50,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.12337467665679205,\n","  'test_rmse': 0.3512473155154243,\n","  'test_corr_coef': 0.947717133922788,\n","  'pruner': 'NopPruner'},\n"," ('Random Forest', 'PatientPruner'): {'best_score': 0.12400594306324769,\n","  'best_params': {'n_estimators': 500,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 30,\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 0.3,\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.12400594306324769,\n","  'test_rmse': 0.35214477571482966,\n","  'test_corr_coef': 0.9475381334576092,\n","  'pruner': 'PatientPruner'},\n"," ('Random Forest', 'PercentilePruner'): {'best_score': 0.12347172109059805,\n","  'best_params': {'n_estimators': 500,\n","   'criterion': 'squared_error',\n","   'max_depth': 20,\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'log2',\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.12347172109059805,\n","  'test_rmse': 0.3513854309595064,\n","  'test_corr_coef': 0.9478099007435906,\n","  'pruner': 'PercentilePruner'},\n"," ('Random Forest',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.15545241861963746, 'best_params': {'n_estimators': 700,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 40,\n","   'min_samples_split': 5,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.0}, 'test_mse': 0.15545241861963746, 'test_rmse': 0.39427454726324584, 'test_corr_coef': 0.9333474018537554, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('Random Forest', 'HyperbandPruner'): {'best_score': 0.13547401750844537,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 30,\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.13547401750844537,\n","  'test_rmse': 0.3680679522974601,\n","  'test_corr_coef': 0.9413267703115014,\n","  'pruner': 'HyperbandPruner'},\n"," ('Random Forest', 'ThresholdPruner'): {'best_score': 0.14608459691483422,\n","  'best_params': {'n_estimators': 200,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 40,\n","   'min_samples_split': 5,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': 50,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.14608459691483422,\n","  'test_rmse': 0.3822101475822355,\n","  'test_corr_coef': 0.9377441169295209,\n","  'pruner': 'ThresholdPruner'},\n"," ('Random Forest', 'WilcoxonPruner'): {'best_score': 0.11646959476999029,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'friedman_mse',\n","   'max_depth': 40,\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 0.5,\n","   'max_leaf_nodes': 100,\n","   'min_impurity_decrease': 0.1,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.11646959476999029,\n","  'test_rmse': 0.34127641988568486,\n","  'test_corr_coef': 0.9483822442439112,\n","  'pruner': 'WilcoxonPruner'},\n"," ('Gradient Boosting', 'MedianPruner'): {'best_score': 0.10596035268056564,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.2,\n","   'n_estimators': 200,\n","   'subsample': 1.0,\n","   'criterion': 'squared_error',\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 7,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': None,\n","   'alpha': 0.9,\n","   'verbose': 0,\n","   'max_leaf_nodes': 50,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.10596035268056564,\n","  'test_rmse': 0.3255155183406248,\n","  'test_corr_coef': 0.9531771509079551,\n","  'pruner': 'MedianPruner'},\n"," ('Gradient Boosting', 'NopPruner'): {'best_score': 0.09092491782126226,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.1,\n","   'n_estimators': 200,\n","   'subsample': 0.9,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.01,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'sqrt',\n","   'alpha': 0.9,\n","   'verbose': 0,\n","   'max_leaf_nodes': 30,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 20,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.09092491782126226,\n","  'test_rmse': 0.3015375894001646,\n","  'test_corr_coef': 0.9591644441671107,\n","  'pruner': 'NopPruner'},\n"," ('Gradient Boosting', 'PatientPruner'): {'best_score': 0.132559903174519,\n","  'best_params': {'loss': 'absolute_error',\n","   'learning_rate': 0.2,\n","   'n_estimators': 100,\n","   'subsample': 1.0,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 7,\n","   'min_impurity_decrease': 0.01,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'log2',\n","   'alpha': 0.9,\n","   'verbose': 0,\n","   'max_leaf_nodes': None,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 20,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.132559903174519,\n","  'test_rmse': 0.36408776850440744,\n","  'test_corr_coef': 0.9400804032538103,\n","  'pruner': 'PatientPruner'},\n"," ('Gradient Boosting', 'PercentilePruner'): {'best_score': 0.09343437955546878,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.2,\n","   'n_estimators': 200,\n","   'subsample': 0.9,\n","   'criterion': 'squared_error',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'log2',\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': 30,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.09343437955546878,\n","  'test_rmse': 0.3056703772946747,\n","  'test_corr_coef': 0.9570270978772224,\n","  'pruner': 'PercentilePruner'},\n"," ('Gradient Boosting',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.09324863155240691, 'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.1,\n","   'n_estimators': 500,\n","   'subsample': 0.9,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.1,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 0.5,\n","   'alpha': 0.9,\n","   'verbose': 0,\n","   'max_leaf_nodes': None,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 20,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.001}, 'test_mse': 0.09324863155240691, 'test_rmse': 0.305366389035216, 'test_corr_coef': 0.958191410403308, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('Gradient Boosting', 'HyperbandPruner'): {'best_score': 0.12057594312974565,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.05,\n","   'n_estimators': 700,\n","   'subsample': 0.5,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 5,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 7,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 0.5,\n","   'alpha': 0.1,\n","   'verbose': 0,\n","   'max_leaf_nodes': 10,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': None,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.12057594312974565,\n","  'test_rmse': 0.34724046873851794,\n","  'test_corr_coef': 0.94468016076508,\n","  'pruner': 'HyperbandPruner'},\n"," ('Gradient Boosting', 'ThresholdPruner'): {'best_score': 0.1055538748788425,\n","  'best_params': {'loss': 'squared_error',\n","   'learning_rate': 0.2,\n","   'n_estimators': 100,\n","   'subsample': 0.9,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 10,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'sqrt',\n","   'alpha': 0.1,\n","   'verbose': 0,\n","   'max_leaf_nodes': 50,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.1055538748788425,\n","  'test_rmse': 0.324890558309783,\n","  'test_corr_coef': 0.9525689662324699,\n","  'pruner': 'ThresholdPruner'},\n"," ('Gradient Boosting', 'WilcoxonPruner'): {'best_score': 0.13197016823417743,\n","  'best_params': {'loss': 'absolute_error',\n","   'learning_rate': 0.05,\n","   'n_estimators': 300,\n","   'subsample': 0.7,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 3,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 7,\n","   'min_impurity_decrease': 0.01,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 0.5,\n","   'alpha': 0.1,\n","   'verbose': 0,\n","   'max_leaf_nodes': 30,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': None,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.13197016823417743,\n","  'test_rmse': 0.36327698555534377,\n","  'test_corr_coef': 0.9415931294299945,\n","  'pruner': 'WilcoxonPruner'},\n"," ('XGBoost', 'MedianPruner'): {'best_score': 0.0898705681968317,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0.1,\n","   'subsample': 0.7,\n","   'colsample_bytree': 0.7,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.0898705681968317,\n","  'test_rmse': 0.2997842027139384,\n","  'test_corr_coef': 0.9594189532708957,\n","  'pruner': 'MedianPruner'},\n"," ('XGBoost', 'NopPruner'): {'best_score': 0.10599083202474795,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'max_depth': 5,\n","   'min_child_weight': 5,\n","   'gamma': 0.1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 1,\n","   'reg_lambda': 5,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.10599083202474795,\n","  'test_rmse': 0.32556233201147206,\n","  'test_corr_coef': 0.9532795599622089,\n","  'pruner': 'NopPruner'},\n"," ('XGBoost', 'PatientPruner'): {'best_score': 0.12245313501106483,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.05,\n","   'max_depth': 3,\n","   'min_child_weight': 1,\n","   'gamma': 0.1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.12245313501106483,\n","  'test_rmse': 0.3499330436112955,\n","  'test_corr_coef': 0.9433938208785971,\n","  'pruner': 'PatientPruner'},\n"," ('XGBoost', 'PercentilePruner'): {'best_score': 0.1018908667230901,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.7,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.1018908667230901,\n","  'test_rmse': 0.3192034879557084,\n","  'test_corr_coef': 0.953708845404612,\n","  'pruner': 'PercentilePruner'},\n"," ('XGBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.08218333690994077,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.15,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.7,\n","   'colsample_bylevel': 0.7,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.08218333690994077,\n","  'test_rmse': 0.28667636266344104,\n","  'test_corr_coef': 0.9630434798497448,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('XGBoost', 'HyperbandPruner'): {'best_score': 0.10063554832884712,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.15,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 0,\n","   'reg_lambda': 1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.10063554832884712,\n","  'test_rmse': 0.31723106457099554,\n","  'test_corr_coef': 0.9535886104929195,\n","  'pruner': 'HyperbandPruner'},\n"," ('XGBoost', 'ThresholdPruner'): {'best_score': 0.10787578291600165,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.01,\n","   'max_depth': 5,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 0,\n","   'reg_lambda': 1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.10787578291600165,\n","  'test_rmse': 0.3284444898548332,\n","  'test_corr_coef': 0.9536947891782032,\n","  'pruner': 'ThresholdPruner'},\n"," ('XGBoost', 'WilcoxonPruner'): {'best_score': 0.10272987541052153,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.7,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.10272987541052153,\n","  'test_rmse': 0.32051501588930514,\n","  'test_corr_coef': 0.9528817104164768,\n","  'pruner': 'WilcoxonPruner'},\n"," ('LightGBM', 'MedianPruner'): {'best_score': 0.08510702468210275,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'num_leaves': 15,\n","   'max_depth': 7,\n","   'min_child_samples': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 1.0,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.1,\n","   'bagging_freq': 5,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08510702468210275,\n","  'test_rmse': 0.2917310828178971,\n","  'test_corr_coef': 0.9610640651363059,\n","  'pruner': 'MedianPruner'},\n"," ('LightGBM', 'NopPruner'): {'best_score': 0.09797286644562232,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.1,\n","   'num_leaves': 63,\n","   'max_depth': 3,\n","   'min_child_samples': 1,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 1,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 0,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09797286644562232,\n","  'test_rmse': 0.313006176369768,\n","  'test_corr_coef': 0.955388850374431,\n","  'pruner': 'NopPruner'},\n"," ('LightGBM', 'PatientPruner'): {'best_score': 0.08620134294019038,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'num_leaves': 31,\n","   'max_depth': 5,\n","   'min_child_samples': 1,\n","   'subsample': 1.0,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 1e-05,\n","   'bagging_freq': 5,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08620134294019038,\n","  'test_rmse': 0.2936006521453765,\n","  'test_corr_coef': 0.9611118650021173,\n","  'pruner': 'PatientPruner'},\n"," ('LightGBM', 'PercentilePruner'): {'best_score': 0.09138899576548488,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'num_leaves': 31,\n","   'max_depth': 5,\n","   'min_child_samples': 1,\n","   'subsample': 1.0,\n","   'colsample_bytree': 0.7,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.1,\n","   'bagging_freq': 0,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09138899576548488,\n","  'test_rmse': 0.3023061292224901,\n","  'test_corr_coef': 0.9580295441872354,\n","  'pruner': 'PercentilePruner'},\n"," ('LightGBM', 'SuccessiveHalvingPruner'): {'best_score': 0.08318288231943329,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'num_leaves': 31,\n","   'max_depth': 7,\n","   'min_child_samples': 1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0,\n","   'min_child_weight': 1e-05,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08318288231943329,\n","  'test_rmse': 0.28841442807084616,\n","  'test_corr_coef': 0.961997957666191,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('LightGBM', 'HyperbandPruner'): {'best_score': 0.08551885335198639,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.05,\n","   'num_leaves': 63,\n","   'max_depth': 5,\n","   'min_child_samples': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.08551885335198639,\n","  'test_rmse': 0.2924360671189284,\n","  'test_corr_coef': 0.9613405547497119,\n","  'pruner': 'HyperbandPruner'},\n"," ('LightGBM', 'ThresholdPruner'): {'best_score': 0.09005684150695638,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.15,\n","   'num_leaves': 63,\n","   'max_depth': -1,\n","   'min_child_samples': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 1.0,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.001,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09005684150695638,\n","  'test_rmse': 0.3000947208915151,\n","  'test_corr_coef': 0.9586824287835334,\n","  'pruner': 'ThresholdPruner'},\n"," ('LightGBM', 'WilcoxonPruner'): {'best_score': 0.09291600232378894,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'num_leaves': 15,\n","   'max_depth': -1,\n","   'min_child_samples': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.001,\n","   'bagging_freq': 0,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09291600232378894,\n","  'test_rmse': 0.30482126291285677,\n","  'test_corr_coef': 0.9577137271606543,\n","  'pruner': 'WilcoxonPruner'},\n"," ('GPBoost', 'MedianPruner'): {'best_score': 0.10013123794553873,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'max_depth': -1,\n","   'num_leaves': 15,\n","   'min_child_samples': 1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 1e-05,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.10013123794553873,\n","  'test_rmse': 0.3164352033916876,\n","  'test_corr_coef': 0.9540221235653149,\n","  'pruner': 'MedianPruner'},\n"," ('GPBoost', 'NopPruner'): {'best_score': 0.1036340627359684,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'max_depth': 3,\n","   'num_leaves': 15,\n","   'min_child_samples': 1,\n","   'subsample': 0.7,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 1.0,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.01,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.1036340627359684,\n","  'test_rmse': 0.3219224483256307,\n","  'test_corr_coef': 0.9525582574157486,\n","  'pruner': 'NopPruner'},\n"," ('GPBoost', 'PatientPruner'): {'best_score': 0.0936923020400716,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'max_depth': 7,\n","   'num_leaves': 63,\n","   'min_child_samples': 1,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.1,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.0936923020400716,\n","  'test_rmse': 0.30609198297255613,\n","  'test_corr_coef': 0.9569897018244895,\n","  'pruner': 'PatientPruner'},\n"," ('GPBoost', 'PercentilePruner'): {'best_score': 0.09823357699600549,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'max_depth': 3,\n","   'num_leaves': 15,\n","   'min_child_samples': 1,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.01,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09823357699600549,\n","  'test_rmse': 0.31342236199098095,\n","  'test_corr_coef': 0.9556105168749771,\n","  'pruner': 'PercentilePruner'},\n"," ('GPBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.09902817795971754,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.01,\n","   'max_depth': 7,\n","   'num_leaves': 63,\n","   'min_child_samples': 1,\n","   'subsample': 1.0,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0,\n","   'min_child_weight': 1e-05,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09902817795971754,\n","  'test_rmse': 0.31468742898266133,\n","  'test_corr_coef': 0.9546589186328368,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('GPBoost', 'HyperbandPruner'): {'best_score': 0.09973817655873879,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.1,\n","   'max_depth': 3,\n","   'num_leaves': 63,\n","   'min_child_samples': 1,\n","   'subsample': 1.0,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.5,\n","   'min_child_weight': 0.01,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09973817655873879,\n","  'test_rmse': 0.3158135154782626,\n","  'test_corr_coef': 0.9545961643114624,\n","  'pruner': 'HyperbandPruner'},\n"," ('GPBoost', 'ThresholdPruner'): {'best_score': 0.09878181048966037,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.1,\n","   'max_depth': 3,\n","   'num_leaves': 31,\n","   'min_child_samples': 1,\n","   'subsample': 1.0,\n","   'colsample_bytree': 0.7,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0.5,\n","   'min_child_weight': 0.1,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.09878181048966037,\n","  'test_rmse': 0.31429573730749255,\n","  'test_corr_coef': 0.9552029073187112,\n","  'pruner': 'ThresholdPruner'},\n"," ('GPBoost', 'WilcoxonPruner'): {'best_score': 0.0987853693895994,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.15,\n","   'max_depth': 3,\n","   'num_leaves': 31,\n","   'min_child_samples': 1,\n","   'subsample': 1.0,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.001,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.0987853693895994,\n","  'test_rmse': 0.3143013989622054,\n","  'test_corr_coef': 0.9545465834260042,\n","  'pruner': 'WilcoxonPruner'},\n"," ('CatBoost', 'MedianPruner'): {'best_score': 0.10106934356001397,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.05,\n","   'depth': 10,\n","   'l2_leaf_reg': 1,\n","   'border_count': 32,\n","   'min_data_in_leaf': 1,\n","   'rsm': 0.6,\n","   'bagging_temperature': 1,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10106934356001397,\n","  'test_rmse': 0.3179140505860255,\n","  'test_corr_coef': 0.9546386164786963,\n","  'pruner': 'MedianPruner'},\n"," ('CatBoost', 'NopPruner'): {'best_score': 0.10208631062341576,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.1,\n","   'depth': 10,\n","   'l2_leaf_reg': 5,\n","   'border_count': 32,\n","   'min_data_in_leaf': 1,\n","   'rsm': 0.6,\n","   'bagging_temperature': 1,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10208631062341576,\n","  'test_rmse': 0.3195094844029137,\n","  'test_corr_coef': 0.9536489292255467,\n","  'pruner': 'NopPruner'},\n"," ('CatBoost', 'PatientPruner'): {'best_score': 0.1003834647979198,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.1,\n","   'depth': 8,\n","   'l2_leaf_reg': 9,\n","   'border_count': 32,\n","   'min_data_in_leaf': 1,\n","   'rsm': 0.6,\n","   'bagging_temperature': 1,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1003834647979198,\n","  'test_rmse': 0.3168334969631838,\n","  'test_corr_coef': 0.9548895428536669,\n","  'pruner': 'PatientPruner'},\n"," ('CatBoost', 'PercentilePruner'): {'best_score': 0.10305473754773768,\n","  'best_params': {'iterations': 1000,\n","   'learning_rate': 0.05,\n","   'depth': 6,\n","   'l2_leaf_reg': 9,\n","   'border_count': 32,\n","   'min_data_in_leaf': 20,\n","   'rsm': 0.6,\n","   'bagging_temperature': 1,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10305473754773768,\n","  'test_rmse': 0.3210213973362799,\n","  'test_corr_coef': 0.9525240172898933,\n","  'pruner': 'PercentilePruner'},\n"," ('CatBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.1003834647979198,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.1,\n","   'depth': 8,\n","   'l2_leaf_reg': 9,\n","   'border_count': 32,\n","   'min_data_in_leaf': 20,\n","   'rsm': 0.6,\n","   'bagging_temperature': 1,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1003834647979198,\n","  'test_rmse': 0.3168334969631838,\n","  'test_corr_coef': 0.9548895428536669,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('CatBoost', 'HyperbandPruner'): {'best_score': 0.10146578295486733,\n","  'best_params': {'iterations': 1000,\n","   'learning_rate': 0.05,\n","   'depth': 6,\n","   'l2_leaf_reg': 7,\n","   'border_count': 32,\n","   'min_data_in_leaf': 20,\n","   'rsm': 0.6,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10146578295486733,\n","  'test_rmse': 0.31853694127191484,\n","  'test_corr_coef': 0.9532680684984001,\n","  'pruner': 'HyperbandPruner'},\n"," ('CatBoost', 'ThresholdPruner'): {'best_score': 0.09767295423337319,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.05,\n","   'depth': 8,\n","   'l2_leaf_reg': 3,\n","   'border_count': 32,\n","   'min_data_in_leaf': 1,\n","   'rsm': 0.6,\n","   'bagging_temperature': 1,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.09767295423337319,\n","  'test_rmse': 0.31252672563058215,\n","  'test_corr_coef': 0.9555811756306276,\n","  'pruner': 'ThresholdPruner'},\n"," ('CatBoost', 'WilcoxonPruner'): {'best_score': 0.10301394884876003,\n","  'best_params': {'iterations': 1000,\n","   'learning_rate': 0.03,\n","   'depth': 10,\n","   'l2_leaf_reg': 1,\n","   'border_count': 32,\n","   'min_data_in_leaf': 20,\n","   'rsm': 0.6,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10301394884876003,\n","  'test_rmse': 0.3209578614845881,\n","  'test_corr_coef': 0.9533780849549102,\n","  'pruner': 'WilcoxonPruner'},\n"," ('NGBoost', 'MedianPruner'): {'best_score': 0.1152894704292283,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.7,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1152894704292283,\n","  'test_rmse': 0.3395430317783422,\n","  'test_corr_coef': 0.94829948182159,\n","  'pruner': 'MedianPruner'},\n"," ('NGBoost', 'NopPruner'): {'best_score': 0.1053248721899002,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.9,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1053248721899002,\n","  'test_rmse': 0.3245379364417975,\n","  'test_corr_coef': 0.9515051422827133,\n","  'pruner': 'NopPruner'},\n"," ('NGBoost', 'PatientPruner'): {'best_score': 0.10814930538358006,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.03,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.9,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10814930538358006,\n","  'test_rmse': 0.32886061695432617,\n","  'test_corr_coef': 0.9502270469565367,\n","  'pruner': 'PatientPruner'},\n"," ('NGBoost', 'PercentilePruner'): {'best_score': 0.11056190619997897,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.05,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.11056190619997897,\n","  'test_rmse': 0.33250850545509203,\n","  'test_corr_coef': 0.9491964948699997,\n","  'pruner': 'PercentilePruner'},\n"," ('NGBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.09867440584340595,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.7,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.09867440584340595,\n","  'test_rmse': 0.31412482525805874,\n","  'test_corr_coef': 0.9555069328657247,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('NGBoost', 'HyperbandPruner'): {'best_score': 0.09920488951527161,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.7,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.09920488951527161,\n","  'test_rmse': 0.314968076978083,\n","  'test_corr_coef': 0.955324861950893,\n","  'pruner': 'HyperbandPruner'},\n"," ('NGBoost', 'ThresholdPruner'): {'best_score': 0.10398453727198938,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.9,\n","   'col_sample': 0.5,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10398453727198938,\n","  'test_rmse': 0.32246633509870354,\n","  'test_corr_coef': 0.9521192503088859,\n","  'pruner': 'ThresholdPruner'},\n"," ('NGBoost', 'WilcoxonPruner'): {'best_score': 0.11995572624494273,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'natural_gradient': True,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.7,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.11995572624494273,\n","  'test_rmse': 0.34634625195740565,\n","  'test_corr_coef': 0.9448380125317961,\n","  'pruner': 'WilcoxonPruner'},\n"," ('HistGradientBoosting', 'MedianPruner'): {'best_score': 0.12180860652701989,\n","  'best_params': {'learning_rate': 0.15,\n","   'max_iter': 100,\n","   'max_depth': 5,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 31,\n","   'l2_regularization': 0.1,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 5,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.12180860652701989,\n","  'test_rmse': 0.34901089743304564,\n","  'test_corr_coef': 0.9435922436271997,\n","  'pruner': 'MedianPruner'},\n"," ('HistGradientBoosting', 'NopPruner'): {'best_score': 0.13828861645367616,\n","  'best_params': {'learning_rate': 0.15,\n","   'max_iter': 500,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 31,\n","   'l2_regularization': 0.1,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 10,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.13828861645367616,\n","  'test_rmse': 0.37187177420943923,\n","  'test_corr_coef': 0.9383213746817468,\n","  'pruner': 'NopPruner'},\n"," ('HistGradientBoosting', 'PatientPruner'): {'best_score': 0.1264288808167698,\n","  'best_params': {'learning_rate': 0.1,\n","   'max_iter': 100,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 31,\n","   'l2_regularization': 1.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1264288808167698,\n","  'test_rmse': 0.35556839119467554,\n","  'test_corr_coef': 0.9412981893132774,\n","  'pruner': 'PatientPruner'},\n"," ('HistGradientBoosting',\n","  'PercentilePruner'): {'best_score': 0.12530530053567965, 'best_params': {'learning_rate': 0.15,\n","   'max_iter': 400,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 15,\n","   'l2_regularization': 0.1,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.12530530053567965, 'test_rmse': 0.3539848874396754, 'test_corr_coef': 0.9419192007539792, 'pruner': 'PercentilePruner'},\n"," ('HistGradientBoosting',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.12672316359882632, 'best_params': {'learning_rate': 0.1,\n","   'max_iter': 100,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': None,\n","   'l2_regularization': 0.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.12672316359882632, 'test_rmse': 0.35598197089013695, 'test_corr_coef': 0.9424579886786292, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('HistGradientBoosting',\n","  'HyperbandPruner'): {'best_score': 0.12097258218439053, 'best_params': {'learning_rate': 0.15,\n","   'max_iter': 500,\n","   'max_depth': 5,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 15,\n","   'l2_regularization': 0.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.12097258218439053, 'test_rmse': 0.34781113004674036, 'test_corr_coef': 0.9438746742321596, 'pruner': 'HyperbandPruner'},\n"," ('HistGradientBoosting',\n","  'ThresholdPruner'): {'best_score': 0.13941846187656182, 'best_params': {'learning_rate': 0.1,\n","   'max_iter': 400,\n","   'max_depth': 5,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': 31,\n","   'l2_regularization': 0.5,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.13941846187656182, 'test_rmse': 0.37338781699000545, 'test_corr_coef': 0.937127149302789, 'pruner': 'ThresholdPruner'},\n"," ('HistGradientBoosting', 'WilcoxonPruner'): {'best_score': 0.1155150567364688,\n","  'best_params': {'learning_rate': 0.1,\n","   'max_iter': 400,\n","   'max_depth': 3,\n","   'min_samples_leaf': 5,\n","   'max_leaf_nodes': 63,\n","   'l2_regularization': 1.0,\n","   'max_bins': 64,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 15,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1155150567364688,\n","  'test_rmse': 0.3398750604802724,\n","  'test_corr_coef': 0.9469491597776423,\n","  'pruner': 'WilcoxonPruner'},\n"," ('PGBM', 'MedianPruner'): {'best_score': 0.12343258517328114,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.05,\n","   'max_leaves': 54,\n","   'min_split_gain': 0.0,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.7,\n","   'bagging_fraction': 0.7,\n","   'tree_correlation': 0.2,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.12343258517328114,\n","  'test_rmse': 0.3513297385267594,\n","  'test_corr_coef': 0.9433598369720617,\n","  'pruner': 'MedianPruner'},\n"," ('PGBM', 'NopPruner'): {'best_score': 0.1267295201974275,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'max_leaves': 35,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 5.0,\n","   'feature_fraction': 1.0,\n","   'bagging_fraction': 0.5,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 5,\n","   'max_bin': 64,\n","   'distribution': 'studentt'},\n","  'test_mse': 0.1267295201974275,\n","  'test_rmse': 0.35599089903735953,\n","  'test_corr_coef': 0.941140480780901,\n","  'pruner': 'NopPruner'},\n"," ('PGBM', 'PatientPruner'): {'best_score': 0.129824463608949,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.15,\n","   'max_leaves': 38,\n","   'min_split_gain': 0.5,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 1.0,\n","   'bagging_fraction': 0.5,\n","   'tree_correlation': 0.0,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.129824463608949,\n","  'test_rmse': 0.3603116201414395,\n","  'test_corr_coef': 0.9407616347982253,\n","  'pruner': 'PatientPruner'},\n"," ('PGBM', 'PercentilePruner'): {'best_score': 0.1034742435248506,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.05,\n","   'max_leaves': 30,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.7,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.1034742435248506,\n","  'test_rmse': 0.3216741262906462,\n","  'test_corr_coef': 0.9526262297145519,\n","  'pruner': 'PercentilePruner'},\n"," ('PGBM', 'SuccessiveHalvingPruner'): {'best_score': 0.07826943068929365,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.15,\n","   'max_leaves': 31,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.1,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'normal'},\n","  'test_mse': 0.07826943068929365,\n","  'test_rmse': 0.27976674335827273,\n","  'test_corr_coef': 0.9647067432415465,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('PGBM', 'HyperbandPruner'): {'best_score': 0.10804920612728598,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.15,\n","   'max_leaves': 52,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 1.0,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 0.5,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'studentt'},\n","  'test_mse': 0.10804920612728598,\n","  'test_rmse': 0.32870839071627905,\n","  'test_corr_coef': 0.950103255895245,\n","  'pruner': 'HyperbandPruner'},\n"," ('PGBM', 'ThresholdPruner'): {'best_score': 0.09417793540001096,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'max_leaves': 52,\n","   'min_split_gain': 0.0,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.0,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'normal'},\n","  'test_mse': 0.09417793540001096,\n","  'test_rmse': 0.3068842377835834,\n","  'test_corr_coef': 0.959620971727772,\n","  'pruner': 'ThresholdPruner'},\n"," ('PGBM', 'WilcoxonPruner'): {'best_score': 0.11682202319670179,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.15,\n","   'max_leaves': 61,\n","   'min_split_gain': 0.1,\n","   'reg_lambda': 10.0,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 0.9,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 64,\n","   'distribution': 'studentt'},\n","  'test_mse': 0.11682202319670179,\n","  'test_rmse': 0.34179236854661016,\n","  'test_corr_coef': 0.9475122997898101,\n","  'pruner': 'WilcoxonPruner'}}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"N9uWqgUD3pKn"},"source":["# **Best Model Analysis**"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"QifO8ipK2ZdZ","executionInfo":{"status":"ok","timestamp":1746268600144,"user_tz":-330,"elapsed":8317,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de6bd7f5-dd5c-4626-8e24-c2122f579c16"},"outputs":[{"output_type":"stream","name":"stdout","text":["0:\tlearn: 1.2343268\ttotal: 625us\tremaining: 124ms\n","1:\tlearn: 1.2023823\ttotal: 3.48ms\tremaining: 345ms\n","2:\tlearn: 1.1741945\ttotal: 5.18ms\tremaining: 340ms\n","3:\tlearn: 1.1400185\ttotal: 5.84ms\tremaining: 286ms\n","4:\tlearn: 1.1142713\ttotal: 6.51ms\tremaining: 254ms\n","5:\tlearn: 1.0781424\ttotal: 7.14ms\tremaining: 231ms\n","6:\tlearn: 1.0510771\ttotal: 7.59ms\tremaining: 209ms\n","7:\tlearn: 1.0234894\ttotal: 8.11ms\tremaining: 195ms\n","8:\tlearn: 0.9975653\ttotal: 8.73ms\tremaining: 185ms\n","9:\tlearn: 0.9753634\ttotal: 9.3ms\tremaining: 177ms\n","10:\tlearn: 0.9563176\ttotal: 9.91ms\tremaining: 170ms\n","11:\tlearn: 0.9315662\ttotal: 10.2ms\tremaining: 160ms\n","12:\tlearn: 0.9081748\ttotal: 10.6ms\tremaining: 153ms\n","13:\tlearn: 0.8852994\ttotal: 11.2ms\tremaining: 149ms\n","14:\tlearn: 0.8676395\ttotal: 11.7ms\tremaining: 145ms\n","15:\tlearn: 0.8508571\ttotal: 12.2ms\tremaining: 141ms\n","16:\tlearn: 0.8346124\ttotal: 12.9ms\tremaining: 139ms\n","17:\tlearn: 0.8177064\ttotal: 13.4ms\tremaining: 136ms\n","18:\tlearn: 0.8016788\ttotal: 13.9ms\tremaining: 133ms\n","19:\tlearn: 0.7843528\ttotal: 14.4ms\tremaining: 130ms\n","20:\tlearn: 0.7690379\ttotal: 14.7ms\tremaining: 125ms\n","21:\tlearn: 0.7529626\ttotal: 15.1ms\tremaining: 122ms\n","22:\tlearn: 0.7410013\ttotal: 15.6ms\tremaining: 120ms\n","23:\tlearn: 0.7271601\ttotal: 17.1ms\tremaining: 125ms\n","24:\tlearn: 0.7135423\ttotal: 19.4ms\tremaining: 136ms\n","25:\tlearn: 0.6988966\ttotal: 20.4ms\tremaining: 136ms\n","26:\tlearn: 0.6876540\ttotal: 20.6ms\tremaining: 132ms\n","27:\tlearn: 0.6724814\ttotal: 21.1ms\tremaining: 129ms\n","28:\tlearn: 0.6633664\ttotal: 21.6ms\tremaining: 127ms\n","29:\tlearn: 0.6527029\ttotal: 22ms\tremaining: 125ms\n","30:\tlearn: 0.6390307\ttotal: 22.6ms\tremaining: 123ms\n","31:\tlearn: 0.6306566\ttotal: 23ms\tremaining: 121ms\n","32:\tlearn: 0.6218534\ttotal: 23.6ms\tremaining: 119ms\n","33:\tlearn: 0.6102368\ttotal: 24.2ms\tremaining: 118ms\n","34:\tlearn: 0.6013184\ttotal: 24.5ms\tremaining: 116ms\n","35:\tlearn: 0.5885164\ttotal: 25ms\tremaining: 114ms\n","36:\tlearn: 0.5791069\ttotal: 25.3ms\tremaining: 111ms\n","37:\tlearn: 0.5699113\ttotal: 25.4ms\tremaining: 108ms\n","38:\tlearn: 0.5598535\ttotal: 26ms\tremaining: 107ms\n","39:\tlearn: 0.5536952\ttotal: 26.3ms\tremaining: 105ms\n","40:\tlearn: 0.5450032\ttotal: 26.7ms\tremaining: 104ms\n","41:\tlearn: 0.5367895\ttotal: 26.9ms\tremaining: 101ms\n","42:\tlearn: 0.5293966\ttotal: 27.4ms\tremaining: 100ms\n","43:\tlearn: 0.5221323\ttotal: 27.8ms\tremaining: 98.7ms\n","44:\tlearn: 0.5148888\ttotal: 28.3ms\tremaining: 97.5ms\n","45:\tlearn: 0.5074984\ttotal: 28.7ms\tremaining: 96.2ms\n","46:\tlearn: 0.5010337\ttotal: 29.1ms\tremaining: 94.8ms\n","47:\tlearn: 0.4917951\ttotal: 29.7ms\tremaining: 94ms\n","48:\tlearn: 0.4857598\ttotal: 30.2ms\tremaining: 93.1ms\n","49:\tlearn: 0.4795286\ttotal: 30.7ms\tremaining: 92ms\n","50:\tlearn: 0.4717082\ttotal: 31.1ms\tremaining: 90.8ms\n","51:\tlearn: 0.4659006\ttotal: 31.3ms\tremaining: 89.1ms\n","52:\tlearn: 0.4614202\ttotal: 31.9ms\tremaining: 88.4ms\n","53:\tlearn: 0.4553084\ttotal: 33.1ms\tremaining: 89.6ms\n","54:\tlearn: 0.4499477\ttotal: 33.6ms\tremaining: 88.6ms\n","55:\tlearn: 0.4452871\ttotal: 34.1ms\tremaining: 87.6ms\n","56:\tlearn: 0.4402931\ttotal: 34.6ms\tremaining: 86.7ms\n","57:\tlearn: 0.4360507\ttotal: 34.9ms\tremaining: 85.5ms\n","58:\tlearn: 0.4307129\ttotal: 35.3ms\tremaining: 84.5ms\n","59:\tlearn: 0.4253727\ttotal: 35.9ms\tremaining: 83.8ms\n","60:\tlearn: 0.4207508\ttotal: 36.4ms\tremaining: 83ms\n","61:\tlearn: 0.4161409\ttotal: 36.9ms\tremaining: 82.2ms\n","62:\tlearn: 0.4119147\ttotal: 37.4ms\tremaining: 81.3ms\n","63:\tlearn: 0.4064657\ttotal: 37.9ms\tremaining: 80.5ms\n","64:\tlearn: 0.4032537\ttotal: 38.4ms\tremaining: 79.7ms\n","65:\tlearn: 0.3985146\ttotal: 38.9ms\tremaining: 79ms\n","66:\tlearn: 0.3949261\ttotal: 39.3ms\tremaining: 78.1ms\n","67:\tlearn: 0.3916414\ttotal: 39.5ms\tremaining: 76.7ms\n","68:\tlearn: 0.3886313\ttotal: 39.8ms\tremaining: 75.7ms\n","69:\tlearn: 0.3858001\ttotal: 40.4ms\tremaining: 75ms\n","70:\tlearn: 0.3819772\ttotal: 40.6ms\tremaining: 73.7ms\n","71:\tlearn: 0.3778723\ttotal: 41ms\tremaining: 73ms\n","72:\tlearn: 0.3741628\ttotal: 41.5ms\tremaining: 72.2ms\n","73:\tlearn: 0.3704688\ttotal: 41.9ms\tremaining: 71.3ms\n","74:\tlearn: 0.3672374\ttotal: 42.4ms\tremaining: 70.6ms\n","75:\tlearn: 0.3638305\ttotal: 42.9ms\tremaining: 70.1ms\n","76:\tlearn: 0.3591201\ttotal: 43.4ms\tremaining: 69.3ms\n","77:\tlearn: 0.3559815\ttotal: 43.8ms\tremaining: 68.5ms\n","78:\tlearn: 0.3541834\ttotal: 44ms\tremaining: 67.4ms\n","79:\tlearn: 0.3512931\ttotal: 44.5ms\tremaining: 66.7ms\n","80:\tlearn: 0.3489425\ttotal: 45ms\tremaining: 66.1ms\n","81:\tlearn: 0.3468008\ttotal: 45.5ms\tremaining: 65.5ms\n","82:\tlearn: 0.3441529\ttotal: 46ms\tremaining: 64.9ms\n","83:\tlearn: 0.3419334\ttotal: 46.5ms\tremaining: 64.2ms\n","84:\tlearn: 0.3396354\ttotal: 46.9ms\tremaining: 63.5ms\n","85:\tlearn: 0.3367233\ttotal: 47.3ms\tremaining: 62.8ms\n","86:\tlearn: 0.3345234\ttotal: 47.7ms\tremaining: 62ms\n","87:\tlearn: 0.3334075\ttotal: 47.8ms\tremaining: 60.9ms\n","88:\tlearn: 0.3306814\ttotal: 48.2ms\tremaining: 60.1ms\n","89:\tlearn: 0.3278456\ttotal: 48.6ms\tremaining: 59.4ms\n","90:\tlearn: 0.3257702\ttotal: 49ms\tremaining: 58.7ms\n","91:\tlearn: 0.3238061\ttotal: 49.4ms\tremaining: 58ms\n","92:\tlearn: 0.3212075\ttotal: 49.9ms\tremaining: 57.4ms\n","93:\tlearn: 0.3188625\ttotal: 50.4ms\tremaining: 56.8ms\n","94:\tlearn: 0.3161833\ttotal: 50.9ms\tremaining: 56.2ms\n","95:\tlearn: 0.3138586\ttotal: 51.4ms\tremaining: 55.7ms\n","96:\tlearn: 0.3111710\ttotal: 51.8ms\tremaining: 55ms\n","97:\tlearn: 0.3090886\ttotal: 52.3ms\tremaining: 54.4ms\n","98:\tlearn: 0.3072115\ttotal: 52.8ms\tremaining: 53.8ms\n","99:\tlearn: 0.3055431\ttotal: 53.2ms\tremaining: 53.2ms\n","100:\tlearn: 0.3035539\ttotal: 53.7ms\tremaining: 52.7ms\n","101:\tlearn: 0.3012340\ttotal: 54.1ms\tremaining: 52ms\n","102:\tlearn: 0.2991410\ttotal: 54.6ms\tremaining: 51.5ms\n","103:\tlearn: 0.2969781\ttotal: 55.2ms\tremaining: 50.9ms\n","104:\tlearn: 0.2950229\ttotal: 55.6ms\tremaining: 50.3ms\n","105:\tlearn: 0.2932666\ttotal: 56.1ms\tremaining: 49.8ms\n","106:\tlearn: 0.2918949\ttotal: 56.3ms\tremaining: 48.9ms\n","107:\tlearn: 0.2892740\ttotal: 56.7ms\tremaining: 48.3ms\n","108:\tlearn: 0.2880090\ttotal: 57.3ms\tremaining: 47.8ms\n","109:\tlearn: 0.2861301\ttotal: 57.7ms\tremaining: 47.2ms\n","110:\tlearn: 0.2847880\ttotal: 58.1ms\tremaining: 46.6ms\n","111:\tlearn: 0.2833665\ttotal: 58.6ms\tremaining: 46.1ms\n","112:\tlearn: 0.2817782\ttotal: 59.1ms\tremaining: 45.5ms\n","113:\tlearn: 0.2799644\ttotal: 59.6ms\tremaining: 45ms\n","114:\tlearn: 0.2794029\ttotal: 59.7ms\tremaining: 44.1ms\n","115:\tlearn: 0.2778417\ttotal: 60.1ms\tremaining: 43.6ms\n","116:\tlearn: 0.2761951\ttotal: 60.6ms\tremaining: 43ms\n","117:\tlearn: 0.2737838\ttotal: 61ms\tremaining: 42.4ms\n","118:\tlearn: 0.2722769\ttotal: 61.5ms\tremaining: 41.9ms\n","119:\tlearn: 0.2704637\ttotal: 61.9ms\tremaining: 41.3ms\n","120:\tlearn: 0.2697502\ttotal: 62.2ms\tremaining: 40.6ms\n","121:\tlearn: 0.2683022\ttotal: 62.7ms\tremaining: 40.1ms\n","122:\tlearn: 0.2667721\ttotal: 63.2ms\tremaining: 39.6ms\n","123:\tlearn: 0.2656284\ttotal: 63.6ms\tremaining: 39ms\n","124:\tlearn: 0.2646682\ttotal: 64.1ms\tremaining: 38.5ms\n","125:\tlearn: 0.2631037\ttotal: 64.6ms\tremaining: 37.9ms\n","126:\tlearn: 0.2615511\ttotal: 65.1ms\tremaining: 37.4ms\n","127:\tlearn: 0.2597689\ttotal: 65.6ms\tremaining: 36.9ms\n","128:\tlearn: 0.2584870\ttotal: 66.1ms\tremaining: 36.4ms\n","129:\tlearn: 0.2573161\ttotal: 66.6ms\tremaining: 35.9ms\n","130:\tlearn: 0.2561569\ttotal: 67.1ms\tremaining: 35.3ms\n","131:\tlearn: 0.2547294\ttotal: 67.6ms\tremaining: 34.8ms\n","132:\tlearn: 0.2536560\ttotal: 68.1ms\tremaining: 34.3ms\n","133:\tlearn: 0.2520095\ttotal: 68.7ms\tremaining: 33.8ms\n","134:\tlearn: 0.2504994\ttotal: 69ms\tremaining: 33.2ms\n","135:\tlearn: 0.2486421\ttotal: 69.5ms\tremaining: 32.7ms\n","136:\tlearn: 0.2479288\ttotal: 70ms\tremaining: 32.2ms\n","137:\tlearn: 0.2468522\ttotal: 70.3ms\tremaining: 31.6ms\n","138:\tlearn: 0.2455745\ttotal: 70.9ms\tremaining: 31.1ms\n","139:\tlearn: 0.2443103\ttotal: 71.3ms\tremaining: 30.6ms\n","140:\tlearn: 0.2428960\ttotal: 71.9ms\tremaining: 30.1ms\n","141:\tlearn: 0.2415803\ttotal: 72.3ms\tremaining: 29.5ms\n","142:\tlearn: 0.2405116\ttotal: 72.8ms\tremaining: 29ms\n","143:\tlearn: 0.2394794\ttotal: 73.2ms\tremaining: 28.5ms\n","144:\tlearn: 0.2382229\ttotal: 73.7ms\tremaining: 28ms\n","145:\tlearn: 0.2366289\ttotal: 74.1ms\tremaining: 27.4ms\n","146:\tlearn: 0.2355727\ttotal: 74.6ms\tremaining: 26.9ms\n","147:\tlearn: 0.2342066\ttotal: 75.2ms\tremaining: 26.4ms\n","148:\tlearn: 0.2329011\ttotal: 75.6ms\tremaining: 25.9ms\n","149:\tlearn: 0.2312285\ttotal: 76.1ms\tremaining: 25.4ms\n","150:\tlearn: 0.2301025\ttotal: 76.5ms\tremaining: 24.8ms\n","151:\tlearn: 0.2287852\ttotal: 76.8ms\tremaining: 24.2ms\n","152:\tlearn: 0.2274435\ttotal: 77.2ms\tremaining: 23.7ms\n","153:\tlearn: 0.2265375\ttotal: 77.7ms\tremaining: 23.2ms\n","154:\tlearn: 0.2246245\ttotal: 78.2ms\tremaining: 22.7ms\n","155:\tlearn: 0.2236117\ttotal: 78.7ms\tremaining: 22.2ms\n","156:\tlearn: 0.2225540\ttotal: 79.1ms\tremaining: 21.7ms\n","157:\tlearn: 0.2209360\ttotal: 79.6ms\tremaining: 21.2ms\n","158:\tlearn: 0.2200447\ttotal: 80ms\tremaining: 20.6ms\n","159:\tlearn: 0.2184088\ttotal: 80.4ms\tremaining: 20.1ms\n","160:\tlearn: 0.2167634\ttotal: 80.9ms\tremaining: 19.6ms\n","161:\tlearn: 0.2158527\ttotal: 81.4ms\tremaining: 19.1ms\n","162:\tlearn: 0.2146977\ttotal: 81.9ms\tremaining: 18.6ms\n","163:\tlearn: 0.2138035\ttotal: 82.4ms\tremaining: 18.1ms\n","164:\tlearn: 0.2130550\ttotal: 82.9ms\tremaining: 17.6ms\n","165:\tlearn: 0.2121628\ttotal: 83.3ms\tremaining: 17.1ms\n","166:\tlearn: 0.2111502\ttotal: 83.6ms\tremaining: 16.5ms\n","167:\tlearn: 0.2106021\ttotal: 84.1ms\tremaining: 16ms\n","168:\tlearn: 0.2095114\ttotal: 84.7ms\tremaining: 15.5ms\n","169:\tlearn: 0.2088892\ttotal: 84.9ms\tremaining: 15ms\n","170:\tlearn: 0.2083614\ttotal: 85.3ms\tremaining: 14.5ms\n","171:\tlearn: 0.2072576\ttotal: 85.8ms\tremaining: 14ms\n","172:\tlearn: 0.2065647\ttotal: 86.3ms\tremaining: 13.5ms\n","173:\tlearn: 0.2058503\ttotal: 86.7ms\tremaining: 13ms\n","174:\tlearn: 0.2046019\ttotal: 87.2ms\tremaining: 12.5ms\n","175:\tlearn: 0.2037944\ttotal: 87.7ms\tremaining: 12ms\n","176:\tlearn: 0.2029120\ttotal: 88.2ms\tremaining: 11.5ms\n","177:\tlearn: 0.2020531\ttotal: 88.7ms\tremaining: 11ms\n","178:\tlearn: 0.2016231\ttotal: 89.2ms\tremaining: 10.5ms\n","179:\tlearn: 0.2011849\ttotal: 89.7ms\tremaining: 9.97ms\n","180:\tlearn: 0.2005820\ttotal: 90.2ms\tremaining: 9.47ms\n","181:\tlearn: 0.1998403\ttotal: 90.8ms\tremaining: 8.98ms\n","182:\tlearn: 0.1989431\ttotal: 91.3ms\tremaining: 8.48ms\n","183:\tlearn: 0.1981223\ttotal: 91.8ms\tremaining: 7.98ms\n","184:\tlearn: 0.1975011\ttotal: 92.3ms\tremaining: 7.49ms\n","185:\tlearn: 0.1962365\ttotal: 92.8ms\tremaining: 6.98ms\n","186:\tlearn: 0.1948298\ttotal: 93.2ms\tremaining: 6.48ms\n","187:\tlearn: 0.1935576\ttotal: 93.7ms\tremaining: 5.98ms\n","188:\tlearn: 0.1931969\ttotal: 94.1ms\tremaining: 5.48ms\n","189:\tlearn: 0.1923677\ttotal: 94.5ms\tremaining: 4.97ms\n","190:\tlearn: 0.1910353\ttotal: 95ms\tremaining: 4.48ms\n","191:\tlearn: 0.1897037\ttotal: 95.4ms\tremaining: 3.98ms\n","192:\tlearn: 0.1883280\ttotal: 95.9ms\tremaining: 3.48ms\n","193:\tlearn: 0.1870188\ttotal: 96.4ms\tremaining: 2.98ms\n","194:\tlearn: 0.1862296\ttotal: 96.7ms\tremaining: 2.48ms\n","195:\tlearn: 0.1858922\ttotal: 97.2ms\tremaining: 1.98ms\n","196:\tlearn: 0.1849972\ttotal: 97.8ms\tremaining: 1.49ms\n","197:\tlearn: 0.1846496\ttotal: 98.3ms\tremaining: 993us\n","198:\tlearn: 0.1838896\ttotal: 99ms\tremaining: 497us\n","199:\tlearn: 0.1831516\ttotal: 99.4ms\tremaining: 0us\n","Training on CPU\n","Estimator 0/100, Train metric: 1.1031\n","Estimator 1/100, Train metric: 0.9614\n","Estimator 2/100, Train metric: 0.8437\n","Estimator 3/100, Train metric: 0.7432\n","Estimator 4/100, Train metric: 0.6615\n","Estimator 5/100, Train metric: 0.5884\n","Estimator 6/100, Train metric: 0.5210\n","Estimator 7/100, Train metric: 0.4718\n","Estimator 8/100, Train metric: 0.4300\n","Estimator 9/100, Train metric: 0.3937\n","Estimator 10/100, Train metric: 0.3633\n","Estimator 11/100, Train metric: 0.3385\n","Estimator 12/100, Train metric: 0.3191\n","Estimator 13/100, Train metric: 0.3044\n","Estimator 14/100, Train metric: 0.2911\n","Estimator 15/100, Train metric: 0.2781\n","Estimator 16/100, Train metric: 0.2688\n","Estimator 17/100, Train metric: 0.2612\n","Estimator 18/100, Train metric: 0.2555\n","Estimator 19/100, Train metric: 0.2474\n","Estimator 20/100, Train metric: 0.2453\n","Estimator 21/100, Train metric: 0.2426\n","Estimator 22/100, Train metric: 0.2359\n","Estimator 23/100, Train metric: 0.2302\n","Estimator 24/100, Train metric: 0.2292\n","Estimator 25/100, Train metric: 0.2236\n","Estimator 26/100, Train metric: 0.2203\n","Estimator 27/100, Train metric: 0.2183\n","Estimator 28/100, Train metric: 0.2183\n","Estimator 29/100, Train metric: 0.2183\n","Estimator 30/100, Train metric: 0.2183\n","Estimator 31/100, Train metric: 0.2183\n","Estimator 32/100, Train metric: 0.2183\n","Estimator 33/100, Train metric: 0.2183\n","Estimator 34/100, Train metric: 0.2183\n","Estimator 35/100, Train metric: 0.2183\n","Estimator 36/100, Train metric: 0.2183\n","Estimator 37/100, Train metric: 0.2183\n","Estimator 38/100, Train metric: 0.2183\n","Estimator 39/100, Train metric: 0.2183\n","Estimator 40/100, Train metric: 0.2183\n","Estimator 41/100, Train metric: 0.2183\n","Estimator 42/100, Train metric: 0.2183\n","Estimator 43/100, Train metric: 0.2183\n","Estimator 44/100, Train metric: 0.2183\n","Estimator 45/100, Train metric: 0.2183\n","Estimator 46/100, Train metric: 0.2183\n","Estimator 47/100, Train metric: 0.2183\n","Estimator 48/100, Train metric: 0.2183\n","Estimator 49/100, Train metric: 0.2183\n","Estimator 50/100, Train metric: 0.2183\n","Estimator 51/100, Train metric: 0.2183\n","Estimator 52/100, Train metric: 0.2183\n","Estimator 53/100, Train metric: 0.2183\n","Estimator 54/100, Train metric: 0.2183\n","Estimator 55/100, Train metric: 0.2183\n","Estimator 56/100, Train metric: 0.2183\n","Estimator 57/100, Train metric: 0.2183\n","Estimator 58/100, Train metric: 0.2183\n","Estimator 59/100, Train metric: 0.2183\n","Estimator 60/100, Train metric: 0.2183\n","Estimator 61/100, Train metric: 0.2183\n","Estimator 62/100, Train metric: 0.2183\n","Estimator 63/100, Train metric: 0.2183\n","Estimator 64/100, Train metric: 0.2183\n","Estimator 65/100, Train metric: 0.2183\n","Estimator 66/100, Train metric: 0.2183\n","Estimator 67/100, Train metric: 0.2183\n","Estimator 68/100, Train metric: 0.2183\n","Estimator 69/100, Train metric: 0.2183\n","Estimator 70/100, Train metric: 0.2183\n","Estimator 71/100, Train metric: 0.2183\n","Estimator 72/100, Train metric: 0.2183\n","Estimator 73/100, Train metric: 0.2183\n","Estimator 74/100, Train metric: 0.2183\n","Estimator 75/100, Train metric: 0.2183\n","Estimator 76/100, Train metric: 0.2183\n","Estimator 77/100, Train metric: 0.2183\n","Estimator 78/100, Train metric: 0.2183\n","Estimator 79/100, Train metric: 0.2183\n","Estimator 80/100, Train metric: 0.2183\n","Estimator 81/100, Train metric: 0.2183\n","Estimator 82/100, Train metric: 0.2183\n","Estimator 83/100, Train metric: 0.2183\n","Estimator 84/100, Train metric: 0.2183\n","Estimator 85/100, Train metric: 0.2183\n","Estimator 86/100, Train metric: 0.2183\n","Estimator 87/100, Train metric: 0.2183\n","Estimator 88/100, Train metric: 0.2183\n","Estimator 89/100, Train metric: 0.2183\n","Estimator 90/100, Train metric: 0.2183\n","Estimator 91/100, Train metric: 0.2183\n","Estimator 92/100, Train metric: 0.2183\n","Estimator 93/100, Train metric: 0.2183\n","Estimator 94/100, Train metric: 0.2183\n","Estimator 95/100, Train metric: 0.2183\n","Estimator 96/100, Train metric: 0.2183\n","Estimator 97/100, Train metric: 0.2183\n","Estimator 98/100, Train metric: 0.2183\n","Estimator 99/100, Train metric: 0.2183\n"]}],"source":["def get_best_models_and_predict(best_scores_autosampler, X_train, y_train, X_test, y_test, file_path):\n","    # Convert input data to NumPy arrays\n","    X_train = np.array(X_train)\n","    y_train = np.array(y_train)\n","    X_test = np.array(X_test)\n","    y_test = np.array(y_test)\n","\n","    # Mapping for model creation based on dictionary keys\n","    model_mapping = {\n","        'Random Forest': RandomForestRegressor,\n","        'Gradient Boosting': GradientBoostingRegressor,\n","        'XGBoost': XGBRegressor,\n","        'LightGBM': LGBMRegressor,\n","        'CatBoost': CatBoostRegressor,\n","        'GPBoost': GPBoostRegressor,\n","        'NGBoost': NGBRegressor,\n","        'HistGradientBoosting': HistGradientBoostingRegressor,\n","        'PGBM': PGBM  # PGBM is handled separately\n","    }\n","\n","    # Dictionary to store the best model for each type\n","    best_models = {}\n","\n","    # Iterate over the dictionary to find the best pruner for each model type\n","    for (model_name, pruner), params in best_scores_autosampler.items():\n","        current_score = params.get('test_mse', np.inf)\n","        if model_name not in best_models or current_score < best_models[model_name]['score']:\n","            best_models[model_name] = {\n","                'score': current_score,\n","                'params': params['best_params'],\n","                'pruner': pruner\n","            }\n","\n","    # Prepare a DataFrame to store predictions\n","    df = pd.read_csv(file_path)\n","\n","    # Iterate over the best models to train and predict\n","    for model_name, model_info in best_models.items():\n","        best_params = model_info['params']\n","        model_class = model_mapping.get(model_name)\n","\n","        if model_class is None:\n","            print(f\"Model {model_name} is not supported or not available.\")\n","            continue\n","\n","        # Handle specific parameters or settings for model if needed\n","        if model_name == 'CatBoost':\n","            best_params.pop('verbose', None)  # Remove 'verbose' for CatBoost\n","\n","        # Create an instance of the best model with the best parameters\n","        if model_name == 'PGBM':\n","            model = model_class()\n","            model.train((X_train, y_train), objective=mseloss_objective, metric=rmseloss_metric, params=best_params)\n","            predictions = model.predict(X_test)\n","        else:\n","            model = model_class(**best_params)\n","            model.fit(X_train, y_train)\n","            predictions = model.predict(X_test)\n","\n","        # Add predictions to the DataFrame\n","        df[f'{model_name} Predictions'] = predictions\n","\n","        # Plot actual vs. predicted\n","        plt.figure(figsize=(10, 6))\n","        plt.scatter(y_test, predictions, alpha=0.6)\n","        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', color='red', lw=2)\n","        plt.xlabel(\"Actual\")\n","        plt.ylabel(\"Predicted\")\n","        plt.title(f\"Actual vs. Predicted Values ({model_name})\")\n","        plt.grid(True)\n","        plt.tight_layout()\n","\n","        # Save the plot temporarily\n","        plot_path = f'temp_plot_{model_name}.png'\n","        plt.savefig(plot_path)\n","        plt.close()\n","\n","    # Save predictions and plots to Excel\n","    with pd.ExcelWriter(file_path.replace('.csv', '_results.xlsx'), engine='xlsxwriter') as writer:\n","        # Write data to Excel\n","        df.to_excel(writer, sheet_name='Data', index=False)\n","\n","        # Get the xlsxwriter objects\n","        workbook = writer.book\n","\n","        # Insert each plot into a separate worksheet\n","        for model_name in best_models.keys():\n","            # Shorten the worksheet name to fit within Excel's 31 character limit\n","            short_model_name = ''.join([word[0] for word in model_name.split()])  # e.g., 'RF' for 'Random Forest'\n","            sheet_name = f'{short_model_name}_Plot'\n","\n","            worksheet = workbook.add_worksheet(sheet_name)\n","            writer.sheets[sheet_name] = worksheet\n","            plot_path = f'temp_plot_{model_name}.png'\n","            worksheet.insert_image('A1', plot_path)\n","\n","    # Clean up temporary plot files\n","    for model_name in best_models.keys():\n","        os.remove(f'temp_plot_{model_name}.png')\n","\n","    return df, best_models\n","\n","# Call the function\n","df, best_models = get_best_models_and_predict(best_scores_autosampler, X_train, y_train, X_test, y_test, \"./drive/MyDrive/SCOUR/Scour_uncertainity/test.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"WiVmP0QP3pKn","executionInfo":{"status":"ok","timestamp":1746268601395,"user_tz":-330,"elapsed":1243,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}}},"outputs":[],"source":["plot_best_scores(best_scores_autosampler,\"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/HyperParameter_Tuning/test_results.xlsx\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ynnJWQRA3pKn","colab":{"base_uri":"https://localhost:8080/","height":397,"referenced_widgets":["7879eb771c88464bb8e17951be712ab9","1548fc736235427f9fd98990851927a7","a412341972a04922b6e89ab2016520cc","49c85061e6ac4cb58e5580884e86948c","ad25bbaed13a4f4c94ff34da56ebd277","1fbd1ab8780c479c809391772b1e3fb5","b1035950e3d644e4b8512b3fd00ee4b4","344fb345296a4ca682a3d85ec5f05841","2a75dba0e2c842cba3fc1ae51f258419","46f69b42b68742a380d6dbc1646a1e72","fe2d4973c1674c1280cbd18a2a40ea0a","f24e6dc3c934434c838dc8a5a505c291","768e9c3bd9bd44c4bbfa1a6b4e64bbcf","e7443ae0d2684eceab74703bd8fa8e3f","df6cf95039844850b5e645ab212b19fb","7d81968df19b460fbaaf09ecc4fbee15","312c7457be4846da9430978ec48e03c9","ea9b3efaba9748d082dda5328e330fa6","68aa4fa11bef4ed3a3d95d4360237128","3e30a2214ab9418e8d259a38b8adfdd2","e696fe8ead56442588c784e7c73abd89","8fec7163c92d4ea1b6b93c14741bcb89","a6c2444243c149ff8c0f66f7af07a0a4","9f5d00d7e7254040990ce20e87f7f66d","41897251d7e04b56a4c124008192e35c","a3b1be3b46cc4b098430452fc078571c","1748789afd354451b00fed3ec9f1568a","44749829308b4ad0ada4df9ae7575fb3","78f9a079fd434e8f8d854027d7653ab9","44496d6a8e8c4f7c86b9bf2a6d9b64a9","7b788d4b7f1c497086c2e8bc4eb1ef4e","9eddebfad2604da389267926e01f50f9","4598a93a5a844dd2829e46c09caffa07","f0f964e6bc594707a23abd003617644c","c3cf908b283b450d9d330a240eda596e","a5344cab96ae4b1c9c1301bdf7d05f2a","905d386fa9f64f72b11b7a31fa6cc529","e9e24716983543cdb8bcdf6911991399","eabfffba963649af9fc6648cef785c38","d20a0129b3e346fdb06baad821788f40","385df22dd335463486baa13697a2a534","6352cd0c27a541e0a7b9bbd0973a4b38","bb09f731cfa0427fa13b2d11e8aa4b66","983356d40a9c49819a98e4da73fdfb70","505f1c3d03614194a514ce654016f24a","06dc763121954c39a300a7e3873ba9f0","c080b6651d034bda95055eb0f0a3f0d8","22f0c4ad7266428e88b8a674cc1308b4","d31c97516e144dbf88dc2ef593689762","e79583c7ace1485cb3a994c8e1fc8dea","451b7028d1e14a38bac836a768fa4a27","37868b788b49418b93a0a5f0d4a7c5ca","ff5b76e1c42a473da77924edc4e10ef9","989272befd674a15974f588841b3395e","4d181233290344ea8c8658e603575845","95e1ac104cba40eea1da93629f321f93","53b415af044a43e4acd19f4322aea129","cc5335b34d8c4704a4b1ae0017fdfdc7","295edccde0b949df813109ce005211ce","f64288328a16448aabe4a3f803bc5684","4a8a2441372848b783e032f140f14a4c","3bb4b31ea0f7407c97b62fe052647c24","0a734537d9b547c499f83532f174442a","d408ee3adf9e4e0db9a83c4488bab90b","1e5edfa219204cfc82b55c11cf2c1e0c","cbe94ffbd6a9485d811ab9dd18ea9a70","9a4bf8ee1ae94bc2bc110880d9b30514","5a5fd337fad140c9873ba58a3a937895","6838b8a50ac542ceb356945d7ee02fef","91378540f3894ab7a02e1f40c2c01f93","30fe44512c8a407f85ffb85cec5e7335","6973e55e45c642a0ac2322b69f2ea76c","1b203654b98a4fdc9b5230ba04cd4608","fac60ba2a7f44277b8cb04b2c593c5e1","2e37923930254efa9c29850f2363eca4","96c40ff3fc1f497b9066788627f28d30","38493ba7a2b54858be6b9ab79727170e"]},"executionInfo":{"status":"ok","timestamp":1746268910837,"user_tz":-330,"elapsed":309431,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}},"outputId":"d9a22c36-5e72-476e-c28c-664152df59eb"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:shap:Using 154 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/78 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7879eb771c88464bb8e17951be712ab9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:shap:Using 154 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/78 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f24e6dc3c934434c838dc8a5a505c291"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:shap:Using 154 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/78 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c2444243c149ff8c0f66f7af07a0a4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:shap:Using 154 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/78 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f964e6bc594707a23abd003617644c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:shap:Using 154 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/78 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505f1c3d03614194a514ce654016f24a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:shap:Using 154 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/78 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e1ac104cba40eea1da93629f321f93"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:shap:Using 154 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/78 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4bf8ee1ae94bc2bc110880d9b30514"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model HistGradientBoosting is not supported or not available.\n","Model PGBM is not supported or not available.\n"]}],"source":["generate_interpretml_explanations_summary_pruners(best_scores_autosampler, X_train, y_train, x_test, feature_names,excel_file_path = \"./drive/MyDrive/SCOUR/Scour_uncertainity/scour_ml/HyperParameter_Tuning/test_results.xlsx\")"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["N9uWqgUD3pKn"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7879eb771c88464bb8e17951be712ab9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1548fc736235427f9fd98990851927a7","IPY_MODEL_a412341972a04922b6e89ab2016520cc","IPY_MODEL_49c85061e6ac4cb58e5580884e86948c"],"layout":"IPY_MODEL_ad25bbaed13a4f4c94ff34da56ebd277"}},"1548fc736235427f9fd98990851927a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fbd1ab8780c479c809391772b1e3fb5","placeholder":"​","style":"IPY_MODEL_b1035950e3d644e4b8512b3fd00ee4b4","value":"100%"}},"a412341972a04922b6e89ab2016520cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_344fb345296a4ca682a3d85ec5f05841","max":78,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a75dba0e2c842cba3fc1ae51f258419","value":78}},"49c85061e6ac4cb58e5580884e86948c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46f69b42b68742a380d6dbc1646a1e72","placeholder":"​","style":"IPY_MODEL_fe2d4973c1674c1280cbd18a2a40ea0a","value":" 78/78 [00:10&lt;00:00,  7.29it/s]"}},"ad25bbaed13a4f4c94ff34da56ebd277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fbd1ab8780c479c809391772b1e3fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1035950e3d644e4b8512b3fd00ee4b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"344fb345296a4ca682a3d85ec5f05841":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a75dba0e2c842cba3fc1ae51f258419":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46f69b42b68742a380d6dbc1646a1e72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe2d4973c1674c1280cbd18a2a40ea0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f24e6dc3c934434c838dc8a5a505c291":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_768e9c3bd9bd44c4bbfa1a6b4e64bbcf","IPY_MODEL_e7443ae0d2684eceab74703bd8fa8e3f","IPY_MODEL_df6cf95039844850b5e645ab212b19fb"],"layout":"IPY_MODEL_7d81968df19b460fbaaf09ecc4fbee15"}},"768e9c3bd9bd44c4bbfa1a6b4e64bbcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_312c7457be4846da9430978ec48e03c9","placeholder":"​","style":"IPY_MODEL_ea9b3efaba9748d082dda5328e330fa6","value":"100%"}},"e7443ae0d2684eceab74703bd8fa8e3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68aa4fa11bef4ed3a3d95d4360237128","max":78,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e30a2214ab9418e8d259a38b8adfdd2","value":78}},"df6cf95039844850b5e645ab212b19fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e696fe8ead56442588c784e7c73abd89","placeholder":"​","style":"IPY_MODEL_8fec7163c92d4ea1b6b93c14741bcb89","value":" 78/78 [00:01&lt;00:00, 57.14it/s]"}},"7d81968df19b460fbaaf09ecc4fbee15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"312c7457be4846da9430978ec48e03c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea9b3efaba9748d082dda5328e330fa6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68aa4fa11bef4ed3a3d95d4360237128":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e30a2214ab9418e8d259a38b8adfdd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e696fe8ead56442588c784e7c73abd89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fec7163c92d4ea1b6b93c14741bcb89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6c2444243c149ff8c0f66f7af07a0a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f5d00d7e7254040990ce20e87f7f66d","IPY_MODEL_41897251d7e04b56a4c124008192e35c","IPY_MODEL_a3b1be3b46cc4b098430452fc078571c"],"layout":"IPY_MODEL_1748789afd354451b00fed3ec9f1568a"}},"9f5d00d7e7254040990ce20e87f7f66d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44749829308b4ad0ada4df9ae7575fb3","placeholder":"​","style":"IPY_MODEL_78f9a079fd434e8f8d854027d7653ab9","value":"100%"}},"41897251d7e04b56a4c124008192e35c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44496d6a8e8c4f7c86b9bf2a6d9b64a9","max":78,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b788d4b7f1c497086c2e8bc4eb1ef4e","value":78}},"a3b1be3b46cc4b098430452fc078571c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9eddebfad2604da389267926e01f50f9","placeholder":"​","style":"IPY_MODEL_4598a93a5a844dd2829e46c09caffa07","value":" 78/78 [00:17&lt;00:00,  4.83it/s]"}},"1748789afd354451b00fed3ec9f1568a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44749829308b4ad0ada4df9ae7575fb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78f9a079fd434e8f8d854027d7653ab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44496d6a8e8c4f7c86b9bf2a6d9b64a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b788d4b7f1c497086c2e8bc4eb1ef4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9eddebfad2604da389267926e01f50f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4598a93a5a844dd2829e46c09caffa07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0f964e6bc594707a23abd003617644c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3cf908b283b450d9d330a240eda596e","IPY_MODEL_a5344cab96ae4b1c9c1301bdf7d05f2a","IPY_MODEL_905d386fa9f64f72b11b7a31fa6cc529"],"layout":"IPY_MODEL_e9e24716983543cdb8bcdf6911991399"}},"c3cf908b283b450d9d330a240eda596e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eabfffba963649af9fc6648cef785c38","placeholder":"​","style":"IPY_MODEL_d20a0129b3e346fdb06baad821788f40","value":"100%"}},"a5344cab96ae4b1c9c1301bdf7d05f2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_385df22dd335463486baa13697a2a534","max":78,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6352cd0c27a541e0a7b9bbd0973a4b38","value":78}},"905d386fa9f64f72b11b7a31fa6cc529":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb09f731cfa0427fa13b2d11e8aa4b66","placeholder":"​","style":"IPY_MODEL_983356d40a9c49819a98e4da73fdfb70","value":" 78/78 [00:18&lt;00:00,  4.35it/s]"}},"e9e24716983543cdb8bcdf6911991399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eabfffba963649af9fc6648cef785c38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d20a0129b3e346fdb06baad821788f40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"385df22dd335463486baa13697a2a534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6352cd0c27a541e0a7b9bbd0973a4b38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb09f731cfa0427fa13b2d11e8aa4b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"983356d40a9c49819a98e4da73fdfb70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"505f1c3d03614194a514ce654016f24a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06dc763121954c39a300a7e3873ba9f0","IPY_MODEL_c080b6651d034bda95055eb0f0a3f0d8","IPY_MODEL_22f0c4ad7266428e88b8a674cc1308b4"],"layout":"IPY_MODEL_d31c97516e144dbf88dc2ef593689762"}},"06dc763121954c39a300a7e3873ba9f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e79583c7ace1485cb3a994c8e1fc8dea","placeholder":"​","style":"IPY_MODEL_451b7028d1e14a38bac836a768fa4a27","value":"100%"}},"c080b6651d034bda95055eb0f0a3f0d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37868b788b49418b93a0a5f0d4a7c5ca","max":78,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff5b76e1c42a473da77924edc4e10ef9","value":78}},"22f0c4ad7266428e88b8a674cc1308b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_989272befd674a15974f588841b3395e","placeholder":"​","style":"IPY_MODEL_4d181233290344ea8c8658e603575845","value":" 78/78 [00:57&lt;00:00,  1.38it/s]"}},"d31c97516e144dbf88dc2ef593689762":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e79583c7ace1485cb3a994c8e1fc8dea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"451b7028d1e14a38bac836a768fa4a27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37868b788b49418b93a0a5f0d4a7c5ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff5b76e1c42a473da77924edc4e10ef9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"989272befd674a15974f588841b3395e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d181233290344ea8c8658e603575845":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95e1ac104cba40eea1da93629f321f93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53b415af044a43e4acd19f4322aea129","IPY_MODEL_cc5335b34d8c4704a4b1ae0017fdfdc7","IPY_MODEL_295edccde0b949df813109ce005211ce"],"layout":"IPY_MODEL_f64288328a16448aabe4a3f803bc5684"}},"53b415af044a43e4acd19f4322aea129":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a8a2441372848b783e032f140f14a4c","placeholder":"​","style":"IPY_MODEL_3bb4b31ea0f7407c97b62fe052647c24","value":"100%"}},"cc5335b34d8c4704a4b1ae0017fdfdc7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a734537d9b547c499f83532f174442a","max":78,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d408ee3adf9e4e0db9a83c4488bab90b","value":78}},"295edccde0b949df813109ce005211ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e5edfa219204cfc82b55c11cf2c1e0c","placeholder":"​","style":"IPY_MODEL_cbe94ffbd6a9485d811ab9dd18ea9a70","value":" 78/78 [00:10&lt;00:00,  8.76it/s]"}},"f64288328a16448aabe4a3f803bc5684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a8a2441372848b783e032f140f14a4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb4b31ea0f7407c97b62fe052647c24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a734537d9b547c499f83532f174442a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d408ee3adf9e4e0db9a83c4488bab90b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e5edfa219204cfc82b55c11cf2c1e0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbe94ffbd6a9485d811ab9dd18ea9a70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a4bf8ee1ae94bc2bc110880d9b30514":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a5fd337fad140c9873ba58a3a937895","IPY_MODEL_6838b8a50ac542ceb356945d7ee02fef","IPY_MODEL_91378540f3894ab7a02e1f40c2c01f93"],"layout":"IPY_MODEL_30fe44512c8a407f85ffb85cec5e7335"}},"5a5fd337fad140c9873ba58a3a937895":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6973e55e45c642a0ac2322b69f2ea76c","placeholder":"​","style":"IPY_MODEL_1b203654b98a4fdc9b5230ba04cd4608","value":"100%"}},"6838b8a50ac542ceb356945d7ee02fef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fac60ba2a7f44277b8cb04b2c593c5e1","max":78,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e37923930254efa9c29850f2363eca4","value":78}},"91378540f3894ab7a02e1f40c2c01f93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96c40ff3fc1f497b9066788627f28d30","placeholder":"​","style":"IPY_MODEL_38493ba7a2b54858be6b9ab79727170e","value":" 78/78 [01:24&lt;00:00,  1.22s/it]"}},"30fe44512c8a407f85ffb85cec5e7335":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6973e55e45c642a0ac2322b69f2ea76c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b203654b98a4fdc9b5230ba04cd4608":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fac60ba2a7f44277b8cb04b2c593c5e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e37923930254efa9c29850f2363eca4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96c40ff3fc1f497b9066788627f28d30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38493ba7a2b54858be6b9ab79727170e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}